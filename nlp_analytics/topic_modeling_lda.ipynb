{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim import models\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "path = 'c:/Users/bill/Documents/projects/data/covid19/open_research'\n",
    "all_sources = pd.read_csv(os.path.join(path, 'metadata.csv'), low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop=set(stopwords.words('english'))\n",
    "\n",
    "#stem = PorterStemmer()\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "def to_tokens(sentence):\n",
    "    words=[ w for w in word_tokenize(sentence) if (w not in stop) ]\n",
    "    #words=[ stem.stem(lem.lemmatize(w)) for w in words if len(w) > 2 ]\n",
    "    words=[ lem.lemmatize(w) for w in words if len(w) > 2 ]\n",
    "    return words\n",
    "\n",
    "corpus = []\n",
    "for news in all_sources['title'].dropna()[:5000]:\n",
    "    corpus.append(to_tokens(news))\n",
    "\n",
    "dic = gensim.corpora.Dictionary(corpus)\n",
    "# (token, count) for each word in the sentence\n",
    "bow_corpus = [ dic.doc2bow(doc) for doc in corpus ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)]\n",
      "1 [(6, 1), (7, 1), (8, 1)]\n",
      "2 [(2, 1), (3, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1)]\n",
      "3 [(16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1)]\n",
      "4 [(4, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1)]\n"
     ]
    }
   ],
   "source": [
    "for i, v in enumerate(bow_corpus[:5]):\n",
    "    print(i, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, \n",
    "                                   num_topics = 4, \n",
    "                                   id2word = dic,                                    \n",
    "                                   passes = 10,\n",
    "                                   workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.035*\"Chapter\" + 0.009*\"Viral\" + 0.008*\"Diseases\" + 0.008*\"The\" + 0.006*\"Infections\" + 0.006*\"Virus\" + 0.004*\"Infectious\" + 0.004*\"virus\" + 0.004*\"Respiratory\" + 0.003*\"China\"'),\n",
       " (1,\n",
       "  '0.023*\"virus\" + 0.012*\"cell\" + 0.012*\"protein\" + 0.012*\"coronavirus\" + 0.010*\"infection\" + 0.007*\"disease\" + 0.006*\"antibody\" + 0.006*\"infectious\" + 0.005*\"gastroenteritis\" + 0.005*\"porcine\"'),\n",
       " (2,\n",
       "  '0.013*\"The\" + 0.010*\"respiratory\" + 0.009*\"syndrome\" + 0.007*\"acute\" + 0.007*\"Chapter\" + 0.006*\"health\" + 0.006*\"SARS\" + 0.005*\"virus\" + 0.005*\"severe\" + 0.005*\"patient\"'),\n",
       " (3,\n",
       "  '0.008*\"Chapter\" + 0.008*\"Acute\" + 0.007*\"Respiratory\" + 0.005*\"infection\" + 0.005*\"volume\" + 0.005*\"Subject\" + 0.005*\"virus\" + 0.005*\"viral\" + 0.005*\"RNA\" + 0.004*\"Disease\"')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should identified topics\n",
    "lda_model.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.9214218854904175\t \n",
      "Topic: 0.008*\"Chapter\" + 0.008*\"Acute\" + 0.007*\"Respiratory\" + 0.005*\"infection\" + 0.005*\"volume\" + 0.005*\"Subject\" + 0.005*\"virus\" + 0.005*\"viral\" + 0.005*\"RNA\" + 0.004*\"Disease\"\n",
      "\n",
      "Score: 0.027481980621814728\t \n",
      "Topic: 0.023*\"virus\" + 0.012*\"cell\" + 0.012*\"protein\" + 0.012*\"coronavirus\" + 0.010*\"infection\" + 0.007*\"disease\" + 0.006*\"antibody\" + 0.006*\"infectious\" + 0.005*\"gastroenteritis\" + 0.005*\"porcine\"\n",
      "\n",
      "Score: 0.025571420788764954\t \n",
      "Topic: 0.013*\"The\" + 0.010*\"respiratory\" + 0.009*\"syndrome\" + 0.007*\"acute\" + 0.007*\"Chapter\" + 0.006*\"health\" + 0.006*\"SARS\" + 0.005*\"virus\" + 0.005*\"severe\" + 0.005*\"patient\"\n",
      "\n",
      "Score: 0.025524664670228958\t \n",
      "Topic: 0.035*\"Chapter\" + 0.009*\"Viral\" + 0.008*\"Diseases\" + 0.008*\"The\" + 0.006*\"Infections\" + 0.006*\"Virus\" + 0.004*\"Infectious\" + 0.004*\"virus\" + 0.004*\"Respiratory\" + 0.003*\"China\"\n"
     ]
    }
   ],
   "source": [
    "# base corpus is 2, and return topic score with the top 10 keywords\n",
    "for index, score in sorted(lda_model[bow_corpus[2]], key=lambda x: -1 * x[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.8395504951477051\t \n",
      "Topic: 0.023*\"virus\" + 0.012*\"cell\" + 0.012*\"protein\" + 0.012*\"coronavirus\" + 0.010*\"infection\" + 0.007*\"disease\" + 0.006*\"antibody\" + 0.006*\"infectious\" + 0.005*\"gastroenteritis\" + 0.005*\"porcine\"\n",
      "\n",
      "Score: 0.058635156601667404\t \n",
      "Topic: 0.013*\"The\" + 0.010*\"respiratory\" + 0.009*\"syndrome\" + 0.007*\"acute\" + 0.007*\"Chapter\" + 0.006*\"health\" + 0.006*\"SARS\" + 0.005*\"virus\" + 0.005*\"severe\" + 0.005*\"patient\"\n",
      "\n",
      "Score: 0.05129947513341904\t \n",
      "Topic: 0.008*\"Chapter\" + 0.008*\"Acute\" + 0.007*\"Respiratory\" + 0.005*\"infection\" + 0.005*\"volume\" + 0.005*\"Subject\" + 0.005*\"virus\" + 0.005*\"viral\" + 0.005*\"RNA\" + 0.004*\"Disease\"\n",
      "\n",
      "Score: 0.050514884293079376\t \n",
      "Topic: 0.035*\"Chapter\" + 0.009*\"Viral\" + 0.008*\"Diseases\" + 0.008*\"The\" + 0.006*\"Infections\" + 0.006*\"Virus\" + 0.004*\"Infectious\" + 0.004*\"virus\" + 0.004*\"Respiratory\" + 0.003*\"China\"\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "sentences = 'covid19 is a deadly virus that causes respiratory infection'\n",
    "for index, score in sorted(lda_model[dic.doc2bow(to_tokens(sentences))], key=lambda x: -1 * x[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting from count to tfidf\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, \n",
    "                                   num_topics = 4, \n",
    "                                   id2word = dic,                                    \n",
    "                                   passes = 10,\n",
    "                                   workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.7727094888687134\t \n",
      "Topic: 0.006*\"volume\" + 0.005*\"Contents\" + 0.005*\"index\" + 0.004*\"Subject\" + 0.003*\"virus\" + 0.003*\"Index\" + 0.002*\"Response\" + 0.002*\"SARS\" + 0.002*\"coronavirus\" + 0.002*\"disease\"\n",
      "\n",
      "Score: 0.08062256872653961\t \n",
      "Topic: 0.006*\"Respiratory\" + 0.006*\"Chapter\" + 0.005*\"Infections\" + 0.005*\"Viral\" + 0.004*\"Acute\" + 0.003*\"The\" + 0.003*\"Diseases\" + 0.003*\"protein\" + 0.002*\"virus\" + 0.002*\"Severe\"\n",
      "\n",
      "Score: 0.07675193250179291\t \n",
      "Topic: 0.003*\"virus\" + 0.003*\"The\" + 0.003*\"infection\" + 0.002*\"Chapter\" + 0.002*\"coronavirus\" + 0.002*\"protein\" + 0.002*\"feline\" + 0.002*\"infectious\" + 0.002*\"patient\" + 0.002*\"bronchitis\"\n",
      "\n",
      "Score: 0.06991596519947052\t \n",
      "Topic: 0.004*\"Chapter\" + 0.003*\"The\" + 0.003*\"health\" + 0.003*\"SARS\" + 0.002*\"Diseases\" + 0.002*\"Health\" + 0.002*\"disease\" + 0.002*\"respiratory\" + 0.002*\"Infectious\" + 0.002*\"public\"\n"
     ]
    }
   ],
   "source": [
    "# base corpus is 2, and return topic score with the top 10 keywords\n",
    "for index, score in sorted(lda_model_tfidf[corpus_tfidf[2]], key=lambda x: -1 * x[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
