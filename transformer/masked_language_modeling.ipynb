{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import BertWordPieceTokenizer\n",
    "import pandas as pd\n",
    "import os\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'C:/Users/bill/Documents/projects/data/chatbot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanse(text):\n",
    "    text = ''.join([ x for x in str(text).lower() if x in string.printable ])\n",
    "    text = re.sub(r'\\b\\d+\\b', '', text)\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = re.sub(r'[#`\\*\\\"“”\\n\\\\…\\+\\-\\/\\=\\(\\)‘•:\\[\\]\\|’\\!;$,?\\'%]', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "data = pd.read_csv(os.path.join(PATH, 'cnv_2019'), sep='\\t', names=[\n",
    "    'rpt_mnth', 'cnv_id', 'msg_id', 'agent', 'msg_type', 'channel', \n",
    "    'creat_ts', 'text', 'intent', 'score', 'resp_cd'\n",
    "])\n",
    "data = data[data['agent'].isin(['coremobile', 'ccp'])]['text'].dropna().apply(cleanse).drop_duplicates().reset_index(drop=True)\n",
    "data.to_csv(os.path.join(PATH, 'tokenizer/sample'), index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i ordered authorized users on my platinum card. want to see when they expect to receive it. if tracking is available\n",
      "tracking for additional cards platinum\n",
      "other card has not been mailed yet you will be notified once its mailed.\n",
      "hi alan thanks for contacting us could you please elaborate your query so that i can help you with it\n",
      "i see one of the card has been mailed on jan under rush delivery maximum time is working days however you will receive it soon as its under rush delivery.\n",
      "no chat with a customer care professional\n",
      "hi joshua i am sorry to hear about your decision to cancel the card i am here to honor your request please help me with the reason for the cancellation of the card.\n",
      "cancel a card\n",
      "hi shashikant thank you for messaging us. i can hep you with card cancellation. if you don t mind may i know the reason of cancellation \n",
      "im no longer going to use the card\n"
     ]
    }
   ],
   "source": [
    "!head $PATH/tokenizer/sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertWordPieceTokenizer()\n",
    "tokenizer.train(files=os.path.join(PATH, 'tokenizer/sample'), vocab_size=30000, min_frequency=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/bill/Documents/projects/data/chatbot\\\\tokenizer\\\\vocab.txt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save(os.path.join(PATH, 'tokenizer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertWordPieceTokenizer(os.path.join(PATH, 'tokenizer/vocab.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertConfig\n",
    "\n",
    "config = DistilBertConfig(\n",
    "    vocab_size=30000,\n",
    "    max_position_embeddings=512,\n",
    "    n_heads=6,\n",
    "    n_layers=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling DistilBertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n"
     ]
    }
   ],
   "source": [
    "from transformers import LineByLineTextDataset, DistilBertTokenizer, DistilBertForMaskedLM\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(os.path.join(PATH, 'tokenizer/vocab.txt'), do_lower_case=True, max_len=512)\n",
    "#model = DistilBertForMaskedLM.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForMaskedLM(config=config).from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "dataset = LineByLineTextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=os.path.join(PATH, 'tokenizer/sample'),\n",
    "    block_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=os.path.join(PATH, 'distilbert'),\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=5,\n",
    "    per_gpu_train_batch_size=32,\n",
    "    save_steps=10000,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    "    prediction_loss_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee2dedfc6f14c24b418c8140aafebe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=5.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72089f3cb7ef408c82e738d4a2639759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=246440.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\torch\\csrc\\utils\\python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 4.997971108586268e-05, \"loss\": 6.128949224472046, \"step\": 500}\n",
      "{\"learning_rate\": 4.9959422171725374e-05, \"loss\": 5.802680884361267, \"step\": 1000}\n",
      "{\"learning_rate\": 4.9939133257588053e-05, \"loss\": 5.359263319015503, \"step\": 1500}\n",
      "{\"learning_rate\": 4.9918844343450746e-05, \"loss\": 4.659339546203613, \"step\": 2000}\n",
      "{\"learning_rate\": 4.9898555429313425e-05, \"loss\": 4.230475105762482, \"step\": 2500}\n",
      "{\"learning_rate\": 4.987826651517611e-05, \"loss\": 3.9149328083992003, \"step\": 3000}\n",
      "{\"learning_rate\": 4.98579776010388e-05, \"loss\": 3.7832697257995607, \"step\": 3500}\n",
      "{\"learning_rate\": 4.9837688686901476e-05, \"loss\": 3.568826804637909, \"step\": 4000}\n",
      "{\"learning_rate\": 4.981739977276416e-05, \"loss\": 3.4469726157188414, \"step\": 4500}\n",
      "{\"learning_rate\": 4.979711085862685e-05, \"loss\": 3.3241396498680116, \"step\": 5000}\n",
      "{\"learning_rate\": 4.9776821944489534e-05, \"loss\": 3.2045674166679383, \"step\": 5500}\n",
      "{\"learning_rate\": 4.975653303035222e-05, \"loss\": 3.1618262119293212, \"step\": 6000}\n",
      "{\"learning_rate\": 4.9736244116214906e-05, \"loss\": 3.0903519439697265, \"step\": 6500}\n",
      "{\"learning_rate\": 4.9715955202077585e-05, \"loss\": 2.99384264087677, \"step\": 7000}\n",
      "{\"learning_rate\": 4.969566628794027e-05, \"loss\": 2.9568832178115843, \"step\": 7500}\n",
      "{\"learning_rate\": 4.967537737380296e-05, \"loss\": 2.8953370757102967, \"step\": 8000}\n",
      "{\"learning_rate\": 4.9655088459665636e-05, \"loss\": 2.8504670808315278, \"step\": 8500}\n",
      "{\"learning_rate\": 4.963479954552833e-05, \"loss\": 2.8075084052085875, \"step\": 9000}\n",
      "{\"learning_rate\": 4.961451063139101e-05, \"loss\": 2.7800838830471037, \"step\": 9500}\n",
      "{\"learning_rate\": 4.9594221717253694e-05, \"loss\": 2.713947474718094, \"step\": 10000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bill\\software\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 4.957393280311638e-05, \"loss\": 2.7053635318279268, \"step\": 10500}\n",
      "{\"learning_rate\": 4.955364388897906e-05, \"loss\": 2.621333956718445, \"step\": 11000}\n",
      "{\"learning_rate\": 4.953335497484175e-05, \"loss\": 2.643410466194153, \"step\": 11500}\n",
      "{\"learning_rate\": 4.951306606070443e-05, \"loss\": 2.6186161227226257, \"step\": 12000}\n",
      "{\"learning_rate\": 4.9492777146567124e-05, \"loss\": 2.596000167131424, \"step\": 12500}\n",
      "{\"learning_rate\": 4.94724882324298e-05, \"loss\": 2.5665775735378267, \"step\": 13000}\n",
      "{\"learning_rate\": 4.945219931829249e-05, \"loss\": 2.552228819847107, \"step\": 13500}\n",
      "{\"learning_rate\": 4.9431910404155175e-05, \"loss\": 2.5118647100925444, \"step\": 14000}\n",
      "{\"learning_rate\": 4.9411621490017854e-05, \"loss\": 2.522433589696884, \"step\": 14500}\n",
      "{\"learning_rate\": 4.939133257588054e-05, \"loss\": 2.5040662636756896, \"step\": 15000}\n",
      "{\"learning_rate\": 4.9371043661743226e-05, \"loss\": 2.4685007209777834, \"step\": 15500}\n",
      "{\"learning_rate\": 4.935075474760591e-05, \"loss\": 2.432910655260086, \"step\": 16000}\n",
      "{\"learning_rate\": 4.93304658334686e-05, \"loss\": 2.4432002902030945, \"step\": 16500}\n",
      "{\"learning_rate\": 4.931017691933128e-05, \"loss\": 2.4140562374591825, \"step\": 17000}\n",
      "{\"learning_rate\": 4.928988800519396e-05, \"loss\": 2.3960992794036864, \"step\": 17500}\n",
      "{\"learning_rate\": 4.926959909105665e-05, \"loss\": 2.361214110374451, \"step\": 18000}\n",
      "{\"learning_rate\": 4.9249310176919335e-05, \"loss\": 2.372092216491699, \"step\": 18500}\n",
      "{\"learning_rate\": 4.9229021262782014e-05, \"loss\": 2.3665186245441436, \"step\": 19000}\n",
      "{\"learning_rate\": 4.920873234864471e-05, \"loss\": 2.376815006971359, \"step\": 19500}\n",
      "{\"learning_rate\": 4.9188443434507386e-05, \"loss\": 2.379724026441574, \"step\": 20000}\n",
      "{\"learning_rate\": 4.916815452037007e-05, \"loss\": 2.3213315777778627, \"step\": 20500}\n",
      "{\"learning_rate\": 4.914786560623276e-05, \"loss\": 2.303109262704849, \"step\": 21000}\n",
      "{\"learning_rate\": 4.912757669209544e-05, \"loss\": 2.3142024784088133, \"step\": 21500}\n",
      "{\"learning_rate\": 4.910728777795813e-05, \"loss\": 2.272918975353241, \"step\": 22000}\n",
      "{\"learning_rate\": 4.908699886382081e-05, \"loss\": 2.275422556400299, \"step\": 22500}\n",
      "{\"learning_rate\": 4.9066709949683495e-05, \"loss\": 2.2468677949905396, \"step\": 23000}\n",
      "{\"learning_rate\": 4.904642103554618e-05, \"loss\": 2.240125685214996, \"step\": 23500}\n",
      "{\"learning_rate\": 4.902613212140886e-05, \"loss\": 2.270248291015625, \"step\": 24000}\n",
      "{\"learning_rate\": 4.900584320727155e-05, \"loss\": 2.2437038252353667, \"step\": 24500}\n",
      "{\"learning_rate\": 4.898555429313423e-05, \"loss\": 2.238495749950409, \"step\": 25000}\n",
      "{\"learning_rate\": 4.896526537899692e-05, \"loss\": 2.2159182076454162, \"step\": 25500}\n",
      "{\"learning_rate\": 4.8944976464859604e-05, \"loss\": 2.2271941883563997, \"step\": 26000}\n",
      "{\"learning_rate\": 4.892468755072229e-05, \"loss\": 2.167669631242752, \"step\": 26500}\n",
      "{\"learning_rate\": 4.8904398636584976e-05, \"loss\": 2.1753530645370485, \"step\": 27000}\n",
      "{\"learning_rate\": 4.8884109722447655e-05, \"loss\": 2.2238466413021087, \"step\": 27500}\n",
      "{\"learning_rate\": 4.886382080831034e-05, \"loss\": 2.187518257141113, \"step\": 28000}\n",
      "{\"learning_rate\": 4.884353189417303e-05, \"loss\": 2.2052101875543593, \"step\": 28500}\n",
      "{\"learning_rate\": 4.882324298003571e-05, \"loss\": 2.181166167020798, \"step\": 29000}\n",
      "{\"learning_rate\": 4.880295406589839e-05, \"loss\": 2.168981751203537, \"step\": 29500}\n",
      "{\"learning_rate\": 4.878266515176108e-05, \"loss\": 2.170206802368164, \"step\": 30000}\n",
      "{\"learning_rate\": 4.8762376237623764e-05, \"loss\": 2.1965660054683687, \"step\": 30500}\n",
      "{\"learning_rate\": 4.874208732348645e-05, \"loss\": 2.154658153295517, \"step\": 31000}\n",
      "{\"learning_rate\": 4.8721798409349136e-05, \"loss\": 2.1167127335071565, \"step\": 31500}\n",
      "{\"learning_rate\": 4.8701509495211815e-05, \"loss\": 2.1144180767536165, \"step\": 32000}\n",
      "{\"learning_rate\": 4.868122058107451e-05, \"loss\": 2.1430769515037538, \"step\": 32500}\n",
      "{\"learning_rate\": 4.866093166693719e-05, \"loss\": 2.1206417620182036, \"step\": 33000}\n",
      "{\"learning_rate\": 4.864064275279987e-05, \"loss\": 2.097435636281967, \"step\": 33500}\n",
      "{\"learning_rate\": 4.862035383866256e-05, \"loss\": 2.126605949640274, \"step\": 34000}\n",
      "{\"learning_rate\": 4.860006492452524e-05, \"loss\": 2.1225915904045105, \"step\": 34500}\n",
      "{\"learning_rate\": 4.857977601038793e-05, \"loss\": 2.088828205347061, \"step\": 35000}\n",
      "{\"learning_rate\": 4.855948709625061e-05, \"loss\": 2.093695707798004, \"step\": 35500}\n",
      "{\"learning_rate\": 4.8539198182113296e-05, \"loss\": 2.05891517663002, \"step\": 36000}\n",
      "{\"learning_rate\": 4.851890926797598e-05, \"loss\": 2.090738300561905, \"step\": 36500}\n",
      "{\"learning_rate\": 4.849862035383867e-05, \"loss\": 2.069566244125366, \"step\": 37000}\n",
      "{\"learning_rate\": 4.847833143970135e-05, \"loss\": 2.0698329281806944, \"step\": 37500}\n",
      "{\"learning_rate\": 4.845804252556403e-05, \"loss\": 2.034556551218033, \"step\": 38000}\n",
      "{\"learning_rate\": 4.843775361142672e-05, \"loss\": 2.068217410445213, \"step\": 38500}\n",
      "{\"learning_rate\": 4.8417464697289404e-05, \"loss\": 2.0335297582149505, \"step\": 39000}\n",
      "{\"learning_rate\": 4.839717578315209e-05, \"loss\": 2.040202855348587, \"step\": 39500}\n",
      "{\"learning_rate\": 4.837688686901477e-05, \"loss\": 2.0467885434627533, \"step\": 40000}\n",
      "{\"learning_rate\": 4.8356597954877455e-05, \"loss\": 2.0432412405014038, \"step\": 40500}\n",
      "{\"learning_rate\": 4.833630904074014e-05, \"loss\": 2.027984080553055, \"step\": 41000}\n",
      "{\"learning_rate\": 4.831602012660283e-05, \"loss\": 2.0185239330530167, \"step\": 41500}\n",
      "{\"learning_rate\": 4.829573121246551e-05, \"loss\": 2.0213223602771757, \"step\": 42000}\n",
      "{\"learning_rate\": 4.827544229832819e-05, \"loss\": 2.0069407429695127, \"step\": 42500}\n",
      "{\"learning_rate\": 4.8255153384190885e-05, \"loss\": 1.9995661013126373, \"step\": 43000}\n",
      "{\"learning_rate\": 4.8234864470053564e-05, \"loss\": 2.0069717284440993, \"step\": 43500}\n",
      "{\"learning_rate\": 4.821457555591625e-05, \"loss\": 2.014298197507858, \"step\": 44000}\n",
      "{\"learning_rate\": 4.8194286641778936e-05, \"loss\": 1.9947732903957367, \"step\": 44500}\n",
      "{\"learning_rate\": 4.8173997727641615e-05, \"loss\": 2.003768137574196, \"step\": 45000}\n",
      "{\"learning_rate\": 4.815370881350431e-05, \"loss\": 1.9948489923477173, \"step\": 45500}\n",
      "{\"learning_rate\": 4.813341989936699e-05, \"loss\": 1.9876772431135177, \"step\": 46000}\n",
      "{\"learning_rate\": 4.811313098522967e-05, \"loss\": 1.998084273338318, \"step\": 46500}\n",
      "{\"learning_rate\": 4.809284207109236e-05, \"loss\": 1.9628007274866104, \"step\": 47000}\n",
      "{\"learning_rate\": 4.807255315695504e-05, \"loss\": 1.9946704829931259, \"step\": 47500}\n",
      "{\"learning_rate\": 4.805226424281773e-05, \"loss\": 2.0087673453092574, \"step\": 48000}\n",
      "{\"learning_rate\": 4.803197532868041e-05, \"loss\": 1.9937255697250367, \"step\": 48500}\n",
      "{\"learning_rate\": 4.8011686414543096e-05, \"loss\": 1.991347577214241, \"step\": 49000}\n",
      "{\"learning_rate\": 4.799139750040578e-05, \"loss\": 1.9513201990127564, \"step\": 49500}\n",
      "{\"learning_rate\": 4.797110858626847e-05, \"loss\": 1.962872095823288, \"step\": 50000}\n",
      "{\"learning_rate\": 4.795081967213115e-05, \"loss\": 1.9690499181747436, \"step\": 50500}\n",
      "{\"learning_rate\": 4.793053075799383e-05, \"loss\": 1.9428703691959381, \"step\": 51000}\n",
      "{\"learning_rate\": 4.791024184385652e-05, \"loss\": 1.9773269186019897, \"step\": 51500}\n",
      "{\"learning_rate\": 4.7889952929719205e-05, \"loss\": 1.9477074670791625, \"step\": 52000}\n",
      "{\"learning_rate\": 4.786966401558189e-05, \"loss\": 1.9574913680553436, \"step\": 52500}\n",
      "{\"learning_rate\": 4.784937510144457e-05, \"loss\": 1.9491573411226273, \"step\": 53000}\n",
      "{\"learning_rate\": 4.7829086187307256e-05, \"loss\": 1.9564004032611846, \"step\": 53500}\n",
      "{\"learning_rate\": 4.780879727316994e-05, \"loss\": 1.9532016760110855, \"step\": 54000}\n",
      "{\"learning_rate\": 4.778850835903262e-05, \"loss\": 1.9327125086784362, \"step\": 54500}\n",
      "{\"learning_rate\": 4.7768219444895314e-05, \"loss\": 1.9454306008815765, \"step\": 55000}\n",
      "{\"learning_rate\": 4.774793053075799e-05, \"loss\": 1.9104451384544372, \"step\": 55500}\n",
      "{\"learning_rate\": 4.7727641616620686e-05, \"loss\": 1.909030830860138, \"step\": 56000}\n",
      "{\"learning_rate\": 4.7707352702483365e-05, \"loss\": 1.937230311870575, \"step\": 56500}\n",
      "{\"learning_rate\": 4.768706378834605e-05, \"loss\": 1.9289976009130478, \"step\": 57000}\n",
      "{\"learning_rate\": 4.766677487420874e-05, \"loss\": 1.9170448285341264, \"step\": 57500}\n",
      "{\"learning_rate\": 4.7646485960071416e-05, \"loss\": 1.9231464875936508, \"step\": 58000}\n",
      "{\"learning_rate\": 4.76261970459341e-05, \"loss\": 1.922964548945427, \"step\": 58500}\n",
      "{\"learning_rate\": 4.760590813179679e-05, \"loss\": 1.9216436586380006, \"step\": 59000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 4.7585619217659474e-05, \"loss\": 1.9016480882167817, \"step\": 59500}\n",
      "{\"learning_rate\": 4.756533030352216e-05, \"loss\": 1.9052011079788207, \"step\": 60000}\n",
      "{\"learning_rate\": 4.754504138938484e-05, \"loss\": 1.9043810179233551, \"step\": 60500}\n",
      "{\"learning_rate\": 4.7524752475247525e-05, \"loss\": 1.9105456326007844, \"step\": 61000}\n",
      "{\"learning_rate\": 4.750446356111021e-05, \"loss\": 1.911097437620163, \"step\": 61500}\n",
      "{\"learning_rate\": 4.74841746469729e-05, \"loss\": 1.911690155506134, \"step\": 62000}\n",
      "{\"learning_rate\": 4.746388573283558e-05, \"loss\": 1.880244991183281, \"step\": 62500}\n",
      "{\"learning_rate\": 4.744359681869827e-05, \"loss\": 1.866886534333229, \"step\": 63000}\n",
      "{\"learning_rate\": 4.742330790456095e-05, \"loss\": 1.8720847388505937, \"step\": 63500}\n",
      "{\"learning_rate\": 4.7403018990423634e-05, \"loss\": 1.8840956897735597, \"step\": 64000}\n",
      "{\"learning_rate\": 4.738273007628632e-05, \"loss\": 1.8646244925260544, \"step\": 64500}\n",
      "{\"learning_rate\": 4.7362441162149e-05, \"loss\": 1.8871823093891145, \"step\": 65000}\n",
      "{\"learning_rate\": 4.734215224801169e-05, \"loss\": 1.894324268937111, \"step\": 65500}\n",
      "{\"learning_rate\": 4.732186333387437e-05, \"loss\": 1.8534998644590377, \"step\": 66000}\n",
      "{\"learning_rate\": 4.7301574419737064e-05, \"loss\": 1.8976179351806641, \"step\": 66500}\n",
      "{\"learning_rate\": 4.728128550559974e-05, \"loss\": 1.8627191524505615, \"step\": 67000}\n",
      "{\"learning_rate\": 4.726099659146243e-05, \"loss\": 1.8625070725679398, \"step\": 67500}\n",
      "{\"learning_rate\": 4.7240707677325115e-05, \"loss\": 1.8980285202264786, \"step\": 68000}\n",
      "{\"learning_rate\": 4.7220418763187794e-05, \"loss\": 1.8637140142917632, \"step\": 68500}\n",
      "{\"learning_rate\": 4.720012984905048e-05, \"loss\": 1.8287697587013245, \"step\": 69000}\n",
      "{\"learning_rate\": 4.7179840934913166e-05, \"loss\": 1.8958361430168151, \"step\": 69500}\n",
      "{\"learning_rate\": 4.715955202077585e-05, \"loss\": 1.8647372303009033, \"step\": 70000}\n",
      "{\"learning_rate\": 4.713926310663854e-05, \"loss\": 1.8347473474740983, \"step\": 70500}\n",
      "{\"learning_rate\": 4.711897419250122e-05, \"loss\": 1.8504300858974456, \"step\": 71000}\n",
      "{\"learning_rate\": 4.70986852783639e-05, \"loss\": 1.8593231838941575, \"step\": 71500}\n",
      "{\"learning_rate\": 4.707839636422659e-05, \"loss\": 1.8329559738636017, \"step\": 72000}\n",
      "{\"learning_rate\": 4.7058107450089275e-05, \"loss\": 1.84149897646904, \"step\": 72500}\n",
      "{\"learning_rate\": 4.703781853595196e-05, \"loss\": 1.845017404794693, \"step\": 73000}\n",
      "{\"learning_rate\": 4.7017529621814646e-05, \"loss\": 1.865807375907898, \"step\": 73500}\n",
      "{\"learning_rate\": 4.6997240707677326e-05, \"loss\": 1.8683655591011048, \"step\": 74000}\n",
      "{\"learning_rate\": 4.697695179354001e-05, \"loss\": 1.84010888504982, \"step\": 74500}\n",
      "{\"learning_rate\": 4.69566628794027e-05, \"loss\": 1.8502412518262863, \"step\": 75000}\n",
      "{\"learning_rate\": 4.693637396526538e-05, \"loss\": 1.8251718460321427, \"step\": 75500}\n",
      "{\"learning_rate\": 4.691608505112807e-05, \"loss\": 1.840853587269783, \"step\": 76000}\n",
      "{\"learning_rate\": 4.689579613699075e-05, \"loss\": 1.8174773117303848, \"step\": 76500}\n",
      "{\"learning_rate\": 4.6875507222853435e-05, \"loss\": 1.8383873797655106, \"step\": 77000}\n",
      "{\"learning_rate\": 4.685521830871612e-05, \"loss\": 1.8510693502426148, \"step\": 77500}\n",
      "{\"learning_rate\": 4.68349293945788e-05, \"loss\": 1.8317120196819305, \"step\": 78000}\n",
      "{\"learning_rate\": 4.681464048044149e-05, \"loss\": 1.8412865921258927, \"step\": 78500}\n",
      "{\"learning_rate\": 4.679435156630417e-05, \"loss\": 1.8274395265579224, \"step\": 79000}\n",
      "{\"learning_rate\": 4.677406265216686e-05, \"loss\": 1.839903473854065, \"step\": 79500}\n",
      "{\"learning_rate\": 4.6753773738029543e-05, \"loss\": 1.793857269525528, \"step\": 80000}\n",
      "{\"learning_rate\": 4.673348482389223e-05, \"loss\": 1.838060198187828, \"step\": 80500}\n",
      "{\"learning_rate\": 4.6713195909754915e-05, \"loss\": 1.8049104410409926, \"step\": 81000}\n",
      "{\"learning_rate\": 4.6692906995617594e-05, \"loss\": 1.8083724628686906, \"step\": 81500}\n",
      "{\"learning_rate\": 4.667261808148028e-05, \"loss\": 1.8460428886413573, \"step\": 82000}\n",
      "{\"learning_rate\": 4.6652329167342966e-05, \"loss\": 1.7868367087841035, \"step\": 82500}\n",
      "{\"learning_rate\": 4.663204025320565e-05, \"loss\": 1.8027916685342789, \"step\": 83000}\n",
      "{\"learning_rate\": 4.661175133906834e-05, \"loss\": 1.8038122099637985, \"step\": 83500}\n",
      "{\"learning_rate\": 4.659146242493102e-05, \"loss\": 1.8038966352939605, \"step\": 84000}\n",
      "{\"learning_rate\": 4.65711735107937e-05, \"loss\": 1.8147617726325989, \"step\": 84500}\n",
      "{\"learning_rate\": 4.655088459665639e-05, \"loss\": 1.8355454627275467, \"step\": 85000}\n",
      "{\"learning_rate\": 4.6530595682519075e-05, \"loss\": 1.787398677945137, \"step\": 85500}\n",
      "{\"learning_rate\": 4.6510306768381754e-05, \"loss\": 1.8156549696922302, \"step\": 86000}\n",
      "{\"learning_rate\": 4.649001785424445e-05, \"loss\": 1.794525647521019, \"step\": 86500}\n",
      "{\"learning_rate\": 4.6469728940107126e-05, \"loss\": 1.8070439406633376, \"step\": 87000}\n",
      "{\"learning_rate\": 4.644944002596981e-05, \"loss\": 1.812470907688141, \"step\": 87500}\n",
      "{\"learning_rate\": 4.64291511118325e-05, \"loss\": 1.812047034740448, \"step\": 88000}\n",
      "{\"learning_rate\": 4.640886219769518e-05, \"loss\": 1.7777795901298523, \"step\": 88500}\n",
      "{\"learning_rate\": 4.638857328355787e-05, \"loss\": 1.7576920856237412, \"step\": 89000}\n",
      "{\"learning_rate\": 4.636828436942055e-05, \"loss\": 1.8161372826099396, \"step\": 89500}\n",
      "{\"learning_rate\": 4.6347995455283235e-05, \"loss\": 1.762487523317337, \"step\": 90000}\n",
      "{\"learning_rate\": 4.632770654114592e-05, \"loss\": 1.767106183886528, \"step\": 90500}\n",
      "{\"learning_rate\": 4.63074176270086e-05, \"loss\": 1.7836308538913728, \"step\": 91000}\n",
      "{\"learning_rate\": 4.628712871287129e-05, \"loss\": 1.7807993270158768, \"step\": 91500}\n",
      "{\"learning_rate\": 4.626683979873397e-05, \"loss\": 1.818414913058281, \"step\": 92000}\n",
      "{\"learning_rate\": 4.624655088459666e-05, \"loss\": 1.7786831753253938, \"step\": 92500}\n",
      "{\"learning_rate\": 4.6226261970459344e-05, \"loss\": 1.8134830936193467, \"step\": 93000}\n",
      "{\"learning_rate\": 4.620597305632203e-05, \"loss\": 1.8131614035367967, \"step\": 93500}\n",
      "{\"learning_rate\": 4.618568414218471e-05, \"loss\": 1.7551213581562042, \"step\": 94000}\n",
      "{\"learning_rate\": 4.6165395228047395e-05, \"loss\": 1.7889313229322434, \"step\": 94500}\n",
      "{\"learning_rate\": 4.614510631391008e-05, \"loss\": 1.7755678259134293, \"step\": 95000}\n",
      "{\"learning_rate\": 4.612481739977277e-05, \"loss\": 1.788664737701416, \"step\": 95500}\n",
      "{\"learning_rate\": 4.610452848563545e-05, \"loss\": 1.780515382885933, \"step\": 96000}\n",
      "{\"learning_rate\": 4.608423957149813e-05, \"loss\": 1.8088958683013916, \"step\": 96500}\n",
      "{\"learning_rate\": 4.6063950657360825e-05, \"loss\": 1.7670976469516755, \"step\": 97000}\n",
      "{\"learning_rate\": 4.6043661743223504e-05, \"loss\": 1.7603800859451293, \"step\": 97500}\n",
      "{\"learning_rate\": 4.602337282908619e-05, \"loss\": 1.7410270820856095, \"step\": 98000}\n",
      "{\"learning_rate\": 4.6003083914948876e-05, \"loss\": 1.782314439535141, \"step\": 98500}\n",
      "{\"learning_rate\": 4.5982795000811555e-05, \"loss\": 1.7763931555747985, \"step\": 99000}\n",
      "{\"learning_rate\": 4.596250608667425e-05, \"loss\": 1.7751191395521164, \"step\": 99500}\n",
      "{\"learning_rate\": 4.594221717253693e-05, \"loss\": 1.7954105707406998, \"step\": 100000}\n",
      "{\"learning_rate\": 4.592192825839961e-05, \"loss\": 1.76569251203537, \"step\": 100500}\n",
      "{\"learning_rate\": 4.59016393442623e-05, \"loss\": 1.7554815117120743, \"step\": 101000}\n",
      "{\"learning_rate\": 4.588135043012498e-05, \"loss\": 1.771054178595543, \"step\": 101500}\n",
      "{\"learning_rate\": 4.586106151598767e-05, \"loss\": 1.7673911374807358, \"step\": 102000}\n",
      "{\"learning_rate\": 4.584077260185035e-05, \"loss\": 1.7670200970172882, \"step\": 102500}\n",
      "{\"learning_rate\": 4.5820483687713036e-05, \"loss\": 1.7554738231897353, \"step\": 103000}\n",
      "{\"learning_rate\": 4.580019477357572e-05, \"loss\": 1.755305619955063, \"step\": 103500}\n",
      "{\"learning_rate\": 4.577990585943841e-05, \"loss\": 1.7532657891511918, \"step\": 104000}\n",
      "{\"learning_rate\": 4.575961694530109e-05, \"loss\": 1.7830303107500076, \"step\": 104500}\n",
      "{\"learning_rate\": 4.573932803116377e-05, \"loss\": 1.7414472893476487, \"step\": 105000}\n",
      "{\"learning_rate\": 4.571903911702646e-05, \"loss\": 1.7512454164028168, \"step\": 105500}\n",
      "{\"learning_rate\": 4.5698750202889145e-05, \"loss\": 1.7467337132692338, \"step\": 106000}\n",
      "{\"learning_rate\": 4.567846128875183e-05, \"loss\": 1.744594225049019, \"step\": 106500}\n",
      "{\"learning_rate\": 4.565817237461451e-05, \"loss\": 1.741424912571907, \"step\": 107000}\n",
      "{\"learning_rate\": 4.5637883460477196e-05, \"loss\": 1.7355041655302048, \"step\": 107500}\n",
      "{\"learning_rate\": 4.561759454633988e-05, \"loss\": 1.7406332581043242, \"step\": 108000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 4.559730563220257e-05, \"loss\": 1.7383772941827773, \"step\": 108500}\n",
      "{\"learning_rate\": 4.5577016718065254e-05, \"loss\": 1.7687381777763367, \"step\": 109000}\n",
      "{\"learning_rate\": 4.555672780392793e-05, \"loss\": 1.7648169734477996, \"step\": 109500}\n",
      "{\"learning_rate\": 4.5536438889790626e-05, \"loss\": 1.7507342969179154, \"step\": 110000}\n",
      "{\"learning_rate\": 4.5516149975653305e-05, \"loss\": 1.7386659895181655, \"step\": 110500}\n",
      "{\"learning_rate\": 4.549586106151599e-05, \"loss\": 1.7125080479383468, \"step\": 111000}\n",
      "{\"learning_rate\": 4.5475572147378677e-05, \"loss\": 1.754179223060608, \"step\": 111500}\n",
      "{\"learning_rate\": 4.5455283233241356e-05, \"loss\": 1.7469014900922775, \"step\": 112000}\n",
      "{\"learning_rate\": 4.543499431910405e-05, \"loss\": 1.7653832006454468, \"step\": 112500}\n",
      "{\"learning_rate\": 4.541470540496673e-05, \"loss\": 1.744118652701378, \"step\": 113000}\n",
      "{\"learning_rate\": 4.5394416490829414e-05, \"loss\": 1.7512749701738357, \"step\": 113500}\n",
      "{\"learning_rate\": 4.53741275766921e-05, \"loss\": 1.716055570602417, \"step\": 114000}\n",
      "{\"learning_rate\": 4.535383866255478e-05, \"loss\": 1.7401879159212112, \"step\": 114500}\n",
      "{\"learning_rate\": 4.5333549748417465e-05, \"loss\": 1.7205842654705048, \"step\": 115000}\n",
      "{\"learning_rate\": 4.531326083428015e-05, \"loss\": 1.7406971403360367, \"step\": 115500}\n",
      "{\"learning_rate\": 4.5292971920142837e-05, \"loss\": 1.7594830863475799, \"step\": 116000}\n",
      "{\"learning_rate\": 4.527268300600552e-05, \"loss\": 1.7182298500537871, \"step\": 116500}\n",
      "{\"learning_rate\": 4.525239409186821e-05, \"loss\": 1.7058387491703033, \"step\": 117000}\n",
      "{\"learning_rate\": 4.523210517773089e-05, \"loss\": 1.7232188931703567, \"step\": 117500}\n",
      "{\"learning_rate\": 4.5211816263593574e-05, \"loss\": 1.730939323067665, \"step\": 118000}\n",
      "{\"learning_rate\": 4.519152734945626e-05, \"loss\": 1.72292311501503, \"step\": 118500}\n",
      "{\"learning_rate\": 4.5171238435318945e-05, \"loss\": 1.7155413408279419, \"step\": 119000}\n",
      "{\"learning_rate\": 4.515094952118163e-05, \"loss\": 1.7276067724227906, \"step\": 119500}\n",
      "{\"learning_rate\": 4.513066060704431e-05, \"loss\": 1.735444410085678, \"step\": 120000}\n",
      "{\"learning_rate\": 4.5110371692906996e-05, \"loss\": 1.713204406619072, \"step\": 120500}\n",
      "{\"learning_rate\": 4.509008277876968e-05, \"loss\": 1.7470606998205185, \"step\": 121000}\n",
      "{\"learning_rate\": 4.506979386463236e-05, \"loss\": 1.7274822586774825, \"step\": 121500}\n",
      "{\"learning_rate\": 4.5049504950495054e-05, \"loss\": 1.7222890127897263, \"step\": 122000}\n",
      "{\"learning_rate\": 4.5029216036357733e-05, \"loss\": 1.683264905333519, \"step\": 122500}\n",
      "{\"learning_rate\": 4.5008927122220426e-05, \"loss\": 1.7417440128326416, \"step\": 123000}\n",
      "{\"learning_rate\": 4.4988638208083105e-05, \"loss\": 1.6816120765209197, \"step\": 123500}\n",
      "{\"learning_rate\": 4.496834929394579e-05, \"loss\": 1.7167888287305832, \"step\": 124000}\n",
      "{\"learning_rate\": 4.494806037980848e-05, \"loss\": 1.7113929821252822, \"step\": 124500}\n",
      "{\"learning_rate\": 4.4927771465671156e-05, \"loss\": 1.7155504106283188, \"step\": 125000}\n",
      "{\"learning_rate\": 4.490748255153384e-05, \"loss\": 1.7262917039394379, \"step\": 125500}\n",
      "{\"learning_rate\": 4.488719363739653e-05, \"loss\": 1.7093336338996887, \"step\": 126000}\n",
      "{\"learning_rate\": 4.4866904723259214e-05, \"loss\": 1.7255235064029693, \"step\": 126500}\n",
      "{\"learning_rate\": 4.48466158091219e-05, \"loss\": 1.733461884379387, \"step\": 127000}\n",
      "{\"learning_rate\": 4.482632689498458e-05, \"loss\": 1.7288704437017441, \"step\": 127500}\n",
      "{\"learning_rate\": 4.4806037980847265e-05, \"loss\": 1.6943561782836913, \"step\": 128000}\n",
      "{\"learning_rate\": 4.478574906670995e-05, \"loss\": 1.7060705626010895, \"step\": 128500}\n",
      "{\"learning_rate\": 4.476546015257264e-05, \"loss\": 1.7048242536783218, \"step\": 129000}\n",
      "{\"learning_rate\": 4.4745171238435316e-05, \"loss\": 1.7001713151931763, \"step\": 129500}\n",
      "{\"learning_rate\": 4.472488232429801e-05, \"loss\": 1.6793593754768372, \"step\": 130000}\n",
      "{\"learning_rate\": 4.470459341016069e-05, \"loss\": 1.7059382532835006, \"step\": 130500}\n",
      "{\"learning_rate\": 4.4684304496023374e-05, \"loss\": 1.6922573734521866, \"step\": 131000}\n",
      "{\"learning_rate\": 4.466401558188606e-05, \"loss\": 1.7036367398500443, \"step\": 131500}\n",
      "{\"learning_rate\": 4.464372666774874e-05, \"loss\": 1.715776089310646, \"step\": 132000}\n",
      "{\"learning_rate\": 4.462343775361143e-05, \"loss\": 1.6943779957294465, \"step\": 132500}\n",
      "{\"learning_rate\": 4.460314883947411e-05, \"loss\": 1.7013099408149719, \"step\": 133000}\n",
      "{\"learning_rate\": 4.4582859925336804e-05, \"loss\": 1.6907075488567351, \"step\": 133500}\n",
      "{\"learning_rate\": 4.456257101119948e-05, \"loss\": 1.7015644736289979, \"step\": 134000}\n",
      "{\"learning_rate\": 4.454228209706217e-05, \"loss\": 1.711225273489952, \"step\": 134500}\n",
      "{\"learning_rate\": 4.4521993182924855e-05, \"loss\": 1.6777831435203552, \"step\": 135000}\n",
      "{\"learning_rate\": 4.4501704268787534e-05, \"loss\": 1.6991439365148544, \"step\": 135500}\n",
      "{\"learning_rate\": 4.448141535465022e-05, \"loss\": 1.7212864611148835, \"step\": 136000}\n",
      "{\"learning_rate\": 4.4461126440512906e-05, \"loss\": 1.6932858290672301, \"step\": 136500}\n",
      "{\"learning_rate\": 4.444083752637559e-05, \"loss\": 1.6719815148115158, \"step\": 137000}\n",
      "{\"learning_rate\": 4.442054861223828e-05, \"loss\": 1.6820439435243606, \"step\": 137500}\n",
      "{\"learning_rate\": 4.440025969810096e-05, \"loss\": 1.7230470697879792, \"step\": 138000}\n",
      "{\"learning_rate\": 4.437997078396364e-05, \"loss\": 1.6715674679279326, \"step\": 138500}\n",
      "{\"learning_rate\": 4.435968186982633e-05, \"loss\": 1.7020925741195678, \"step\": 139000}\n",
      "{\"learning_rate\": 4.4339392955689015e-05, \"loss\": 1.6815681681632995, \"step\": 139500}\n",
      "{\"learning_rate\": 4.4319104041551694e-05, \"loss\": 1.7118263612985611, \"step\": 140000}\n",
      "{\"learning_rate\": 4.429881512741439e-05, \"loss\": 1.6602262154817582, \"step\": 140500}\n",
      "{\"learning_rate\": 4.4278526213277066e-05, \"loss\": 1.690634336590767, \"step\": 141000}\n",
      "{\"learning_rate\": 4.425823729913975e-05, \"loss\": 1.6879310717582703, \"step\": 141500}\n",
      "{\"learning_rate\": 4.423794838500244e-05, \"loss\": 1.6792254683971406, \"step\": 142000}\n",
      "{\"learning_rate\": 4.421765947086512e-05, \"loss\": 1.693619788646698, \"step\": 142500}\n",
      "{\"learning_rate\": 4.419737055672781e-05, \"loss\": 1.7069857014417649, \"step\": 143000}\n",
      "{\"learning_rate\": 4.417708164259049e-05, \"loss\": 1.7125359120368957, \"step\": 143500}\n",
      "{\"learning_rate\": 4.4156792728453175e-05, \"loss\": 1.6710346417427062, \"step\": 144000}\n",
      "{\"learning_rate\": 4.413650381431586e-05, \"loss\": 1.713367955327034, \"step\": 144500}\n",
      "{\"learning_rate\": 4.411621490017854e-05, \"loss\": 1.6944114961624146, \"step\": 145000}\n",
      "{\"learning_rate\": 4.409592598604123e-05, \"loss\": 1.6700722200870515, \"step\": 145500}\n",
      "{\"learning_rate\": 4.407563707190391e-05, \"loss\": 1.6794321241378785, \"step\": 146000}\n",
      "{\"learning_rate\": 4.40553481577666e-05, \"loss\": 1.6627071468830108, \"step\": 146500}\n",
      "{\"learning_rate\": 4.4035059243629284e-05, \"loss\": 1.6541420036554337, \"step\": 147000}\n",
      "{\"learning_rate\": 4.401477032949197e-05, \"loss\": 1.6558383269309997, \"step\": 147500}\n",
      "{\"learning_rate\": 4.3994481415354656e-05, \"loss\": 1.6753122861385346, \"step\": 148000}\n",
      "{\"learning_rate\": 4.3974192501217335e-05, \"loss\": 1.6944702380895615, \"step\": 148500}\n",
      "{\"learning_rate\": 4.395390358708002e-05, \"loss\": 1.6715348279476165, \"step\": 149000}\n",
      "{\"learning_rate\": 4.393361467294271e-05, \"loss\": 1.6455439667701721, \"step\": 149500}\n",
      "{\"learning_rate\": 4.391332575880539e-05, \"loss\": 1.6759118502736092, \"step\": 150000}\n",
      "{\"learning_rate\": 4.389303684466807e-05, \"loss\": 1.6811105893850327, \"step\": 150500}\n",
      "{\"learning_rate\": 4.387274793053076e-05, \"loss\": 1.6560787928104401, \"step\": 151000}\n",
      "{\"learning_rate\": 4.3852459016393444e-05, \"loss\": 1.6610229260921479, \"step\": 151500}\n",
      "{\"learning_rate\": 4.383217010225613e-05, \"loss\": 1.6742040655612946, \"step\": 152000}\n",
      "{\"learning_rate\": 4.3811881188118816e-05, \"loss\": 1.6740140118598938, \"step\": 152500}\n",
      "{\"learning_rate\": 4.3791592273981495e-05, \"loss\": 1.6683378769159316, \"step\": 153000}\n",
      "{\"learning_rate\": 4.377130335984419e-05, \"loss\": 1.66655937063694, \"step\": 153500}\n",
      "{\"learning_rate\": 4.375101444570687e-05, \"loss\": 1.6596807314157487, \"step\": 154000}\n",
      "{\"learning_rate\": 4.373072553156955e-05, \"loss\": 1.678683025598526, \"step\": 154500}\n",
      "{\"learning_rate\": 4.371043661743224e-05, \"loss\": 1.6364769730567932, \"step\": 155000}\n",
      "{\"learning_rate\": 4.369014770329492e-05, \"loss\": 1.6875168365240096, \"step\": 155500}\n",
      "{\"learning_rate\": 4.366985878915761e-05, \"loss\": 1.6647269179821014, \"step\": 156000}\n",
      "{\"learning_rate\": 4.364956987502029e-05, \"loss\": 1.6891862833499909, \"step\": 156500}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 4.3629280960882976e-05, \"loss\": 1.6722978160381317, \"step\": 157000}\n",
      "{\"learning_rate\": 4.360899204674566e-05, \"loss\": 1.6812296562194824, \"step\": 157500}\n",
      "{\"learning_rate\": 4.358870313260834e-05, \"loss\": 1.6579440114498138, \"step\": 158000}\n",
      "{\"learning_rate\": 4.356841421847103e-05, \"loss\": 1.6519947255849838, \"step\": 158500}\n",
      "{\"learning_rate\": 4.354812530433371e-05, \"loss\": 1.6671981557607651, \"step\": 159000}\n",
      "{\"learning_rate\": 4.35278363901964e-05, \"loss\": 1.6744684401750565, \"step\": 159500}\n",
      "{\"learning_rate\": 4.3507547476059084e-05, \"loss\": 1.6526326731443406, \"step\": 160000}\n",
      "{\"learning_rate\": 4.348725856192177e-05, \"loss\": 1.6204775751829148, \"step\": 160500}\n",
      "{\"learning_rate\": 4.346696964778445e-05, \"loss\": 1.6730505256652832, \"step\": 161000}\n",
      "{\"learning_rate\": 4.3446680733647135e-05, \"loss\": 1.665782541513443, \"step\": 161500}\n",
      "{\"learning_rate\": 4.342639181950982e-05, \"loss\": 1.652376938223839, \"step\": 162000}\n",
      "{\"learning_rate\": 4.340610290537251e-05, \"loss\": 1.6365734058618546, \"step\": 162500}\n",
      "{\"learning_rate\": 4.338581399123519e-05, \"loss\": 1.655672739982605, \"step\": 163000}\n",
      "{\"learning_rate\": 4.336552507709787e-05, \"loss\": 1.6786582067012787, \"step\": 163500}\n",
      "{\"learning_rate\": 4.3345236162960565e-05, \"loss\": 1.6299825458526611, \"step\": 164000}\n",
      "{\"learning_rate\": 4.3324947248823244e-05, \"loss\": 1.67071075797081, \"step\": 164500}\n",
      "{\"learning_rate\": 4.330465833468593e-05, \"loss\": 1.6533518303632737, \"step\": 165000}\n",
      "{\"learning_rate\": 4.3284369420548616e-05, \"loss\": 1.661114159345627, \"step\": 165500}\n",
      "{\"learning_rate\": 4.3264080506411295e-05, \"loss\": 1.6185715008974075, \"step\": 166000}\n",
      "{\"learning_rate\": 4.324379159227399e-05, \"loss\": 1.6634716901779174, \"step\": 166500}\n",
      "{\"learning_rate\": 4.322350267813667e-05, \"loss\": 1.627058666229248, \"step\": 167000}\n",
      "{\"learning_rate\": 4.320321376399935e-05, \"loss\": 1.615750470995903, \"step\": 167500}\n",
      "{\"learning_rate\": 4.318292484986204e-05, \"loss\": 1.6259608110189439, \"step\": 168000}\n",
      "{\"learning_rate\": 4.316263593572472e-05, \"loss\": 1.6520799394845962, \"step\": 168500}\n",
      "{\"learning_rate\": 4.314234702158741e-05, \"loss\": 1.643931221961975, \"step\": 169000}\n",
      "{\"learning_rate\": 4.312205810745009e-05, \"loss\": 1.643870542407036, \"step\": 169500}\n",
      "{\"learning_rate\": 4.3101769193312776e-05, \"loss\": 1.6279841163158417, \"step\": 170000}\n",
      "{\"learning_rate\": 4.308148027917546e-05, \"loss\": 1.6524193513393401, \"step\": 170500}\n",
      "{\"learning_rate\": 4.306119136503815e-05, \"loss\": 1.629778807759285, \"step\": 171000}\n",
      "{\"learning_rate\": 4.304090245090083e-05, \"loss\": 1.6390100319385528, \"step\": 171500}\n",
      "{\"learning_rate\": 4.302061353676351e-05, \"loss\": 1.6337946826219558, \"step\": 172000}\n",
      "{\"learning_rate\": 4.30003246226262e-05, \"loss\": 1.63625315117836, \"step\": 172500}\n",
      "{\"learning_rate\": 4.2980035708488885e-05, \"loss\": 1.6423938567638396, \"step\": 173000}\n",
      "{\"learning_rate\": 4.295974679435157e-05, \"loss\": 1.637548816561699, \"step\": 173500}\n",
      "{\"learning_rate\": 4.293945788021425e-05, \"loss\": 1.62377579331398, \"step\": 174000}\n",
      "{\"learning_rate\": 4.2919168966076936e-05, \"loss\": 1.6348559296131133, \"step\": 174500}\n",
      "{\"learning_rate\": 4.289888005193962e-05, \"loss\": 1.6435139684677125, \"step\": 175000}\n",
      "{\"learning_rate\": 4.28785911378023e-05, \"loss\": 1.6350152866840362, \"step\": 175500}\n",
      "{\"learning_rate\": 4.2858302223664994e-05, \"loss\": 1.6425964281558991, \"step\": 176000}\n",
      "{\"learning_rate\": 4.283801330952767e-05, \"loss\": 1.647995838880539, \"step\": 176500}\n",
      "{\"learning_rate\": 4.2817724395390366e-05, \"loss\": 1.6559053995609283, \"step\": 177000}\n",
      "{\"learning_rate\": 4.2797435481253045e-05, \"loss\": 1.6354710260629655, \"step\": 177500}\n",
      "{\"learning_rate\": 4.277714656711573e-05, \"loss\": 1.625388279914856, \"step\": 178000}\n",
      "{\"learning_rate\": 4.275685765297842e-05, \"loss\": 1.6291000823974608, \"step\": 178500}\n",
      "{\"learning_rate\": 4.2736568738841096e-05, \"loss\": 1.6366820154190063, \"step\": 179000}\n",
      "{\"learning_rate\": 4.271627982470379e-05, \"loss\": 1.6384752593040466, \"step\": 179500}\n",
      "{\"learning_rate\": 4.269599091056647e-05, \"loss\": 1.6021187436580657, \"step\": 180000}\n",
      "{\"learning_rate\": 4.2675701996429154e-05, \"loss\": 1.6231735000610352, \"step\": 180500}\n",
      "{\"learning_rate\": 4.265541308229184e-05, \"loss\": 1.6049100041389466, \"step\": 181000}\n",
      "{\"learning_rate\": 4.263512416815452e-05, \"loss\": 1.631116562485695, \"step\": 181500}\n",
      "{\"learning_rate\": 4.2614835254017205e-05, \"loss\": 1.6444161949157714, \"step\": 182000}\n",
      "{\"learning_rate\": 4.259454633987989e-05, \"loss\": 1.6332328999042511, \"step\": 182500}\n",
      "{\"learning_rate\": 4.257425742574258e-05, \"loss\": 1.6171739979982376, \"step\": 183000}\n",
      "{\"learning_rate\": 4.255396851160526e-05, \"loss\": 1.632050179719925, \"step\": 183500}\n",
      "{\"learning_rate\": 4.253367959746795e-05, \"loss\": 1.6066362212896348, \"step\": 184000}\n",
      "{\"learning_rate\": 4.251339068333063e-05, \"loss\": 1.6176435979604722, \"step\": 184500}\n",
      "{\"learning_rate\": 4.2493101769193314e-05, \"loss\": 1.6157337834835053, \"step\": 185000}\n",
      "{\"learning_rate\": 4.2472812855056e-05, \"loss\": 1.6259899808168412, \"step\": 185500}\n",
      "{\"learning_rate\": 4.245252394091868e-05, \"loss\": 1.6296961219310762, \"step\": 186000}\n",
      "{\"learning_rate\": 4.243223502678137e-05, \"loss\": 1.6209736409187316, \"step\": 186500}\n",
      "{\"learning_rate\": 4.241194611264405e-05, \"loss\": 1.6212225251197816, \"step\": 187000}\n",
      "{\"learning_rate\": 4.239165719850674e-05, \"loss\": 1.6403625708818437, \"step\": 187500}\n",
      "{\"learning_rate\": 4.237136828436942e-05, \"loss\": 1.6346628926992417, \"step\": 188000}\n",
      "{\"learning_rate\": 4.23510793702321e-05, \"loss\": 1.6128414771556854, \"step\": 188500}\n",
      "{\"learning_rate\": 4.2330790456094795e-05, \"loss\": 1.6278671377897262, \"step\": 189000}\n",
      "{\"learning_rate\": 4.2310501541957474e-05, \"loss\": 1.6499459989070893, \"step\": 189500}\n",
      "{\"learning_rate\": 4.2290212627820166e-05, \"loss\": 1.6259204288721085, \"step\": 190000}\n",
      "{\"learning_rate\": 4.2269923713682846e-05, \"loss\": 1.6069566786289216, \"step\": 190500}\n",
      "{\"learning_rate\": 4.224963479954553e-05, \"loss\": 1.6054498317241668, \"step\": 191000}\n",
      "{\"learning_rate\": 4.222934588540822e-05, \"loss\": 1.624985407948494, \"step\": 191500}\n",
      "{\"learning_rate\": 4.22090569712709e-05, \"loss\": 1.6093690512180328, \"step\": 192000}\n",
      "{\"learning_rate\": 4.218876805713358e-05, \"loss\": 1.607206733226776, \"step\": 192500}\n",
      "{\"learning_rate\": 4.216847914299627e-05, \"loss\": 1.625864614844322, \"step\": 193000}\n",
      "{\"learning_rate\": 4.2148190228858955e-05, \"loss\": 1.6133813279867173, \"step\": 193500}\n",
      "{\"learning_rate\": 4.212790131472164e-05, \"loss\": 1.6160931615829468, \"step\": 194000}\n",
      "{\"learning_rate\": 4.2107612400584326e-05, \"loss\": 1.6189111099243163, \"step\": 194500}\n",
      "{\"learning_rate\": 4.2087323486447006e-05, \"loss\": 1.6276055021286011, \"step\": 195000}\n",
      "{\"learning_rate\": 4.206703457230969e-05, \"loss\": 1.6349249432086945, \"step\": 195500}\n",
      "{\"learning_rate\": 4.204674565817238e-05, \"loss\": 1.6078034952878952, \"step\": 196000}\n",
      "{\"learning_rate\": 4.202645674403506e-05, \"loss\": 1.6225696860551835, \"step\": 196500}\n",
      "{\"learning_rate\": 4.200616782989775e-05, \"loss\": 1.648891314983368, \"step\": 197000}\n",
      "{\"learning_rate\": 4.198587891576043e-05, \"loss\": 1.6117594929933547, \"step\": 197500}\n",
      "{\"learning_rate\": 4.1965590001623115e-05, \"loss\": 1.634209477543831, \"step\": 198000}\n",
      "{\"learning_rate\": 4.19453010874858e-05, \"loss\": 1.6035220391750336, \"step\": 198500}\n",
      "{\"learning_rate\": 4.192501217334848e-05, \"loss\": 1.6156575293540956, \"step\": 199000}\n",
      "{\"learning_rate\": 4.190472325921117e-05, \"loss\": 1.5989238543510438, \"step\": 199500}\n",
      "{\"learning_rate\": 4.188443434507385e-05, \"loss\": 1.6298726087808608, \"step\": 200000}\n",
      "{\"learning_rate\": 4.186414543093654e-05, \"loss\": 1.590002935051918, \"step\": 200500}\n",
      "{\"learning_rate\": 4.1843856516799223e-05, \"loss\": 1.5934720079898834, \"step\": 201000}\n",
      "{\"learning_rate\": 4.182356760266191e-05, \"loss\": 1.6010504729747772, \"step\": 201500}\n",
      "{\"learning_rate\": 4.1803278688524595e-05, \"loss\": 1.6203522111177444, \"step\": 202000}\n",
      "{\"learning_rate\": 4.1782989774387274e-05, \"loss\": 1.595945825457573, \"step\": 202500}\n",
      "{\"learning_rate\": 4.176270086024996e-05, \"loss\": 1.6247381494045257, \"step\": 203000}\n",
      "{\"learning_rate\": 4.1742411946112646e-05, \"loss\": 1.6114906114339829, \"step\": 203500}\n",
      "{\"learning_rate\": 4.172212303197533e-05, \"loss\": 1.5768097115755082, \"step\": 204000}\n",
      "{\"learning_rate\": 4.170183411783802e-05, \"loss\": 1.6149424352645874, \"step\": 204500}\n",
      "{\"learning_rate\": 4.16815452037007e-05, \"loss\": 1.6206677380800247, \"step\": 205000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 4.166125628956338e-05, \"loss\": 1.609274302959442, \"step\": 205500}\n",
      "{\"learning_rate\": 4.164096737542607e-05, \"loss\": 1.6341561917066574, \"step\": 206000}\n",
      "{\"learning_rate\": 4.1620678461288755e-05, \"loss\": 1.6323397884368895, \"step\": 206500}\n",
      "{\"learning_rate\": 4.1600389547151434e-05, \"loss\": 1.6266976351737976, \"step\": 207000}\n",
      "{\"learning_rate\": 4.158010063301413e-05, \"loss\": 1.621362811088562, \"step\": 207500}\n",
      "{\"learning_rate\": 4.1559811718876806e-05, \"loss\": 1.612387875199318, \"step\": 208000}\n",
      "{\"learning_rate\": 4.153952280473949e-05, \"loss\": 1.608404631137848, \"step\": 208500}\n",
      "{\"learning_rate\": 4.151923389060218e-05, \"loss\": 1.6109141927957535, \"step\": 209000}\n",
      "{\"learning_rate\": 4.149894497646486e-05, \"loss\": 1.6198628281354903, \"step\": 209500}\n",
      "{\"learning_rate\": 4.147865606232755e-05, \"loss\": 1.61674462556839, \"step\": 210000}\n",
      "{\"learning_rate\": 4.145836714819023e-05, \"loss\": 1.578289226770401, \"step\": 210500}\n",
      "{\"learning_rate\": 4.1438078234052915e-05, \"loss\": 1.5854062976837158, \"step\": 211000}\n",
      "{\"learning_rate\": 4.14177893199156e-05, \"loss\": 1.600321001648903, \"step\": 211500}\n",
      "{\"learning_rate\": 4.139750040577828e-05, \"loss\": 1.598634968161583, \"step\": 212000}\n",
      "{\"learning_rate\": 4.137721149164097e-05, \"loss\": 1.6009077748060228, \"step\": 212500}\n",
      "{\"learning_rate\": 4.135692257750365e-05, \"loss\": 1.5933120750188827, \"step\": 213000}\n",
      "{\"learning_rate\": 4.133663366336634e-05, \"loss\": 1.6111614873409272, \"step\": 213500}\n",
      "{\"learning_rate\": 4.1316344749229024e-05, \"loss\": 1.5793803659677506, \"step\": 214000}\n",
      "{\"learning_rate\": 4.129605583509171e-05, \"loss\": 1.5808887808322907, \"step\": 214500}\n",
      "{\"learning_rate\": 4.1275766920954396e-05, \"loss\": 1.5844481451511383, \"step\": 215000}\n",
      "{\"learning_rate\": 4.1255478006817075e-05, \"loss\": 1.5988669378757476, \"step\": 215500}\n",
      "{\"learning_rate\": 4.123518909267976e-05, \"loss\": 1.5871480818986892, \"step\": 216000}\n",
      "{\"learning_rate\": 4.121490017854245e-05, \"loss\": 1.6072514419555664, \"step\": 216500}\n",
      "{\"learning_rate\": 4.119461126440513e-05, \"loss\": 1.6130860078334808, \"step\": 217000}\n",
      "{\"learning_rate\": 4.117432235026781e-05, \"loss\": 1.6084676856994629, \"step\": 217500}\n",
      "{\"learning_rate\": 4.11540334361305e-05, \"loss\": 1.5980430941581727, \"step\": 218000}\n",
      "{\"learning_rate\": 4.1133744521993184e-05, \"loss\": 1.6070540543794631, \"step\": 218500}\n",
      "{\"learning_rate\": 4.111345560785587e-05, \"loss\": 1.5944534351825714, \"step\": 219000}\n",
      "{\"learning_rate\": 4.1093166693718556e-05, \"loss\": 1.5848577754497528, \"step\": 219500}\n",
      "{\"learning_rate\": 4.1072877779581235e-05, \"loss\": 1.5839912322759628, \"step\": 220000}\n",
      "{\"learning_rate\": 4.105258886544393e-05, \"loss\": 1.5678913930654526, \"step\": 220500}\n",
      "{\"learning_rate\": 4.103229995130661e-05, \"loss\": 1.607043788433075, \"step\": 221000}\n",
      "{\"learning_rate\": 4.101201103716929e-05, \"loss\": 1.5568711822032928, \"step\": 221500}\n",
      "{\"learning_rate\": 4.099172212303198e-05, \"loss\": 1.5981820995807647, \"step\": 222000}\n",
      "{\"learning_rate\": 4.097143320889466e-05, \"loss\": 1.6024043596982955, \"step\": 222500}\n",
      "{\"learning_rate\": 4.095114429475735e-05, \"loss\": 1.5992247632741927, \"step\": 223000}\n",
      "{\"learning_rate\": 4.093085538062003e-05, \"loss\": 1.6016806275844575, \"step\": 223500}\n",
      "{\"learning_rate\": 4.0910566466482716e-05, \"loss\": 1.5900709364414216, \"step\": 224000}\n",
      "{\"learning_rate\": 4.08902775523454e-05, \"loss\": 1.6011411263942719, \"step\": 224500}\n",
      "{\"learning_rate\": 4.086998863820808e-05, \"loss\": 1.6462037888765335, \"step\": 225000}\n",
      "{\"learning_rate\": 4.0849699724070774e-05, \"loss\": 1.5692733490467072, \"step\": 225500}\n",
      "{\"learning_rate\": 4.082941080993345e-05, \"loss\": 1.597317509174347, \"step\": 226000}\n",
      "{\"learning_rate\": 4.080912189579614e-05, \"loss\": 1.5903384379148484, \"step\": 226500}\n",
      "{\"learning_rate\": 4.0788832981658825e-05, \"loss\": 1.6192200568914414, \"step\": 227000}\n",
      "{\"learning_rate\": 4.076854406752151e-05, \"loss\": 1.5971493335962295, \"step\": 227500}\n",
      "{\"learning_rate\": 4.074825515338419e-05, \"loss\": 1.5814342852830887, \"step\": 228000}\n",
      "{\"learning_rate\": 4.0727966239246876e-05, \"loss\": 1.5828520138263702, \"step\": 228500}\n",
      "{\"learning_rate\": 4.070767732510956e-05, \"loss\": 1.586576221346855, \"step\": 229000}\n",
      "{\"learning_rate\": 4.068738841097225e-05, \"loss\": 1.5843922967910766, \"step\": 229500}\n",
      "{\"learning_rate\": 4.0667099496834934e-05, \"loss\": 1.5778638814687729, \"step\": 230000}\n",
      "{\"learning_rate\": 4.064681058269761e-05, \"loss\": 1.6123889614343643, \"step\": 230500}\n",
      "{\"learning_rate\": 4.0626521668560305e-05, \"loss\": 1.5947225152254105, \"step\": 231000}\n",
      "{\"learning_rate\": 4.0606232754422985e-05, \"loss\": 1.5890248256921768, \"step\": 231500}\n",
      "{\"learning_rate\": 4.058594384028567e-05, \"loss\": 1.580855486869812, \"step\": 232000}\n",
      "{\"learning_rate\": 4.0565654926148357e-05, \"loss\": 1.600786373734474, \"step\": 232500}\n",
      "{\"learning_rate\": 4.0545366012011036e-05, \"loss\": 1.570142183303833, \"step\": 233000}\n",
      "{\"learning_rate\": 4.052507709787373e-05, \"loss\": 1.5688544335365295, \"step\": 233500}\n",
      "{\"learning_rate\": 4.050478818373641e-05, \"loss\": 1.5690539835691453, \"step\": 234000}\n",
      "{\"learning_rate\": 4.0484499269599094e-05, \"loss\": 1.5622562490701675, \"step\": 234500}\n",
      "{\"learning_rate\": 4.046421035546178e-05, \"loss\": 1.5799627655744553, \"step\": 235000}\n",
      "{\"learning_rate\": 4.044392144132446e-05, \"loss\": 1.5858126858472823, \"step\": 235500}\n",
      "{\"learning_rate\": 4.0423632527187145e-05, \"loss\": 1.5655381911993027, \"step\": 236000}\n",
      "{\"learning_rate\": 4.040334361304983e-05, \"loss\": 1.576310271024704, \"step\": 236500}\n",
      "{\"learning_rate\": 4.0383054698912516e-05, \"loss\": 1.5563450067043305, \"step\": 237000}\n",
      "{\"learning_rate\": 4.03627657847752e-05, \"loss\": 1.546819935321808, \"step\": 237500}\n",
      "{\"learning_rate\": 4.034247687063789e-05, \"loss\": 1.5939362545013427, \"step\": 238000}\n",
      "{\"learning_rate\": 4.032218795650057e-05, \"loss\": 1.5896346259117127, \"step\": 238500}\n",
      "{\"learning_rate\": 4.0301899042363253e-05, \"loss\": 1.6032244625091552, \"step\": 239000}\n",
      "{\"learning_rate\": 4.028161012822594e-05, \"loss\": 1.580763478398323, \"step\": 239500}\n",
      "{\"learning_rate\": 4.0261321214088625e-05, \"loss\": 1.5670786039829254, \"step\": 240000}\n",
      "{\"learning_rate\": 4.024103229995131e-05, \"loss\": 1.5826146568059922, \"step\": 240500}\n",
      "{\"learning_rate\": 4.022074338581399e-05, \"loss\": 1.5766291480064392, \"step\": 241000}\n",
      "{\"learning_rate\": 4.0200454471676676e-05, \"loss\": 1.5891393284797668, \"step\": 241500}\n",
      "{\"learning_rate\": 4.018016555753936e-05, \"loss\": 1.557020357966423, \"step\": 242000}\n",
      "{\"learning_rate\": 4.015987664340204e-05, \"loss\": 1.5955701299905778, \"step\": 242500}\n",
      "{\"learning_rate\": 4.0139587729264734e-05, \"loss\": 1.5551446017026902, \"step\": 243000}\n",
      "{\"learning_rate\": 4.0119298815127413e-05, \"loss\": 1.5735142126083375, \"step\": 243500}\n",
      "{\"learning_rate\": 4.0099009900990106e-05, \"loss\": 1.5830951310396195, \"step\": 244000}\n",
      "{\"learning_rate\": 4.0078720986852785e-05, \"loss\": 1.5547723789215089, \"step\": 244500}\n",
      "{\"learning_rate\": 4.005843207271547e-05, \"loss\": 1.57947804749012, \"step\": 245000}\n",
      "{\"learning_rate\": 4.003814315857816e-05, \"loss\": 1.5855501979589461, \"step\": 245500}\n",
      "{\"learning_rate\": 4.0017854244440836e-05, \"loss\": 1.5813700299263, \"step\": 246000}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4671165569cb4f8a9ef093bd6c0db7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=246440.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 3.999756533030352e-05, \"loss\": 1.557959607720375, \"step\": 246500}\n",
      "{\"learning_rate\": 3.997727641616621e-05, \"loss\": 1.55147276699543, \"step\": 247000}\n",
      "{\"learning_rate\": 3.9956987502028894e-05, \"loss\": 1.5901314021348953, \"step\": 247500}\n",
      "{\"learning_rate\": 3.993669858789158e-05, \"loss\": 1.541367137312889, \"step\": 248000}\n",
      "{\"learning_rate\": 3.991640967375426e-05, \"loss\": 1.5665299710035323, \"step\": 248500}\n",
      "{\"learning_rate\": 3.9896120759616945e-05, \"loss\": 1.586864545106888, \"step\": 249000}\n",
      "{\"learning_rate\": 3.987583184547963e-05, \"loss\": 1.5585404982566833, \"step\": 249500}\n",
      "{\"learning_rate\": 3.985554293134232e-05, \"loss\": 1.569550331234932, \"step\": 250000}\n",
      "{\"learning_rate\": 3.9835254017205e-05, \"loss\": 1.5784214890003205, \"step\": 250500}\n",
      "{\"learning_rate\": 3.981496510306769e-05, \"loss\": 1.569969848036766, \"step\": 251000}\n",
      "{\"learning_rate\": 3.979467618893037e-05, \"loss\": 1.5491194353103637, \"step\": 251500}\n",
      "{\"learning_rate\": 3.9774387274793054e-05, \"loss\": 1.5666718628406524, \"step\": 252000}\n",
      "{\"learning_rate\": 3.975409836065574e-05, \"loss\": 1.5882706733942031, \"step\": 252500}\n",
      "{\"learning_rate\": 3.973380944651842e-05, \"loss\": 1.5605809366703034, \"step\": 253000}\n",
      "{\"learning_rate\": 3.971352053238111e-05, \"loss\": 1.5647203370332718, \"step\": 253500}\n",
      "{\"learning_rate\": 3.969323161824379e-05, \"loss\": 1.5702832864522933, \"step\": 254000}\n",
      "{\"learning_rate\": 3.9672942704106484e-05, \"loss\": 1.557205168247223, \"step\": 254500}\n",
      "{\"learning_rate\": 3.965265378996916e-05, \"loss\": 1.5669633673429488, \"step\": 255000}\n",
      "{\"learning_rate\": 3.963236487583184e-05, \"loss\": 1.5530214215517044, \"step\": 255500}\n",
      "{\"learning_rate\": 3.9612075961694535e-05, \"loss\": 1.5574608054161072, \"step\": 256000}\n",
      "{\"learning_rate\": 3.9591787047557214e-05, \"loss\": 1.5671081091165542, \"step\": 256500}\n",
      "{\"learning_rate\": 3.95714981334199e-05, \"loss\": 1.5596662237644197, \"step\": 257000}\n",
      "{\"learning_rate\": 3.9551209219282586e-05, \"loss\": 1.560163838148117, \"step\": 257500}\n",
      "{\"learning_rate\": 3.953092030514527e-05, \"loss\": 1.5647647433280945, \"step\": 258000}\n",
      "{\"learning_rate\": 3.951063139100796e-05, \"loss\": 1.5741293565034866, \"step\": 258500}\n",
      "{\"learning_rate\": 3.949034247687064e-05, \"loss\": 1.5224369031190872, \"step\": 259000}\n",
      "{\"learning_rate\": 3.947005356273332e-05, \"loss\": 1.572029575228691, \"step\": 259500}\n",
      "{\"learning_rate\": 3.944976464859601e-05, \"loss\": 1.5971989337205887, \"step\": 260000}\n",
      "{\"learning_rate\": 3.9429475734458695e-05, \"loss\": 1.5522034446001052, \"step\": 260500}\n",
      "{\"learning_rate\": 3.940918682032138e-05, \"loss\": 1.5613924877643586, \"step\": 261000}\n",
      "{\"learning_rate\": 3.938889790618407e-05, \"loss\": 1.54624513399601, \"step\": 261500}\n",
      "{\"learning_rate\": 3.9368608992046746e-05, \"loss\": 1.5491367421150208, \"step\": 262000}\n",
      "{\"learning_rate\": 3.934832007790943e-05, \"loss\": 1.5793534576892854, \"step\": 262500}\n",
      "{\"learning_rate\": 3.932803116377212e-05, \"loss\": 1.548891883134842, \"step\": 263000}\n",
      "{\"learning_rate\": 3.93077422496348e-05, \"loss\": 1.5732569266557694, \"step\": 263500}\n",
      "{\"learning_rate\": 3.928745333549749e-05, \"loss\": 1.5490832619667054, \"step\": 264000}\n",
      "{\"learning_rate\": 3.926716442136017e-05, \"loss\": 1.5380067728757858, \"step\": 264500}\n",
      "{\"learning_rate\": 3.9246875507222855e-05, \"loss\": 1.563775296807289, \"step\": 265000}\n",
      "{\"learning_rate\": 3.922658659308554e-05, \"loss\": 1.5158418411016463, \"step\": 265500}\n",
      "{\"learning_rate\": 3.920629767894822e-05, \"loss\": 1.5733783012628555, \"step\": 266000}\n",
      "{\"learning_rate\": 3.918600876481091e-05, \"loss\": 1.5431076272726059, \"step\": 266500}\n",
      "{\"learning_rate\": 3.916571985067359e-05, \"loss\": 1.5296135704517364, \"step\": 267000}\n",
      "{\"learning_rate\": 3.914543093653628e-05, \"loss\": 1.559937641620636, \"step\": 267500}\n",
      "{\"learning_rate\": 3.9125142022398964e-05, \"loss\": 1.545963290810585, \"step\": 268000}\n",
      "{\"learning_rate\": 3.910485310826165e-05, \"loss\": 1.5524962589740754, \"step\": 268500}\n",
      "{\"learning_rate\": 3.9084564194124336e-05, \"loss\": 1.5344901205301285, \"step\": 269000}\n",
      "{\"learning_rate\": 3.9064275279987015e-05, \"loss\": 1.5709929140806198, \"step\": 269500}\n",
      "{\"learning_rate\": 3.90439863658497e-05, \"loss\": 1.577158212184906, \"step\": 270000}\n",
      "{\"learning_rate\": 3.902369745171239e-05, \"loss\": 1.549989154458046, \"step\": 270500}\n",
      "{\"learning_rate\": 3.900340853757507e-05, \"loss\": 1.5585872238874436, \"step\": 271000}\n",
      "{\"learning_rate\": 3.898311962343776e-05, \"loss\": 1.553762526154518, \"step\": 271500}\n",
      "{\"learning_rate\": 3.896283070930044e-05, \"loss\": 1.5458283356428146, \"step\": 272000}\n",
      "{\"learning_rate\": 3.8942541795163124e-05, \"loss\": 1.5501461489200592, \"step\": 272500}\n",
      "{\"learning_rate\": 3.892225288102581e-05, \"loss\": 1.5558823739290237, \"step\": 273000}\n",
      "{\"learning_rate\": 3.8901963966888496e-05, \"loss\": 1.5347131541967391, \"step\": 273500}\n",
      "{\"learning_rate\": 3.8881675052751175e-05, \"loss\": 1.5124835790395736, \"step\": 274000}\n",
      "{\"learning_rate\": 3.886138613861387e-05, \"loss\": 1.5525591953992843, \"step\": 274500}\n",
      "{\"learning_rate\": 3.8841097224476547e-05, \"loss\": 1.531502874135971, \"step\": 275000}\n",
      "{\"learning_rate\": 3.882080831033923e-05, \"loss\": 1.5308879679441452, \"step\": 275500}\n",
      "{\"learning_rate\": 3.880051939620192e-05, \"loss\": 1.5336000446081162, \"step\": 276000}\n",
      "{\"learning_rate\": 3.87802304820646e-05, \"loss\": 1.5535898611545562, \"step\": 276500}\n",
      "{\"learning_rate\": 3.875994156792729e-05, \"loss\": 1.543122619152069, \"step\": 277000}\n",
      "{\"learning_rate\": 3.873965265378997e-05, \"loss\": 1.556978133201599, \"step\": 277500}\n",
      "{\"learning_rate\": 3.8719363739652655e-05, \"loss\": 1.5638272784948348, \"step\": 278000}\n",
      "{\"learning_rate\": 3.869907482551534e-05, \"loss\": 1.5279287201166154, \"step\": 278500}\n",
      "{\"learning_rate\": 3.867878591137802e-05, \"loss\": 1.550842124581337, \"step\": 279000}\n",
      "{\"learning_rate\": 3.865849699724071e-05, \"loss\": 1.5439905984401703, \"step\": 279500}\n",
      "{\"learning_rate\": 3.863820808310339e-05, \"loss\": 1.535983508348465, \"step\": 280000}\n",
      "{\"learning_rate\": 3.861791916896608e-05, \"loss\": 1.5387148866653442, \"step\": 280500}\n",
      "{\"learning_rate\": 3.8597630254828764e-05, \"loss\": 1.5376503306627274, \"step\": 281000}\n",
      "{\"learning_rate\": 3.857734134069145e-05, \"loss\": 1.5255618720054627, \"step\": 281500}\n",
      "{\"learning_rate\": 3.855705242655413e-05, \"loss\": 1.55377459192276, \"step\": 282000}\n",
      "{\"learning_rate\": 3.8536763512416815e-05, \"loss\": 1.5604547358751297, \"step\": 282500}\n",
      "{\"learning_rate\": 3.85164745982795e-05, \"loss\": 1.5393653401136398, \"step\": 283000}\n",
      "{\"learning_rate\": 3.849618568414219e-05, \"loss\": 1.5519785192012787, \"step\": 283500}\n",
      "{\"learning_rate\": 3.847589677000487e-05, \"loss\": 1.552654312491417, \"step\": 284000}\n",
      "{\"learning_rate\": 3.845560785586755e-05, \"loss\": 1.5157147433757783, \"step\": 284500}\n",
      "{\"learning_rate\": 3.843531894173024e-05, \"loss\": 1.5469199769496917, \"step\": 285000}\n",
      "{\"learning_rate\": 3.8415030027592924e-05, \"loss\": 1.5445422564744948, \"step\": 285500}\n",
      "{\"learning_rate\": 3.839474111345561e-05, \"loss\": 1.5230302000045777, \"step\": 286000}\n",
      "{\"learning_rate\": 3.8374452199318296e-05, \"loss\": 1.5565346450805664, \"step\": 286500}\n",
      "{\"learning_rate\": 3.8354163285180975e-05, \"loss\": 1.5419052950143814, \"step\": 287000}\n",
      "{\"learning_rate\": 3.833387437104367e-05, \"loss\": 1.5483688315153121, \"step\": 287500}\n",
      "{\"learning_rate\": 3.831358545690635e-05, \"loss\": 1.5344088746309281, \"step\": 288000}\n",
      "{\"learning_rate\": 3.829329654276903e-05, \"loss\": 1.5279293135404586, \"step\": 288500}\n",
      "{\"learning_rate\": 3.827300762863172e-05, \"loss\": 1.5236799229383469, \"step\": 289000}\n",
      "{\"learning_rate\": 3.82527187144944e-05, \"loss\": 1.546706737279892, \"step\": 289500}\n",
      "{\"learning_rate\": 3.823242980035709e-05, \"loss\": 1.5401997836828232, \"step\": 290000}\n",
      "{\"learning_rate\": 3.821214088621977e-05, \"loss\": 1.5128151955604554, \"step\": 290500}\n",
      "{\"learning_rate\": 3.8191851972082456e-05, \"loss\": 1.542610164642334, \"step\": 291000}\n",
      "{\"learning_rate\": 3.817156305794514e-05, \"loss\": 1.5505593148469925, \"step\": 291500}\n",
      "{\"learning_rate\": 3.815127414380783e-05, \"loss\": 1.5551056402921677, \"step\": 292000}\n",
      "{\"learning_rate\": 3.813098522967051e-05, \"loss\": 1.52276193857193, \"step\": 292500}\n",
      "{\"learning_rate\": 3.811069631553319e-05, \"loss\": 1.5147700221538545, \"step\": 293000}\n",
      "{\"learning_rate\": 3.809040740139588e-05, \"loss\": 1.531777294278145, \"step\": 293500}\n",
      "{\"learning_rate\": 3.8070118487258565e-05, \"loss\": 1.508321583032608, \"step\": 294000}\n",
      "{\"learning_rate\": 3.804982957312125e-05, \"loss\": 1.530146266102791, \"step\": 294500}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 3.802954065898393e-05, \"loss\": 1.5353796137571334, \"step\": 295000}\n",
      "{\"learning_rate\": 3.8009251744846616e-05, \"loss\": 1.5185956262350082, \"step\": 295500}\n",
      "{\"learning_rate\": 3.79889628307093e-05, \"loss\": 1.5097811735868454, \"step\": 296000}\n",
      "{\"learning_rate\": 3.796867391657199e-05, \"loss\": 1.558483452439308, \"step\": 296500}\n",
      "{\"learning_rate\": 3.7948385002434674e-05, \"loss\": 1.5500751608610153, \"step\": 297000}\n",
      "{\"learning_rate\": 3.792809608829735e-05, \"loss\": 1.5625609576702117, \"step\": 297500}\n",
      "{\"learning_rate\": 3.7907807174160046e-05, \"loss\": 1.5290316992998123, \"step\": 298000}\n",
      "{\"learning_rate\": 3.7887518260022725e-05, \"loss\": 1.51874440741539, \"step\": 298500}\n",
      "{\"learning_rate\": 3.786722934588541e-05, \"loss\": 1.5457076816558837, \"step\": 299000}\n",
      "{\"learning_rate\": 3.78469404317481e-05, \"loss\": 1.5231231701374055, \"step\": 299500}\n",
      "{\"learning_rate\": 3.7826651517610776e-05, \"loss\": 1.49819038271904, \"step\": 300000}\n",
      "{\"learning_rate\": 3.780636260347347e-05, \"loss\": 1.5417707315683364, \"step\": 300500}\n",
      "{\"learning_rate\": 3.778607368933615e-05, \"loss\": 1.5634930809736252, \"step\": 301000}\n",
      "{\"learning_rate\": 3.7765784775198834e-05, \"loss\": 1.5322267351150514, \"step\": 301500}\n",
      "{\"learning_rate\": 3.774549586106152e-05, \"loss\": 1.5260480070114135, \"step\": 302000}\n",
      "{\"learning_rate\": 3.77252069469242e-05, \"loss\": 1.5044332498311996, \"step\": 302500}\n",
      "{\"learning_rate\": 3.7704918032786885e-05, \"loss\": 1.5276710520982741, \"step\": 303000}\n",
      "{\"learning_rate\": 3.768462911864957e-05, \"loss\": 1.5451464697122574, \"step\": 303500}\n",
      "{\"learning_rate\": 3.766434020451226e-05, \"loss\": 1.5632705619335174, \"step\": 304000}\n",
      "{\"learning_rate\": 3.764405129037494e-05, \"loss\": 1.5011831988096238, \"step\": 304500}\n",
      "{\"learning_rate\": 3.762376237623763e-05, \"loss\": 1.5207673745155335, \"step\": 305000}\n",
      "{\"learning_rate\": 3.760347346210031e-05, \"loss\": 1.533154642701149, \"step\": 305500}\n",
      "{\"learning_rate\": 3.7583184547962994e-05, \"loss\": 1.54440230345726, \"step\": 306000}\n",
      "{\"learning_rate\": 3.756289563382568e-05, \"loss\": 1.556870959997177, \"step\": 306500}\n",
      "{\"learning_rate\": 3.7542606719688366e-05, \"loss\": 1.5437918400764465, \"step\": 307000}\n",
      "{\"learning_rate\": 3.752231780555105e-05, \"loss\": 1.5538255647420882, \"step\": 307500}\n",
      "{\"learning_rate\": 3.750202889141373e-05, \"loss\": 1.5160103739500046, \"step\": 308000}\n",
      "{\"learning_rate\": 3.748173997727642e-05, \"loss\": 1.5559126315116882, \"step\": 308500}\n",
      "{\"learning_rate\": 3.74614510631391e-05, \"loss\": 1.5078120896816254, \"step\": 309000}\n",
      "{\"learning_rate\": 3.744116214900178e-05, \"loss\": 1.5296609978675841, \"step\": 309500}\n",
      "{\"learning_rate\": 3.7420873234864475e-05, \"loss\": 1.5074698446989059, \"step\": 310000}\n",
      "{\"learning_rate\": 3.7400584320727154e-05, \"loss\": 1.5261844209432602, \"step\": 310500}\n",
      "{\"learning_rate\": 3.7380295406589846e-05, \"loss\": 1.506663840651512, \"step\": 311000}\n",
      "{\"learning_rate\": 3.7360006492452526e-05, \"loss\": 1.5313237283229828, \"step\": 311500}\n",
      "{\"learning_rate\": 3.733971757831521e-05, \"loss\": 1.5091818912029267, \"step\": 312000}\n",
      "{\"learning_rate\": 3.73194286641779e-05, \"loss\": 1.534410223722458, \"step\": 312500}\n",
      "{\"learning_rate\": 3.729913975004058e-05, \"loss\": 1.535594411611557, \"step\": 313000}\n",
      "{\"learning_rate\": 3.727885083590326e-05, \"loss\": 1.5333981490135193, \"step\": 313500}\n",
      "{\"learning_rate\": 3.725856192176595e-05, \"loss\": 1.520115220427513, \"step\": 314000}\n",
      "{\"learning_rate\": 3.7238273007628635e-05, \"loss\": 1.491877520442009, \"step\": 314500}\n",
      "{\"learning_rate\": 3.721798409349132e-05, \"loss\": 1.5234290615320205, \"step\": 315000}\n",
      "{\"learning_rate\": 3.7197695179354e-05, \"loss\": 1.5452094589471816, \"step\": 315500}\n",
      "{\"learning_rate\": 3.7177406265216686e-05, \"loss\": 1.5211280295848846, \"step\": 316000}\n",
      "{\"learning_rate\": 3.715711735107937e-05, \"loss\": 1.5371642700433732, \"step\": 316500}\n",
      "{\"learning_rate\": 3.713682843694206e-05, \"loss\": 1.5208104899525643, \"step\": 317000}\n",
      "{\"learning_rate\": 3.711653952280474e-05, \"loss\": 1.5057249368429184, \"step\": 317500}\n",
      "{\"learning_rate\": 3.709625060866743e-05, \"loss\": 1.5024786705970765, \"step\": 318000}\n",
      "{\"learning_rate\": 3.707596169453011e-05, \"loss\": 1.5175799467563629, \"step\": 318500}\n",
      "{\"learning_rate\": 3.7055672780392794e-05, \"loss\": 1.5365359266996383, \"step\": 319000}\n",
      "{\"learning_rate\": 3.703538386625548e-05, \"loss\": 1.53539142537117, \"step\": 319500}\n",
      "{\"learning_rate\": 3.701509495211816e-05, \"loss\": 1.529697645664215, \"step\": 320000}\n",
      "{\"learning_rate\": 3.699480603798085e-05, \"loss\": 1.5091158765554429, \"step\": 320500}\n",
      "{\"learning_rate\": 3.697451712384353e-05, \"loss\": 1.5265782150030136, \"step\": 321000}\n",
      "{\"learning_rate\": 3.6954228209706224e-05, \"loss\": 1.5142026150226593, \"step\": 321500}\n",
      "{\"learning_rate\": 3.69339392955689e-05, \"loss\": 1.5002133098840713, \"step\": 322000}\n",
      "{\"learning_rate\": 3.691365038143158e-05, \"loss\": 1.5130389590263367, \"step\": 322500}\n",
      "{\"learning_rate\": 3.6893361467294275e-05, \"loss\": 1.4788204214572906, \"step\": 323000}\n",
      "{\"learning_rate\": 3.6873072553156954e-05, \"loss\": 1.5294330488443375, \"step\": 323500}\n",
      "{\"learning_rate\": 3.685278363901964e-05, \"loss\": 1.5190288900136948, \"step\": 324000}\n",
      "{\"learning_rate\": 3.6832494724882326e-05, \"loss\": 1.5325851044654846, \"step\": 324500}\n",
      "{\"learning_rate\": 3.681220581074501e-05, \"loss\": 1.5095025026798248, \"step\": 325000}\n",
      "{\"learning_rate\": 3.67919168966077e-05, \"loss\": 1.4894520829916, \"step\": 325500}\n",
      "{\"learning_rate\": 3.677162798247038e-05, \"loss\": 1.5535371400117874, \"step\": 326000}\n",
      "{\"learning_rate\": 3.675133906833306e-05, \"loss\": 1.5149281290769576, \"step\": 326500}\n",
      "{\"learning_rate\": 3.673105015419575e-05, \"loss\": 1.5140563890933991, \"step\": 327000}\n",
      "{\"learning_rate\": 3.6710761240058435e-05, \"loss\": 1.5015652277469635, \"step\": 327500}\n",
      "{\"learning_rate\": 3.6690472325921114e-05, \"loss\": 1.5172414653301238, \"step\": 328000}\n",
      "{\"learning_rate\": 3.667018341178381e-05, \"loss\": 1.5104518102407456, \"step\": 328500}\n",
      "{\"learning_rate\": 3.6649894497646486e-05, \"loss\": 1.5022758141756059, \"step\": 329000}\n",
      "{\"learning_rate\": 3.662960558350917e-05, \"loss\": 1.497136402487755, \"step\": 329500}\n",
      "{\"learning_rate\": 3.660931666937186e-05, \"loss\": 1.5273691288232802, \"step\": 330000}\n",
      "{\"learning_rate\": 3.658902775523454e-05, \"loss\": 1.4958131411075593, \"step\": 330500}\n",
      "{\"learning_rate\": 3.656873884109723e-05, \"loss\": 1.4995867060422898, \"step\": 331000}\n",
      "{\"learning_rate\": 3.654844992695991e-05, \"loss\": 1.5408584657907487, \"step\": 331500}\n",
      "{\"learning_rate\": 3.6528161012822595e-05, \"loss\": 1.5284219433069228, \"step\": 332000}\n",
      "{\"learning_rate\": 3.650787209868528e-05, \"loss\": 1.5196982032060624, \"step\": 332500}\n",
      "{\"learning_rate\": 3.648758318454796e-05, \"loss\": 1.5097892689704895, \"step\": 333000}\n",
      "{\"learning_rate\": 3.646729427041065e-05, \"loss\": 1.5724580949544906, \"step\": 333500}\n",
      "{\"learning_rate\": 3.644700535627333e-05, \"loss\": 1.508904673576355, \"step\": 334000}\n",
      "{\"learning_rate\": 3.642671644213602e-05, \"loss\": 1.5248085687756538, \"step\": 334500}\n",
      "{\"learning_rate\": 3.6406427527998704e-05, \"loss\": 1.4703091601133347, \"step\": 335000}\n",
      "{\"learning_rate\": 3.638613861386139e-05, \"loss\": 1.5079554121494294, \"step\": 335500}\n",
      "{\"learning_rate\": 3.6365849699724076e-05, \"loss\": 1.5018538604974747, \"step\": 336000}\n",
      "{\"learning_rate\": 3.6345560785586755e-05, \"loss\": 1.516107514858246, \"step\": 336500}\n",
      "{\"learning_rate\": 3.632527187144944e-05, \"loss\": 1.4956193264722824, \"step\": 337000}\n",
      "{\"learning_rate\": 3.630498295731213e-05, \"loss\": 1.4958003343343735, \"step\": 337500}\n",
      "{\"learning_rate\": 3.628469404317481e-05, \"loss\": 1.5085008860826492, \"step\": 338000}\n",
      "{\"learning_rate\": 3.626440512903749e-05, \"loss\": 1.5289749881029129, \"step\": 338500}\n",
      "{\"learning_rate\": 3.624411621490018e-05, \"loss\": 1.520165816783905, \"step\": 339000}\n",
      "{\"learning_rate\": 3.6223827300762864e-05, \"loss\": 1.5014987498521806, \"step\": 339500}\n",
      "{\"learning_rate\": 3.620353838662555e-05, \"loss\": 1.5236789103746413, \"step\": 340000}\n",
      "{\"learning_rate\": 3.6183249472488236e-05, \"loss\": 1.5173862565755845, \"step\": 340500}\n",
      "{\"learning_rate\": 3.6162960558350915e-05, \"loss\": 1.5100428080558777, \"step\": 341000}\n",
      "{\"learning_rate\": 3.614267164421361e-05, \"loss\": 1.5270123246908187, \"step\": 341500}\n",
      "{\"learning_rate\": 3.612238273007629e-05, \"loss\": 1.5100693086385726, \"step\": 342000}\n",
      "{\"learning_rate\": 3.610209381593897e-05, \"loss\": 1.4986697130203248, \"step\": 342500}\n",
      "{\"learning_rate\": 3.608180490180166e-05, \"loss\": 1.5251232094764708, \"step\": 343000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 3.606151598766434e-05, \"loss\": 1.522289174079895, \"step\": 343500}\n",
      "{\"learning_rate\": 3.604122707352703e-05, \"loss\": 1.5141226394176484, \"step\": 344000}\n",
      "{\"learning_rate\": 3.602093815938971e-05, \"loss\": 1.5406827812194823, \"step\": 344500}\n",
      "{\"learning_rate\": 3.6000649245252396e-05, \"loss\": 1.507112223148346, \"step\": 345000}\n",
      "{\"learning_rate\": 3.598036033111508e-05, \"loss\": 1.4872461782693862, \"step\": 345500}\n",
      "{\"learning_rate\": 3.596007141697776e-05, \"loss\": 1.5090194594860078, \"step\": 346000}\n",
      "{\"learning_rate\": 3.5939782502840454e-05, \"loss\": 1.5053401322364808, \"step\": 346500}\n",
      "{\"learning_rate\": 3.591949358870313e-05, \"loss\": 1.4946132545471191, \"step\": 347000}\n",
      "{\"learning_rate\": 3.589920467456582e-05, \"loss\": 1.49993820810318, \"step\": 347500}\n",
      "{\"learning_rate\": 3.5878915760428505e-05, \"loss\": 1.5170123401880264, \"step\": 348000}\n",
      "{\"learning_rate\": 3.585862684629119e-05, \"loss\": 1.513134134054184, \"step\": 348500}\n",
      "{\"learning_rate\": 3.583833793215387e-05, \"loss\": 1.5309298247098924, \"step\": 349000}\n",
      "{\"learning_rate\": 3.5818049018016556e-05, \"loss\": 1.5006190567016602, \"step\": 349500}\n",
      "{\"learning_rate\": 3.579776010387924e-05, \"loss\": 1.4966498384475708, \"step\": 350000}\n",
      "{\"learning_rate\": 3.577747118974193e-05, \"loss\": 1.5107911127805709, \"step\": 350500}\n",
      "{\"learning_rate\": 3.5757182275604614e-05, \"loss\": 1.514149609208107, \"step\": 351000}\n",
      "{\"learning_rate\": 3.573689336146729e-05, \"loss\": 1.4787610281705856, \"step\": 351500}\n",
      "{\"learning_rate\": 3.5716604447329985e-05, \"loss\": 1.479257155776024, \"step\": 352000}\n",
      "{\"learning_rate\": 3.5696315533192665e-05, \"loss\": 1.4918137197494508, \"step\": 352500}\n",
      "{\"learning_rate\": 3.5676026619055344e-05, \"loss\": 1.4995729782581328, \"step\": 353000}\n",
      "{\"learning_rate\": 3.5655737704918037e-05, \"loss\": 1.5062848241329194, \"step\": 353500}\n",
      "{\"learning_rate\": 3.5635448790780716e-05, \"loss\": 1.4796017271280288, \"step\": 354000}\n",
      "{\"learning_rate\": 3.561515987664341e-05, \"loss\": 1.5322442339658737, \"step\": 354500}\n",
      "{\"learning_rate\": 3.559487096250609e-05, \"loss\": 1.5019147205352783, \"step\": 355000}\n",
      "{\"learning_rate\": 3.5574582048368774e-05, \"loss\": 1.485129628777504, \"step\": 355500}\n",
      "{\"learning_rate\": 3.555429313423146e-05, \"loss\": 1.4858876271247863, \"step\": 356000}\n",
      "{\"learning_rate\": 3.553400422009414e-05, \"loss\": 1.5263676650524138, \"step\": 356500}\n",
      "{\"learning_rate\": 3.551371530595683e-05, \"loss\": 1.5189648139476777, \"step\": 357000}\n",
      "{\"learning_rate\": 3.549342639181951e-05, \"loss\": 1.5164152932167054, \"step\": 357500}\n",
      "{\"learning_rate\": 3.5473137477682196e-05, \"loss\": 1.5106744713783264, \"step\": 358000}\n",
      "{\"learning_rate\": 3.545284856354488e-05, \"loss\": 1.4881795146465302, \"step\": 358500}\n",
      "{\"learning_rate\": 3.543255964940757e-05, \"loss\": 1.5068854712247848, \"step\": 359000}\n",
      "{\"learning_rate\": 3.541227073527025e-05, \"loss\": 1.5047016595602036, \"step\": 359500}\n",
      "{\"learning_rate\": 3.5391981821132933e-05, \"loss\": 1.4857743833065034, \"step\": 360000}\n",
      "{\"learning_rate\": 3.537169290699562e-05, \"loss\": 1.4897390221357345, \"step\": 360500}\n",
      "{\"learning_rate\": 3.5351403992858305e-05, \"loss\": 1.5278673961162568, \"step\": 361000}\n",
      "{\"learning_rate\": 3.533111507872099e-05, \"loss\": 1.482681358575821, \"step\": 361500}\n",
      "{\"learning_rate\": 3.531082616458367e-05, \"loss\": 1.4952349326610566, \"step\": 362000}\n",
      "{\"learning_rate\": 3.5290537250446356e-05, \"loss\": 1.512037840604782, \"step\": 362500}\n",
      "{\"learning_rate\": 3.527024833630904e-05, \"loss\": 1.5078424178361893, \"step\": 363000}\n",
      "{\"learning_rate\": 3.524995942217172e-05, \"loss\": 1.4815989756584167, \"step\": 363500}\n",
      "{\"learning_rate\": 3.5229670508034414e-05, \"loss\": 1.4884883822202684, \"step\": 364000}\n",
      "{\"learning_rate\": 3.5209381593897093e-05, \"loss\": 1.4938503948450088, \"step\": 364500}\n",
      "{\"learning_rate\": 3.5189092679759786e-05, \"loss\": 1.5007638151645661, \"step\": 365000}\n",
      "{\"learning_rate\": 3.5168803765622465e-05, \"loss\": 1.5047606885433198, \"step\": 365500}\n",
      "{\"learning_rate\": 3.514851485148515e-05, \"loss\": 1.4689953207969666, \"step\": 366000}\n",
      "{\"learning_rate\": 3.512822593734784e-05, \"loss\": 1.522620917201042, \"step\": 366500}\n",
      "{\"learning_rate\": 3.5107937023210516e-05, \"loss\": 1.4717816511392594, \"step\": 367000}\n",
      "{\"learning_rate\": 3.508764810907321e-05, \"loss\": 1.5104565461874009, \"step\": 367500}\n",
      "{\"learning_rate\": 3.506735919493589e-05, \"loss\": 1.4919416638612748, \"step\": 368000}\n",
      "{\"learning_rate\": 3.5047070280798574e-05, \"loss\": 1.4791750262975694, \"step\": 368500}\n",
      "{\"learning_rate\": 3.502678136666126e-05, \"loss\": 1.5080349905490875, \"step\": 369000}\n",
      "{\"learning_rate\": 3.500649245252394e-05, \"loss\": 1.4920190892219543, \"step\": 369500}\n",
      "{\"learning_rate\": 3.4986203538386625e-05, \"loss\": 1.5029588613510132, \"step\": 370000}\n",
      "{\"learning_rate\": 3.496591462424931e-05, \"loss\": 1.4923852593898774, \"step\": 370500}\n",
      "{\"learning_rate\": 3.4945625710112e-05, \"loss\": 1.5124092873334885, \"step\": 371000}\n",
      "{\"learning_rate\": 3.492533679597468e-05, \"loss\": 1.4784959746599198, \"step\": 371500}\n",
      "{\"learning_rate\": 3.490504788183737e-05, \"loss\": 1.4688929983377457, \"step\": 372000}\n",
      "{\"learning_rate\": 3.488475896770005e-05, \"loss\": 1.5163461327552796, \"step\": 372500}\n",
      "{\"learning_rate\": 3.4864470053562734e-05, \"loss\": 1.4902884324193, \"step\": 373000}\n",
      "{\"learning_rate\": 3.484418113942542e-05, \"loss\": 1.4830191956758498, \"step\": 373500}\n",
      "{\"learning_rate\": 3.48238922252881e-05, \"loss\": 1.4671033855676652, \"step\": 374000}\n",
      "{\"learning_rate\": 3.480360331115079e-05, \"loss\": 1.5158788694143295, \"step\": 374500}\n",
      "{\"learning_rate\": 3.478331439701347e-05, \"loss\": 1.4785229173898697, \"step\": 375000}\n",
      "{\"learning_rate\": 3.476302548287616e-05, \"loss\": 1.4964694650173187, \"step\": 375500}\n",
      "{\"learning_rate\": 3.474273656873884e-05, \"loss\": 1.4981737178564072, \"step\": 376000}\n",
      "{\"learning_rate\": 3.472244765460152e-05, \"loss\": 1.496892908334732, \"step\": 376500}\n",
      "{\"learning_rate\": 3.4702158740464215e-05, \"loss\": 1.5039986565113068, \"step\": 377000}\n",
      "{\"learning_rate\": 3.4681869826326894e-05, \"loss\": 1.4710283900499344, \"step\": 377500}\n",
      "{\"learning_rate\": 3.466158091218959e-05, \"loss\": 1.5081129508018494, \"step\": 378000}\n",
      "{\"learning_rate\": 3.4641291998052266e-05, \"loss\": 1.4855543543100358, \"step\": 378500}\n",
      "{\"learning_rate\": 3.462100308391495e-05, \"loss\": 1.4955672565698623, \"step\": 379000}\n",
      "{\"learning_rate\": 3.460071416977764e-05, \"loss\": 1.494189060330391, \"step\": 379500}\n",
      "{\"learning_rate\": 3.458042525564032e-05, \"loss\": 1.508249529004097, \"step\": 380000}\n",
      "{\"learning_rate\": 3.4560136341503e-05, \"loss\": 1.4981657099723815, \"step\": 380500}\n",
      "{\"learning_rate\": 3.453984742736569e-05, \"loss\": 1.484751450419426, \"step\": 381000}\n",
      "{\"learning_rate\": 3.4519558513228375e-05, \"loss\": 1.4972136005163192, \"step\": 381500}\n",
      "{\"learning_rate\": 3.449926959909106e-05, \"loss\": 1.489693781375885, \"step\": 382000}\n",
      "{\"learning_rate\": 3.447898068495374e-05, \"loss\": 1.4879057134389877, \"step\": 382500}\n",
      "{\"learning_rate\": 3.4458691770816426e-05, \"loss\": 1.4555555347204208, \"step\": 383000}\n",
      "{\"learning_rate\": 3.443840285667911e-05, \"loss\": 1.499701011300087, \"step\": 383500}\n",
      "{\"learning_rate\": 3.44181139425418e-05, \"loss\": 1.5011426416635514, \"step\": 384000}\n",
      "{\"learning_rate\": 3.439782502840448e-05, \"loss\": 1.489677878022194, \"step\": 384500}\n",
      "{\"learning_rate\": 3.437753611426717e-05, \"loss\": 1.4742292702198028, \"step\": 385000}\n",
      "{\"learning_rate\": 3.435724720012985e-05, \"loss\": 1.4732479463815689, \"step\": 385500}\n",
      "{\"learning_rate\": 3.4336958285992535e-05, \"loss\": 1.4663296228647231, \"step\": 386000}\n",
      "{\"learning_rate\": 3.431666937185522e-05, \"loss\": 1.4941359182596208, \"step\": 386500}\n",
      "{\"learning_rate\": 3.42963804577179e-05, \"loss\": 1.4701510047912598, \"step\": 387000}\n",
      "{\"learning_rate\": 3.427609154358059e-05, \"loss\": 1.505744925737381, \"step\": 387500}\n",
      "{\"learning_rate\": 3.425580262944327e-05, \"loss\": 1.4986192433834076, \"step\": 388000}\n",
      "{\"learning_rate\": 3.423551371530596e-05, \"loss\": 1.5048374116420746, \"step\": 388500}\n",
      "{\"learning_rate\": 3.4215224801168644e-05, \"loss\": 1.4944308613538742, \"step\": 389000}\n",
      "{\"learning_rate\": 3.419493588703133e-05, \"loss\": 1.4799930453300476, \"step\": 389500}\n",
      "{\"learning_rate\": 3.4174646972894016e-05, \"loss\": 1.4840630530118941, \"step\": 390000}\n",
      "{\"learning_rate\": 3.4154358058756695e-05, \"loss\": 1.488663870215416, \"step\": 390500}\n",
      "{\"learning_rate\": 3.413406914461938e-05, \"loss\": 1.4817226535081864, \"step\": 391000}\n",
      "{\"learning_rate\": 3.411378023048207e-05, \"loss\": 1.4933953108787537, \"step\": 391500}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 3.409349131634475e-05, \"loss\": 1.4709656341075896, \"step\": 392000}\n",
      "{\"learning_rate\": 3.407320240220744e-05, \"loss\": 1.4912839455604554, \"step\": 392500}\n",
      "{\"learning_rate\": 3.405291348807012e-05, \"loss\": 1.4785441794395446, \"step\": 393000}\n",
      "{\"learning_rate\": 3.4032624573932804e-05, \"loss\": 1.4948534595966338, \"step\": 393500}\n",
      "{\"learning_rate\": 3.401233565979549e-05, \"loss\": 1.4920565427541732, \"step\": 394000}\n",
      "{\"learning_rate\": 3.3992046745658176e-05, \"loss\": 1.4795369819402695, \"step\": 394500}\n",
      "{\"learning_rate\": 3.3971757831520855e-05, \"loss\": 1.4890050913095474, \"step\": 395000}\n",
      "{\"learning_rate\": 3.395146891738355e-05, \"loss\": 1.4791620744466782, \"step\": 395500}\n",
      "{\"learning_rate\": 3.3931180003246227e-05, \"loss\": 1.480379185795784, \"step\": 396000}\n",
      "{\"learning_rate\": 3.391089108910891e-05, \"loss\": 1.4998876304626465, \"step\": 396500}\n",
      "{\"learning_rate\": 3.38906021749716e-05, \"loss\": 1.4869209820032119, \"step\": 397000}\n",
      "{\"learning_rate\": 3.387031326083428e-05, \"loss\": 1.4916663637161256, \"step\": 397500}\n",
      "{\"learning_rate\": 3.385002434669697e-05, \"loss\": 1.4718740112781525, \"step\": 398000}\n",
      "{\"learning_rate\": 3.382973543255965e-05, \"loss\": 1.4949429744482041, \"step\": 398500}\n",
      "{\"learning_rate\": 3.3809446518422335e-05, \"loss\": 1.5030957787036896, \"step\": 399000}\n",
      "{\"learning_rate\": 3.378915760428502e-05, \"loss\": 1.50017116689682, \"step\": 399500}\n",
      "{\"learning_rate\": 3.37688686901477e-05, \"loss\": 1.475774752497673, \"step\": 400000}\n",
      "{\"learning_rate\": 3.374857977601039e-05, \"loss\": 1.484214635372162, \"step\": 400500}\n",
      "{\"learning_rate\": 3.372829086187307e-05, \"loss\": 1.4860877825021743, \"step\": 401000}\n",
      "{\"learning_rate\": 3.370800194773576e-05, \"loss\": 1.4623662252426148, \"step\": 401500}\n",
      "{\"learning_rate\": 3.3687713033598444e-05, \"loss\": 1.4904126032590865, \"step\": 402000}\n",
      "{\"learning_rate\": 3.366742411946113e-05, \"loss\": 1.4959106432199478, \"step\": 402500}\n",
      "{\"learning_rate\": 3.3647135205323816e-05, \"loss\": 1.475278801560402, \"step\": 403000}\n",
      "{\"learning_rate\": 3.3626846291186495e-05, \"loss\": 1.4735794349908828, \"step\": 403500}\n",
      "{\"learning_rate\": 3.360655737704918e-05, \"loss\": 1.4976066341400147, \"step\": 404000}\n",
      "{\"learning_rate\": 3.358626846291187e-05, \"loss\": 1.4820273336172103, \"step\": 404500}\n",
      "{\"learning_rate\": 3.356597954877455e-05, \"loss\": 1.4744644490480423, \"step\": 405000}\n",
      "{\"learning_rate\": 3.354569063463723e-05, \"loss\": 1.477700233578682, \"step\": 405500}\n",
      "{\"learning_rate\": 3.352540172049992e-05, \"loss\": 1.4935926703214646, \"step\": 406000}\n",
      "{\"learning_rate\": 3.3505112806362604e-05, \"loss\": 1.4529761385917663, \"step\": 406500}\n",
      "{\"learning_rate\": 3.348482389222529e-05, \"loss\": 1.469491433262825, \"step\": 407000}\n",
      "{\"learning_rate\": 3.3464534978087976e-05, \"loss\": 1.4901938352584838, \"step\": 407500}\n",
      "{\"learning_rate\": 3.3444246063950655e-05, \"loss\": 1.4726880601644516, \"step\": 408000}\n",
      "{\"learning_rate\": 3.342395714981335e-05, \"loss\": 1.4907383030653, \"step\": 408500}\n",
      "{\"learning_rate\": 3.340366823567603e-05, \"loss\": 1.5019365737438202, \"step\": 409000}\n",
      "{\"learning_rate\": 3.338337932153871e-05, \"loss\": 1.4761661101579666, \"step\": 409500}\n",
      "{\"learning_rate\": 3.33630904074014e-05, \"loss\": 1.4695017963647843, \"step\": 410000}\n",
      "{\"learning_rate\": 3.334280149326408e-05, \"loss\": 1.4581447582244873, \"step\": 410500}\n",
      "{\"learning_rate\": 3.332251257912677e-05, \"loss\": 1.4621891897916794, \"step\": 411000}\n",
      "{\"learning_rate\": 3.330222366498945e-05, \"loss\": 1.4487464168071746, \"step\": 411500}\n",
      "{\"learning_rate\": 3.3281934750852136e-05, \"loss\": 1.4943651822805404, \"step\": 412000}\n",
      "{\"learning_rate\": 3.326164583671482e-05, \"loss\": 1.4798861478567122, \"step\": 412500}\n",
      "{\"learning_rate\": 3.32413569225775e-05, \"loss\": 1.4738721985816956, \"step\": 413000}\n",
      "{\"learning_rate\": 3.3221068008440194e-05, \"loss\": 1.4485073453187942, \"step\": 413500}\n",
      "{\"learning_rate\": 3.320077909430287e-05, \"loss\": 1.4707210783958435, \"step\": 414000}\n",
      "{\"learning_rate\": 3.318049018016556e-05, \"loss\": 1.4508691091537476, \"step\": 414500}\n",
      "{\"learning_rate\": 3.3160201266028245e-05, \"loss\": 1.4781197687387466, \"step\": 415000}\n",
      "{\"learning_rate\": 3.313991235189093e-05, \"loss\": 1.4630220501422881, \"step\": 415500}\n",
      "{\"learning_rate\": 3.311962343775361e-05, \"loss\": 1.4662421562671661, \"step\": 416000}\n",
      "{\"learning_rate\": 3.3099334523616296e-05, \"loss\": 1.4839594110250474, \"step\": 416500}\n",
      "{\"learning_rate\": 3.307904560947898e-05, \"loss\": 1.4685249843597412, \"step\": 417000}\n",
      "{\"learning_rate\": 3.305875669534167e-05, \"loss\": 1.476448518395424, \"step\": 417500}\n",
      "{\"learning_rate\": 3.3038467781204354e-05, \"loss\": 1.4784900258779525, \"step\": 418000}\n",
      "{\"learning_rate\": 3.301817886706703e-05, \"loss\": 1.4866258013248443, \"step\": 418500}\n",
      "{\"learning_rate\": 3.2997889952929726e-05, \"loss\": 1.480994376897812, \"step\": 419000}\n",
      "{\"learning_rate\": 3.2977601038792405e-05, \"loss\": 1.46301651763916, \"step\": 419500}\n",
      "{\"learning_rate\": 3.295731212465509e-05, \"loss\": 1.477360387444496, \"step\": 420000}\n",
      "{\"learning_rate\": 3.293702321051778e-05, \"loss\": 1.47492049741745, \"step\": 420500}\n",
      "{\"learning_rate\": 3.2916734296380456e-05, \"loss\": 1.4473666129112244, \"step\": 421000}\n",
      "{\"learning_rate\": 3.289644538224315e-05, \"loss\": 1.4764361197948457, \"step\": 421500}\n",
      "{\"learning_rate\": 3.287615646810583e-05, \"loss\": 1.4740095471143722, \"step\": 422000}\n",
      "{\"learning_rate\": 3.2855867553968514e-05, \"loss\": 1.4355576075315475, \"step\": 422500}\n",
      "{\"learning_rate\": 3.28355786398312e-05, \"loss\": 1.4694563487172128, \"step\": 423000}\n",
      "{\"learning_rate\": 3.281528972569388e-05, \"loss\": 1.4726529035568237, \"step\": 423500}\n",
      "{\"learning_rate\": 3.2795000811556565e-05, \"loss\": 1.4983488047122955, \"step\": 424000}\n",
      "{\"learning_rate\": 3.277471189741925e-05, \"loss\": 1.459159064412117, \"step\": 424500}\n",
      "{\"learning_rate\": 3.275442298328194e-05, \"loss\": 1.4580435914993286, \"step\": 425000}\n",
      "{\"learning_rate\": 3.273413406914462e-05, \"loss\": 1.4544820011854172, \"step\": 425500}\n",
      "{\"learning_rate\": 3.271384515500731e-05, \"loss\": 1.4737331891059875, \"step\": 426000}\n",
      "{\"learning_rate\": 3.269355624086999e-05, \"loss\": 1.4822842614650726, \"step\": 426500}\n",
      "{\"learning_rate\": 3.2673267326732674e-05, \"loss\": 1.4668017513751983, \"step\": 427000}\n",
      "{\"learning_rate\": 3.265297841259536e-05, \"loss\": 1.4548533214330672, \"step\": 427500}\n",
      "{\"learning_rate\": 3.2632689498458046e-05, \"loss\": 1.4756912118196488, \"step\": 428000}\n",
      "{\"learning_rate\": 3.261240058432073e-05, \"loss\": 1.4451995706558227, \"step\": 428500}\n",
      "{\"learning_rate\": 3.259211167018341e-05, \"loss\": 1.4617337877750396, \"step\": 429000}\n",
      "{\"learning_rate\": 3.25718227560461e-05, \"loss\": 1.435985286951065, \"step\": 429500}\n",
      "{\"learning_rate\": 3.255153384190878e-05, \"loss\": 1.4615327695608138, \"step\": 430000}\n",
      "{\"learning_rate\": 3.253124492777146e-05, \"loss\": 1.4875948853492738, \"step\": 430500}\n",
      "{\"learning_rate\": 3.2510956013634155e-05, \"loss\": 1.4424913746118546, \"step\": 431000}\n",
      "{\"learning_rate\": 3.2490667099496834e-05, \"loss\": 1.4606070747375488, \"step\": 431500}\n",
      "{\"learning_rate\": 3.2470378185359526e-05, \"loss\": 1.4746787852048875, \"step\": 432000}\n",
      "{\"learning_rate\": 3.2450089271222206e-05, \"loss\": 1.4726973295211792, \"step\": 432500}\n",
      "{\"learning_rate\": 3.242980035708489e-05, \"loss\": 1.4583780815601348, \"step\": 433000}\n",
      "{\"learning_rate\": 3.240951144294758e-05, \"loss\": 1.470848217010498, \"step\": 433500}\n",
      "{\"learning_rate\": 3.238922252881026e-05, \"loss\": 1.4712996212244034, \"step\": 434000}\n",
      "{\"learning_rate\": 3.236893361467294e-05, \"loss\": 1.4694896434545517, \"step\": 434500}\n",
      "{\"learning_rate\": 3.234864470053563e-05, \"loss\": 1.433913927793503, \"step\": 435000}\n",
      "{\"learning_rate\": 3.2328355786398315e-05, \"loss\": 1.492257611989975, \"step\": 435500}\n",
      "{\"learning_rate\": 3.2308066872261e-05, \"loss\": 1.4387293938398362, \"step\": 436000}\n",
      "{\"learning_rate\": 3.228777795812368e-05, \"loss\": 1.4663665834665298, \"step\": 436500}\n",
      "{\"learning_rate\": 3.2267489043986366e-05, \"loss\": 1.4566473677158356, \"step\": 437000}\n",
      "{\"learning_rate\": 3.224720012984905e-05, \"loss\": 1.4621886090040206, \"step\": 437500}\n",
      "{\"learning_rate\": 3.222691121571174e-05, \"loss\": 1.461952872633934, \"step\": 438000}\n",
      "{\"learning_rate\": 3.2206622301574423e-05, \"loss\": 1.4523759301900863, \"step\": 438500}\n",
      "{\"learning_rate\": 3.218633338743711e-05, \"loss\": 1.4609225025177002, \"step\": 439000}\n",
      "{\"learning_rate\": 3.216604447329979e-05, \"loss\": 1.4507012668848038, \"step\": 439500}\n",
      "{\"learning_rate\": 3.2145755559162474e-05, \"loss\": 1.4732236906290055, \"step\": 440000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 3.212546664502516e-05, \"loss\": 1.4487463830709457, \"step\": 440500}\n",
      "{\"learning_rate\": 3.210517773088784e-05, \"loss\": 1.4592644022703172, \"step\": 441000}\n",
      "{\"learning_rate\": 3.208488881675053e-05, \"loss\": 1.4848800472021102, \"step\": 441500}\n",
      "{\"learning_rate\": 3.206459990261321e-05, \"loss\": 1.4751463032960892, \"step\": 442000}\n",
      "{\"learning_rate\": 3.20443109884759e-05, \"loss\": 1.4393612760305405, \"step\": 442500}\n",
      "{\"learning_rate\": 3.202402207433858e-05, \"loss\": 1.4588327634334564, \"step\": 443000}\n",
      "{\"learning_rate\": 3.200373316020126e-05, \"loss\": 1.435251164317131, \"step\": 443500}\n",
      "{\"learning_rate\": 3.1983444246063955e-05, \"loss\": 1.462027539253235, \"step\": 444000}\n",
      "{\"learning_rate\": 3.1963155331926634e-05, \"loss\": 1.4450304403305054, \"step\": 444500}\n",
      "{\"learning_rate\": 3.194286641778932e-05, \"loss\": 1.4614441318511964, \"step\": 445000}\n",
      "{\"learning_rate\": 3.1922577503652006e-05, \"loss\": 1.4763686267137528, \"step\": 445500}\n",
      "{\"learning_rate\": 3.190228858951469e-05, \"loss\": 1.4769953819513322, \"step\": 446000}\n",
      "{\"learning_rate\": 3.188199967537738e-05, \"loss\": 1.4913998855352402, \"step\": 446500}\n",
      "{\"learning_rate\": 3.186171076124006e-05, \"loss\": 1.4536059066057205, \"step\": 447000}\n",
      "{\"learning_rate\": 3.184142184710274e-05, \"loss\": 1.4565108915567397, \"step\": 447500}\n",
      "{\"learning_rate\": 3.182113293296543e-05, \"loss\": 1.4603998976945878, \"step\": 448000}\n",
      "{\"learning_rate\": 3.1800844018828115e-05, \"loss\": 1.4348136751651763, \"step\": 448500}\n",
      "{\"learning_rate\": 3.17805551046908e-05, \"loss\": 1.4558235691785812, \"step\": 449000}\n",
      "{\"learning_rate\": 3.176026619055349e-05, \"loss\": 1.4668128039240838, \"step\": 449500}\n",
      "{\"learning_rate\": 3.1739977276416166e-05, \"loss\": 1.4483826006650924, \"step\": 450000}\n",
      "{\"learning_rate\": 3.171968836227885e-05, \"loss\": 1.4447260066270828, \"step\": 450500}\n",
      "{\"learning_rate\": 3.169939944814154e-05, \"loss\": 1.4592457891106605, \"step\": 451000}\n",
      "{\"learning_rate\": 3.167911053400422e-05, \"loss\": 1.4482093222141266, \"step\": 451500}\n",
      "{\"learning_rate\": 3.165882161986691e-05, \"loss\": 1.45663909137249, \"step\": 452000}\n",
      "{\"learning_rate\": 3.163853270572959e-05, \"loss\": 1.447455674290657, \"step\": 452500}\n",
      "{\"learning_rate\": 3.1618243791592275e-05, \"loss\": 1.4707394520044326, \"step\": 453000}\n",
      "{\"learning_rate\": 3.159795487745496e-05, \"loss\": 1.4741863729953766, \"step\": 453500}\n",
      "{\"learning_rate\": 3.157766596331764e-05, \"loss\": 1.4599999722242356, \"step\": 454000}\n",
      "{\"learning_rate\": 3.155737704918033e-05, \"loss\": 1.455726802110672, \"step\": 454500}\n",
      "{\"learning_rate\": 3.153708813504301e-05, \"loss\": 1.4743987286090852, \"step\": 455000}\n",
      "{\"learning_rate\": 3.15167992209057e-05, \"loss\": 1.4512639601230621, \"step\": 455500}\n",
      "{\"learning_rate\": 3.1496510306768384e-05, \"loss\": 1.4373361452817917, \"step\": 456000}\n",
      "{\"learning_rate\": 3.147622139263107e-05, \"loss\": 1.457540102481842, \"step\": 456500}\n",
      "{\"learning_rate\": 3.1455932478493756e-05, \"loss\": 1.4512368965148925, \"step\": 457000}\n",
      "{\"learning_rate\": 3.1435643564356435e-05, \"loss\": 1.4356101802587509, \"step\": 457500}\n",
      "{\"learning_rate\": 3.141535465021912e-05, \"loss\": 1.4511375485658646, \"step\": 458000}\n",
      "{\"learning_rate\": 3.139506573608181e-05, \"loss\": 1.4669327456951142, \"step\": 458500}\n",
      "{\"learning_rate\": 3.137477682194449e-05, \"loss\": 1.4464039251804353, \"step\": 459000}\n",
      "{\"learning_rate\": 3.135448790780717e-05, \"loss\": 1.455642423391342, \"step\": 459500}\n",
      "{\"learning_rate\": 3.133419899366986e-05, \"loss\": 1.4643020181655884, \"step\": 460000}\n",
      "{\"learning_rate\": 3.1313910079532544e-05, \"loss\": 1.4747737259864808, \"step\": 460500}\n",
      "{\"learning_rate\": 3.129362116539523e-05, \"loss\": 1.457320062994957, \"step\": 461000}\n",
      "{\"learning_rate\": 3.1273332251257916e-05, \"loss\": 1.4466693850755692, \"step\": 461500}\n",
      "{\"learning_rate\": 3.1253043337120595e-05, \"loss\": 1.4632213430404664, \"step\": 462000}\n",
      "{\"learning_rate\": 3.123275442298329e-05, \"loss\": 1.4409723719358445, \"step\": 462500}\n",
      "{\"learning_rate\": 3.121246550884597e-05, \"loss\": 1.427120041489601, \"step\": 463000}\n",
      "{\"learning_rate\": 3.119217659470865e-05, \"loss\": 1.433977097272873, \"step\": 463500}\n",
      "{\"learning_rate\": 3.117188768057134e-05, \"loss\": 1.4538076103925706, \"step\": 464000}\n",
      "{\"learning_rate\": 3.115159876643402e-05, \"loss\": 1.4511994498968124, \"step\": 464500}\n",
      "{\"learning_rate\": 3.113130985229671e-05, \"loss\": 1.4406803294420243, \"step\": 465000}\n",
      "{\"learning_rate\": 3.111102093815939e-05, \"loss\": 1.4670153642892838, \"step\": 465500}\n",
      "{\"learning_rate\": 3.1090732024022076e-05, \"loss\": 1.469901229262352, \"step\": 466000}\n",
      "{\"learning_rate\": 3.107044310988476e-05, \"loss\": 1.4704043658971786, \"step\": 466500}\n",
      "{\"learning_rate\": 3.105015419574744e-05, \"loss\": 1.4497500981092453, \"step\": 467000}\n",
      "{\"learning_rate\": 3.1029865281610134e-05, \"loss\": 1.4421045190095902, \"step\": 467500}\n",
      "{\"learning_rate\": 3.100957636747281e-05, \"loss\": 1.4465869551897048, \"step\": 468000}\n",
      "{\"learning_rate\": 3.09892874533355e-05, \"loss\": 1.4579519139528274, \"step\": 468500}\n",
      "{\"learning_rate\": 3.0968998539198185e-05, \"loss\": 1.4323601719141006, \"step\": 469000}\n",
      "{\"learning_rate\": 3.094870962506087e-05, \"loss\": 1.4649575711488725, \"step\": 469500}\n",
      "{\"learning_rate\": 3.092842071092355e-05, \"loss\": 1.4296358538866043, \"step\": 470000}\n",
      "{\"learning_rate\": 3.0908131796786236e-05, \"loss\": 1.422958427786827, \"step\": 470500}\n",
      "{\"learning_rate\": 3.088784288264892e-05, \"loss\": 1.4783249069452287, \"step\": 471000}\n",
      "{\"learning_rate\": 3.086755396851161e-05, \"loss\": 1.4479212176799774, \"step\": 471500}\n",
      "{\"learning_rate\": 3.0847265054374294e-05, \"loss\": 1.4362038877010346, \"step\": 472000}\n",
      "{\"learning_rate\": 3.082697614023697e-05, \"loss\": 1.4398934171199798, \"step\": 472500}\n",
      "{\"learning_rate\": 3.080668722609966e-05, \"loss\": 1.4646212238073348, \"step\": 473000}\n",
      "{\"learning_rate\": 3.0786398311962345e-05, \"loss\": 1.436707507610321, \"step\": 473500}\n",
      "{\"learning_rate\": 3.076610939782503e-05, \"loss\": 1.47190134704113, \"step\": 474000}\n",
      "{\"learning_rate\": 3.0745820483687717e-05, \"loss\": 1.4219900178909302, \"step\": 474500}\n",
      "{\"learning_rate\": 3.0725531569550396e-05, \"loss\": 1.4371511017084122, \"step\": 475000}\n",
      "{\"learning_rate\": 3.070524265541309e-05, \"loss\": 1.443091968178749, \"step\": 475500}\n",
      "{\"learning_rate\": 3.068495374127577e-05, \"loss\": 1.431089903831482, \"step\": 476000}\n",
      "{\"learning_rate\": 3.0664664827138454e-05, \"loss\": 1.4755286415815354, \"step\": 476500}\n",
      "{\"learning_rate\": 3.064437591300114e-05, \"loss\": 1.4205240384340285, \"step\": 477000}\n",
      "{\"learning_rate\": 3.062408699886382e-05, \"loss\": 1.4531195585727692, \"step\": 477500}\n",
      "{\"learning_rate\": 3.060379808472651e-05, \"loss\": 1.4749127095937729, \"step\": 478000}\n",
      "{\"learning_rate\": 3.058350917058919e-05, \"loss\": 1.4443568196296692, \"step\": 478500}\n",
      "{\"learning_rate\": 3.0563220256451876e-05, \"loss\": 1.4505929613113404, \"step\": 479000}\n",
      "{\"learning_rate\": 3.054293134231456e-05, \"loss\": 1.4453915461301803, \"step\": 479500}\n",
      "{\"learning_rate\": 3.052264242817724e-05, \"loss\": 1.4429882913827896, \"step\": 480000}\n",
      "{\"learning_rate\": 3.0502353514039928e-05, \"loss\": 1.454002496957779, \"step\": 480500}\n",
      "{\"learning_rate\": 3.0482064599902617e-05, \"loss\": 1.4486901491880417, \"step\": 481000}\n",
      "{\"learning_rate\": 3.04617756857653e-05, \"loss\": 1.4455783069133759, \"step\": 481500}\n",
      "{\"learning_rate\": 3.0441486771627985e-05, \"loss\": 1.4739484306573867, \"step\": 482000}\n",
      "{\"learning_rate\": 3.0421197857490668e-05, \"loss\": 1.4429629414081573, \"step\": 482500}\n",
      "{\"learning_rate\": 3.040090894335335e-05, \"loss\": 1.449945869922638, \"step\": 483000}\n",
      "{\"learning_rate\": 3.038062002921604e-05, \"loss\": 1.4580831751823424, \"step\": 483500}\n",
      "{\"learning_rate\": 3.0360331115078722e-05, \"loss\": 1.4527399226427078, \"step\": 484000}\n",
      "{\"learning_rate\": 3.034004220094141e-05, \"loss\": 1.464985164999962, \"step\": 484500}\n",
      "{\"learning_rate\": 3.031975328680409e-05, \"loss\": 1.446227240920067, \"step\": 485000}\n",
      "{\"learning_rate\": 3.0299464372666773e-05, \"loss\": 1.4518829486370086, \"step\": 485500}\n",
      "{\"learning_rate\": 3.0279175458529463e-05, \"loss\": 1.4662869396209717, \"step\": 486000}\n",
      "{\"learning_rate\": 3.0258886544392145e-05, \"loss\": 1.4415484594106673, \"step\": 486500}\n",
      "{\"learning_rate\": 3.0238597630254828e-05, \"loss\": 1.4436043285131455, \"step\": 487000}\n",
      "{\"learning_rate\": 3.0218308716117517e-05, \"loss\": 1.4656231464147569, \"step\": 487500}\n",
      "{\"learning_rate\": 3.01980198019802e-05, \"loss\": 1.449625585794449, \"step\": 488000}\n",
      "{\"learning_rate\": 3.0177730887842886e-05, \"loss\": 1.4632505074739457, \"step\": 488500}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 3.0157441973705568e-05, \"loss\": 1.4520417665243148, \"step\": 489000}\n",
      "{\"learning_rate\": 3.013715305956825e-05, \"loss\": 1.4402511203289032, \"step\": 489500}\n",
      "{\"learning_rate\": 3.011686414543094e-05, \"loss\": 1.4508647820949554, \"step\": 490000}\n",
      "{\"learning_rate\": 3.0096575231293623e-05, \"loss\": 1.4774880388975142, \"step\": 490500}\n",
      "{\"learning_rate\": 3.0076286317156305e-05, \"loss\": 1.4361363503932953, \"step\": 491000}\n",
      "{\"learning_rate\": 3.005599740301899e-05, \"loss\": 1.4335335114002228, \"step\": 491500}\n",
      "{\"learning_rate\": 3.0035708488881674e-05, \"loss\": 1.387437010884285, \"step\": 492000}\n",
      "{\"learning_rate\": 3.0015419574744363e-05, \"loss\": 1.4704072333574294, \"step\": 492500}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40cca432df824621bef83a8a872219cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=246440.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 2.9995130660607046e-05, \"loss\": 1.4187353028655052, \"step\": 493000}\n",
      "{\"learning_rate\": 2.9974841746469728e-05, \"loss\": 1.4357689129710198, \"step\": 493500}\n",
      "{\"learning_rate\": 2.9954552832332418e-05, \"loss\": 1.4401490358114242, \"step\": 494000}\n",
      "{\"learning_rate\": 2.99342639181951e-05, \"loss\": 1.4251235044002533, \"step\": 494500}\n",
      "{\"learning_rate\": 2.9913975004057783e-05, \"loss\": 1.4508706914186478, \"step\": 495000}\n",
      "{\"learning_rate\": 2.989368608992047e-05, \"loss\": 1.4584126826524735, \"step\": 495500}\n",
      "{\"learning_rate\": 2.987339717578315e-05, \"loss\": 1.4426148283481597, \"step\": 496000}\n",
      "{\"learning_rate\": 2.985310826164584e-05, \"loss\": 1.4342023227214813, \"step\": 496500}\n",
      "{\"learning_rate\": 2.9832819347508523e-05, \"loss\": 1.4338972841501236, \"step\": 497000}\n",
      "{\"learning_rate\": 2.9812530433371206e-05, \"loss\": 1.4429015947580337, \"step\": 497500}\n",
      "{\"learning_rate\": 2.9792241519233895e-05, \"loss\": 1.4313430364131927, \"step\": 498000}\n",
      "{\"learning_rate\": 2.9771952605096577e-05, \"loss\": 1.4175987964868546, \"step\": 498500}\n",
      "{\"learning_rate\": 2.9751663690959263e-05, \"loss\": 1.4387771273851395, \"step\": 499000}\n",
      "{\"learning_rate\": 2.9731374776821946e-05, \"loss\": 1.4420399534702302, \"step\": 499500}\n",
      "{\"learning_rate\": 2.971108586268463e-05, \"loss\": 1.4322218644618987, \"step\": 500000}\n",
      "{\"learning_rate\": 2.9690796948547318e-05, \"loss\": 1.42985258936882, \"step\": 500500}\n",
      "{\"learning_rate\": 2.967050803441e-05, \"loss\": 1.4308374276161193, \"step\": 501000}\n",
      "{\"learning_rate\": 2.9650219120272683e-05, \"loss\": 1.4179227899312974, \"step\": 501500}\n",
      "{\"learning_rate\": 2.962993020613537e-05, \"loss\": 1.4133334894180298, \"step\": 502000}\n",
      "{\"learning_rate\": 2.960964129199805e-05, \"loss\": 1.4433920410871506, \"step\": 502500}\n",
      "{\"learning_rate\": 2.958935237786074e-05, \"loss\": 1.4339739377498626, \"step\": 503000}\n",
      "{\"learning_rate\": 2.9569063463723423e-05, \"loss\": 1.431855961561203, \"step\": 503500}\n",
      "{\"learning_rate\": 2.9548774549586106e-05, \"loss\": 1.425466141462326, \"step\": 504000}\n",
      "{\"learning_rate\": 2.9528485635448795e-05, \"loss\": 1.4279147901535034, \"step\": 504500}\n",
      "{\"learning_rate\": 2.9508196721311478e-05, \"loss\": 1.401564714193344, \"step\": 505000}\n",
      "{\"learning_rate\": 2.948790780717416e-05, \"loss\": 1.4501234335899353, \"step\": 505500}\n",
      "{\"learning_rate\": 2.9467618893036846e-05, \"loss\": 1.4247903410196305, \"step\": 506000}\n",
      "{\"learning_rate\": 2.944732997889953e-05, \"loss\": 1.4230669758319854, \"step\": 506500}\n",
      "{\"learning_rate\": 2.9427041064762218e-05, \"loss\": 1.4106621046066283, \"step\": 507000}\n",
      "{\"learning_rate\": 2.94067521506249e-05, \"loss\": 1.4043503749370574, \"step\": 507500}\n",
      "{\"learning_rate\": 2.9386463236487583e-05, \"loss\": 1.4311844499111175, \"step\": 508000}\n",
      "{\"learning_rate\": 2.936617432235027e-05, \"loss\": 1.4209174654483796, \"step\": 508500}\n",
      "{\"learning_rate\": 2.9345885408212952e-05, \"loss\": 1.4422505320310592, \"step\": 509000}\n",
      "{\"learning_rate\": 2.932559649407564e-05, \"loss\": 1.4071676617860793, \"step\": 509500}\n",
      "{\"learning_rate\": 2.9305307579938324e-05, \"loss\": 1.440620214819908, \"step\": 510000}\n",
      "{\"learning_rate\": 2.9285018665801006e-05, \"loss\": 1.4136231900453569, \"step\": 510500}\n",
      "{\"learning_rate\": 2.9264729751663696e-05, \"loss\": 1.40738827252388, \"step\": 511000}\n",
      "{\"learning_rate\": 2.9244440837526378e-05, \"loss\": 1.4122252533435822, \"step\": 511500}\n",
      "{\"learning_rate\": 2.922415192338906e-05, \"loss\": 1.450151178598404, \"step\": 512000}\n",
      "{\"learning_rate\": 2.9203863009251747e-05, \"loss\": 1.4353246225118637, \"step\": 512500}\n",
      "{\"learning_rate\": 2.918357409511443e-05, \"loss\": 1.4375692366361619, \"step\": 513000}\n",
      "{\"learning_rate\": 2.916328518097712e-05, \"loss\": 1.4304841051101684, \"step\": 513500}\n",
      "{\"learning_rate\": 2.91429962668398e-05, \"loss\": 1.438370835661888, \"step\": 514000}\n",
      "{\"learning_rate\": 2.9122707352702484e-05, \"loss\": 1.411504573583603, \"step\": 514500}\n",
      "{\"learning_rate\": 2.910241843856517e-05, \"loss\": 1.4242331886291504, \"step\": 515000}\n",
      "{\"learning_rate\": 2.9082129524427852e-05, \"loss\": 1.4099750055074691, \"step\": 515500}\n",
      "{\"learning_rate\": 2.9061840610290535e-05, \"loss\": 1.4343320180177688, \"step\": 516000}\n",
      "{\"learning_rate\": 2.9041551696153224e-05, \"loss\": 1.427628213763237, \"step\": 516500}\n",
      "{\"learning_rate\": 2.9021262782015907e-05, \"loss\": 1.4344898165464401, \"step\": 517000}\n",
      "{\"learning_rate\": 2.9000973867878596e-05, \"loss\": 1.4620633573532105, \"step\": 517500}\n",
      "{\"learning_rate\": 2.898068495374128e-05, \"loss\": 1.419097025513649, \"step\": 518000}\n",
      "{\"learning_rate\": 2.896039603960396e-05, \"loss\": 1.413221314907074, \"step\": 518500}\n",
      "{\"learning_rate\": 2.8940107125466647e-05, \"loss\": 1.4130699909925462, \"step\": 519000}\n",
      "{\"learning_rate\": 2.891981821132933e-05, \"loss\": 1.4152497336864471, \"step\": 519500}\n",
      "{\"learning_rate\": 2.889952929719202e-05, \"loss\": 1.4094536374807358, \"step\": 520000}\n",
      "{\"learning_rate\": 2.88792403830547e-05, \"loss\": 1.4282463507652283, \"step\": 520500}\n",
      "{\"learning_rate\": 2.8858951468917384e-05, \"loss\": 1.4105515494346619, \"step\": 521000}\n",
      "{\"learning_rate\": 2.883866255478007e-05, \"loss\": 1.3884831687211991, \"step\": 521500}\n",
      "{\"learning_rate\": 2.8818373640642752e-05, \"loss\": 1.4103086676597596, \"step\": 522000}\n",
      "{\"learning_rate\": 2.8798084726505435e-05, \"loss\": 1.4323009071350097, \"step\": 522500}\n",
      "{\"learning_rate\": 2.8777795812368124e-05, \"loss\": 1.4157378668785094, \"step\": 523000}\n",
      "{\"learning_rate\": 2.8757506898230807e-05, \"loss\": 1.4287503561973571, \"step\": 523500}\n",
      "{\"learning_rate\": 2.8737217984093496e-05, \"loss\": 1.4323881019353866, \"step\": 524000}\n",
      "{\"learning_rate\": 2.871692906995618e-05, \"loss\": 1.4010436557531356, \"step\": 524500}\n",
      "{\"learning_rate\": 2.869664015581886e-05, \"loss\": 1.4464282835721969, \"step\": 525000}\n",
      "{\"learning_rate\": 2.8676351241681547e-05, \"loss\": 1.4120773704051972, \"step\": 525500}\n",
      "{\"learning_rate\": 2.865606232754423e-05, \"loss\": 1.4399269659519196, \"step\": 526000}\n",
      "{\"learning_rate\": 2.8635773413406912e-05, \"loss\": 1.4324958502054215, \"step\": 526500}\n",
      "{\"learning_rate\": 2.8615484499269602e-05, \"loss\": 1.4086990288496017, \"step\": 527000}\n",
      "{\"learning_rate\": 2.8595195585132284e-05, \"loss\": 1.4211007308363914, \"step\": 527500}\n",
      "{\"learning_rate\": 2.8574906670994974e-05, \"loss\": 1.4037811099290847, \"step\": 528000}\n",
      "{\"learning_rate\": 2.8554617756857653e-05, \"loss\": 1.4204893683195114, \"step\": 528500}\n",
      "{\"learning_rate\": 2.8534328842720335e-05, \"loss\": 1.3804465334415437, \"step\": 529000}\n",
      "{\"learning_rate\": 2.8514039928583025e-05, \"loss\": 1.4172375557422638, \"step\": 529500}\n",
      "{\"learning_rate\": 2.8493751014445707e-05, \"loss\": 1.4317117675542832, \"step\": 530000}\n",
      "{\"learning_rate\": 2.847346210030839e-05, \"loss\": 1.4316499630212784, \"step\": 530500}\n",
      "{\"learning_rate\": 2.845317318617108e-05, \"loss\": 1.4427196959257125, \"step\": 531000}\n",
      "{\"learning_rate\": 2.8432884272033762e-05, \"loss\": 1.413370696902275, \"step\": 531500}\n",
      "{\"learning_rate\": 2.8412595357896448e-05, \"loss\": 1.411054509997368, \"step\": 532000}\n",
      "{\"learning_rate\": 2.839230644375913e-05, \"loss\": 1.409896112203598, \"step\": 532500}\n",
      "{\"learning_rate\": 2.8372017529621813e-05, \"loss\": 1.4132856987714768, \"step\": 533000}\n",
      "{\"learning_rate\": 2.8351728615484502e-05, \"loss\": 1.4158524202108382, \"step\": 533500}\n",
      "{\"learning_rate\": 2.8331439701347185e-05, \"loss\": 1.4133450864553452, \"step\": 534000}\n",
      "{\"learning_rate\": 2.8311150787209874e-05, \"loss\": 1.41398645144701, \"step\": 534500}\n",
      "{\"learning_rate\": 2.8290861873072557e-05, \"loss\": 1.425962100982666, \"step\": 535000}\n",
      "{\"learning_rate\": 2.827057295893524e-05, \"loss\": 1.4060628728866578, \"step\": 535500}\n",
      "{\"learning_rate\": 2.8250284044797925e-05, \"loss\": 1.4223378283977508, \"step\": 536000}\n",
      "{\"learning_rate\": 2.8229995130660608e-05, \"loss\": 1.4055358358621597, \"step\": 536500}\n",
      "{\"learning_rate\": 2.820970621652329e-05, \"loss\": 1.4180859130620957, \"step\": 537000}\n",
      "{\"learning_rate\": 2.818941730238598e-05, \"loss\": 1.4299296132326127, \"step\": 537500}\n",
      "{\"learning_rate\": 2.8169128388248662e-05, \"loss\": 1.4028683762550354, \"step\": 538000}\n",
      "{\"learning_rate\": 2.8148839474111348e-05, \"loss\": 1.3951949605941771, \"step\": 538500}\n",
      "{\"learning_rate\": 2.812855055997403e-05, \"loss\": 1.4211323206424713, \"step\": 539000}\n",
      "{\"learning_rate\": 2.8108261645836713e-05, \"loss\": 1.4124416513442992, \"step\": 539500}\n",
      "{\"learning_rate\": 2.8087972731699402e-05, \"loss\": 1.422248195528984, \"step\": 540000}\n",
      "{\"learning_rate\": 2.8067683817562085e-05, \"loss\": 1.4211278855800629, \"step\": 540500}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 2.8047394903424768e-05, \"loss\": 1.4196793838739394, \"step\": 541000}\n",
      "{\"learning_rate\": 2.8027105989287457e-05, \"loss\": 1.429656055688858, \"step\": 541500}\n",
      "{\"learning_rate\": 2.800681707515014e-05, \"loss\": 1.4180287597179413, \"step\": 542000}\n",
      "{\"learning_rate\": 2.7986528161012825e-05, \"loss\": 1.40483101272583, \"step\": 542500}\n",
      "{\"learning_rate\": 2.7966239246875508e-05, \"loss\": 1.4368343467712403, \"step\": 543000}\n",
      "{\"learning_rate\": 2.794595033273819e-05, \"loss\": 1.4101314208507538, \"step\": 543500}\n",
      "{\"learning_rate\": 2.792566141860088e-05, \"loss\": 1.4334459022283554, \"step\": 544000}\n",
      "{\"learning_rate\": 2.7905372504463562e-05, \"loss\": 1.4426021975278855, \"step\": 544500}\n",
      "{\"learning_rate\": 2.788508359032625e-05, \"loss\": 1.4062258239984513, \"step\": 545000}\n",
      "{\"learning_rate\": 2.786479467618893e-05, \"loss\": 1.38975182056427, \"step\": 545500}\n",
      "{\"learning_rate\": 2.7844505762051613e-05, \"loss\": 1.4387222310304641, \"step\": 546000}\n",
      "{\"learning_rate\": 2.7824216847914303e-05, \"loss\": 1.4102762441635133, \"step\": 546500}\n",
      "{\"learning_rate\": 2.7803927933776985e-05, \"loss\": 1.4126790729165077, \"step\": 547000}\n",
      "{\"learning_rate\": 2.7783639019639668e-05, \"loss\": 1.4399286373853684, \"step\": 547500}\n",
      "{\"learning_rate\": 2.7763350105502357e-05, \"loss\": 1.4291884406805038, \"step\": 548000}\n",
      "{\"learning_rate\": 2.774306119136504e-05, \"loss\": 1.4149122846126556, \"step\": 548500}\n",
      "{\"learning_rate\": 2.7722772277227726e-05, \"loss\": 1.4069869375228883, \"step\": 549000}\n",
      "{\"learning_rate\": 2.7702483363090408e-05, \"loss\": 1.4108798880577087, \"step\": 549500}\n",
      "{\"learning_rate\": 2.768219444895309e-05, \"loss\": 1.4015134073495865, \"step\": 550000}\n",
      "{\"learning_rate\": 2.766190553481578e-05, \"loss\": 1.4069315382242202, \"step\": 550500}\n",
      "{\"learning_rate\": 2.7641616620678463e-05, \"loss\": 1.4162245308160781, \"step\": 551000}\n",
      "{\"learning_rate\": 2.7621327706541145e-05, \"loss\": 1.3979905413389206, \"step\": 551500}\n",
      "{\"learning_rate\": 2.760103879240383e-05, \"loss\": 1.4295711487531662, \"step\": 552000}\n",
      "{\"learning_rate\": 2.7580749878266514e-05, \"loss\": 1.4136525950431824, \"step\": 552500}\n",
      "{\"learning_rate\": 2.7560460964129203e-05, \"loss\": 1.421621836423874, \"step\": 553000}\n",
      "{\"learning_rate\": 2.7540172049991886e-05, \"loss\": 1.429540841817856, \"step\": 553500}\n",
      "{\"learning_rate\": 2.7519883135854568e-05, \"loss\": 1.4062635959386827, \"step\": 554000}\n",
      "{\"learning_rate\": 2.7499594221717258e-05, \"loss\": 1.4198551285266876, \"step\": 554500}\n",
      "{\"learning_rate\": 2.747930530757994e-05, \"loss\": 1.40728316116333, \"step\": 555000}\n",
      "{\"learning_rate\": 2.7459016393442626e-05, \"loss\": 1.404387005329132, \"step\": 555500}\n",
      "{\"learning_rate\": 2.743872747930531e-05, \"loss\": 1.4122361243963242, \"step\": 556000}\n",
      "{\"learning_rate\": 2.741843856516799e-05, \"loss\": 1.4426871461868287, \"step\": 556500}\n",
      "{\"learning_rate\": 2.739814965103068e-05, \"loss\": 1.4207522802352905, \"step\": 557000}\n",
      "{\"learning_rate\": 2.7377860736893363e-05, \"loss\": 1.4242911121845245, \"step\": 557500}\n",
      "{\"learning_rate\": 2.7357571822756046e-05, \"loss\": 1.4226215356588363, \"step\": 558000}\n",
      "{\"learning_rate\": 2.733728290861873e-05, \"loss\": 1.438754075407982, \"step\": 558500}\n",
      "{\"learning_rate\": 2.7316993994481414e-05, \"loss\": 1.4188430519104005, \"step\": 559000}\n",
      "{\"learning_rate\": 2.7296705080344103e-05, \"loss\": 1.4130069344043732, \"step\": 559500}\n",
      "{\"learning_rate\": 2.7276416166206786e-05, \"loss\": 1.4093005828857421, \"step\": 560000}\n",
      "{\"learning_rate\": 2.725612725206947e-05, \"loss\": 1.4131105464696885, \"step\": 560500}\n",
      "{\"learning_rate\": 2.7235838337932158e-05, \"loss\": 1.414050201177597, \"step\": 561000}\n",
      "{\"learning_rate\": 2.721554942379484e-05, \"loss\": 1.4097257826328278, \"step\": 561500}\n",
      "{\"learning_rate\": 2.7195260509657523e-05, \"loss\": 1.4110636104345322, \"step\": 562000}\n",
      "{\"learning_rate\": 2.717497159552021e-05, \"loss\": 1.4244347295761108, \"step\": 562500}\n",
      "{\"learning_rate\": 2.715468268138289e-05, \"loss\": 1.4039574930667877, \"step\": 563000}\n",
      "{\"learning_rate\": 2.713439376724558e-05, \"loss\": 1.4044861562252045, \"step\": 563500}\n",
      "{\"learning_rate\": 2.7114104853108263e-05, \"loss\": 1.4247960191965103, \"step\": 564000}\n",
      "{\"learning_rate\": 2.7093815938970946e-05, \"loss\": 1.4151793357729912, \"step\": 564500}\n",
      "{\"learning_rate\": 2.7073527024833635e-05, \"loss\": 1.4173783575296401, \"step\": 565000}\n",
      "{\"learning_rate\": 2.7053238110696318e-05, \"loss\": 1.4194028596878052, \"step\": 565500}\n",
      "{\"learning_rate\": 2.7032949196559e-05, \"loss\": 1.4021771758794785, \"step\": 566000}\n",
      "{\"learning_rate\": 2.7012660282421686e-05, \"loss\": 1.402904391169548, \"step\": 566500}\n",
      "{\"learning_rate\": 2.699237136828437e-05, \"loss\": 1.4068962174654007, \"step\": 567000}\n",
      "{\"learning_rate\": 2.6972082454147058e-05, \"loss\": 1.4281569043397904, \"step\": 567500}\n",
      "{\"learning_rate\": 2.695179354000974e-05, \"loss\": 1.4121934837698937, \"step\": 568000}\n",
      "{\"learning_rate\": 2.6931504625872423e-05, \"loss\": 1.3951473163962365, \"step\": 568500}\n",
      "{\"learning_rate\": 2.691121571173511e-05, \"loss\": 1.4093843706846236, \"step\": 569000}\n",
      "{\"learning_rate\": 2.6890926797597792e-05, \"loss\": 1.4315374596118926, \"step\": 569500}\n",
      "{\"learning_rate\": 2.687063788346048e-05, \"loss\": 1.4274106042385102, \"step\": 570000}\n",
      "{\"learning_rate\": 2.6850348969323164e-05, \"loss\": 1.4130374693870544, \"step\": 570500}\n",
      "{\"learning_rate\": 2.6830060055185846e-05, \"loss\": 1.3965860829353332, \"step\": 571000}\n",
      "{\"learning_rate\": 2.6809771141048536e-05, \"loss\": 1.3735442196130752, \"step\": 571500}\n",
      "{\"learning_rate\": 2.6789482226911218e-05, \"loss\": 1.4031027998924255, \"step\": 572000}\n",
      "{\"learning_rate\": 2.67691933127739e-05, \"loss\": 1.3965704593658448, \"step\": 572500}\n",
      "{\"learning_rate\": 2.6748904398636587e-05, \"loss\": 1.4100038713216783, \"step\": 573000}\n",
      "{\"learning_rate\": 2.672861548449927e-05, \"loss\": 1.406676933169365, \"step\": 573500}\n",
      "{\"learning_rate\": 2.670832657036196e-05, \"loss\": 1.42367679977417, \"step\": 574000}\n",
      "{\"learning_rate\": 2.668803765622464e-05, \"loss\": 1.4122018206119538, \"step\": 574500}\n",
      "{\"learning_rate\": 2.6667748742087324e-05, \"loss\": 1.4210733708143235, \"step\": 575000}\n",
      "{\"learning_rate\": 2.664745982795001e-05, \"loss\": 1.3900921425819397, \"step\": 575500}\n",
      "{\"learning_rate\": 2.6627170913812692e-05, \"loss\": 1.420874121069908, \"step\": 576000}\n",
      "{\"learning_rate\": 2.6606881999675375e-05, \"loss\": 1.4053850198984146, \"step\": 576500}\n",
      "{\"learning_rate\": 2.6586593085538064e-05, \"loss\": 1.424008554160595, \"step\": 577000}\n",
      "{\"learning_rate\": 2.6566304171400747e-05, \"loss\": 1.4004066889286042, \"step\": 577500}\n",
      "{\"learning_rate\": 2.6546015257263436e-05, \"loss\": 1.405763592004776, \"step\": 578000}\n",
      "{\"learning_rate\": 2.652572634312612e-05, \"loss\": 1.420264003276825, \"step\": 578500}\n",
      "{\"learning_rate\": 2.65054374289888e-05, \"loss\": 1.4242448259592055, \"step\": 579000}\n",
      "{\"learning_rate\": 2.6485148514851487e-05, \"loss\": 1.4183898038864136, \"step\": 579500}\n",
      "{\"learning_rate\": 2.646485960071417e-05, \"loss\": 1.4328201668262481, \"step\": 580000}\n",
      "{\"learning_rate\": 2.644457068657686e-05, \"loss\": 1.4051850616931916, \"step\": 580500}\n",
      "{\"learning_rate\": 2.642428177243954e-05, \"loss\": 1.4249384974241257, \"step\": 581000}\n",
      "{\"learning_rate\": 2.6403992858302224e-05, \"loss\": 1.4228106110095977, \"step\": 581500}\n",
      "{\"learning_rate\": 2.638370394416491e-05, \"loss\": 1.4006533752679824, \"step\": 582000}\n",
      "{\"learning_rate\": 2.6363415030027592e-05, \"loss\": 1.4103045885562897, \"step\": 582500}\n",
      "{\"learning_rate\": 2.6343126115890275e-05, \"loss\": 1.4156552368402482, \"step\": 583000}\n",
      "{\"learning_rate\": 2.6322837201752964e-05, \"loss\": 1.3972154824733733, \"step\": 583500}\n",
      "{\"learning_rate\": 2.6302548287615647e-05, \"loss\": 1.4118703595399857, \"step\": 584000}\n",
      "{\"learning_rate\": 2.6282259373478336e-05, \"loss\": 1.4127430946826935, \"step\": 584500}\n",
      "{\"learning_rate\": 2.626197045934102e-05, \"loss\": 1.4150645743608474, \"step\": 585000}\n",
      "{\"learning_rate\": 2.62416815452037e-05, \"loss\": 1.4114135705828668, \"step\": 585500}\n",
      "{\"learning_rate\": 2.6221392631066387e-05, \"loss\": 1.379413715839386, \"step\": 586000}\n",
      "{\"learning_rate\": 2.620110371692907e-05, \"loss\": 1.3945358749628067, \"step\": 586500}\n",
      "{\"learning_rate\": 2.6180814802791752e-05, \"loss\": 1.3760524611473084, \"step\": 587000}\n",
      "{\"learning_rate\": 2.6160525888654442e-05, \"loss\": 1.417673224210739, \"step\": 587500}\n",
      "{\"learning_rate\": 2.6140236974517124e-05, \"loss\": 1.390155410528183, \"step\": 588000}\n",
      "{\"learning_rate\": 2.611994806037981e-05, \"loss\": 1.4266456484794616, \"step\": 588500}\n",
      "{\"learning_rate\": 2.6099659146242493e-05, \"loss\": 1.4157143652439117, \"step\": 589000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 2.6079370232105175e-05, \"loss\": 1.4235679978132247, \"step\": 589500}\n",
      "{\"learning_rate\": 2.6059081317967865e-05, \"loss\": 1.423918808579445, \"step\": 590000}\n",
      "{\"learning_rate\": 2.6038792403830547e-05, \"loss\": 1.400764684319496, \"step\": 590500}\n",
      "{\"learning_rate\": 2.6018503489693237e-05, \"loss\": 1.3937043334245682, \"step\": 591000}\n",
      "{\"learning_rate\": 2.599821457555592e-05, \"loss\": 1.4108518929481506, \"step\": 591500}\n",
      "{\"learning_rate\": 2.5977925661418602e-05, \"loss\": 1.4238339796066284, \"step\": 592000}\n",
      "{\"learning_rate\": 2.5957636747281288e-05, \"loss\": 1.3929543142318725, \"step\": 592500}\n",
      "{\"learning_rate\": 2.593734783314397e-05, \"loss\": 1.4495368180274963, \"step\": 593000}\n",
      "{\"learning_rate\": 2.5917058919006653e-05, \"loss\": 1.422385253548622, \"step\": 593500}\n",
      "{\"learning_rate\": 2.5896770004869342e-05, \"loss\": 1.415796257853508, \"step\": 594000}\n",
      "{\"learning_rate\": 2.5876481090732025e-05, \"loss\": 1.3939064801931382, \"step\": 594500}\n",
      "{\"learning_rate\": 2.5856192176594714e-05, \"loss\": 1.3910545237064362, \"step\": 595000}\n",
      "{\"learning_rate\": 2.5835903262457397e-05, \"loss\": 1.406122461915016, \"step\": 595500}\n",
      "{\"learning_rate\": 2.581561434832008e-05, \"loss\": 1.4212162975072862, \"step\": 596000}\n",
      "{\"learning_rate\": 2.5795325434182765e-05, \"loss\": 1.401191284060478, \"step\": 596500}\n",
      "{\"learning_rate\": 2.5775036520045448e-05, \"loss\": 1.3881751317977906, \"step\": 597000}\n",
      "{\"learning_rate\": 2.575474760590813e-05, \"loss\": 1.4181077321767808, \"step\": 597500}\n",
      "{\"learning_rate\": 2.573445869177082e-05, \"loss\": 1.4126821594238281, \"step\": 598000}\n",
      "{\"learning_rate\": 2.5714169777633502e-05, \"loss\": 1.40466362118721, \"step\": 598500}\n",
      "{\"learning_rate\": 2.5693880863496188e-05, \"loss\": 1.4000464327335358, \"step\": 599000}\n",
      "{\"learning_rate\": 2.567359194935887e-05, \"loss\": 1.4120174901485443, \"step\": 599500}\n",
      "{\"learning_rate\": 2.5653303035221553e-05, \"loss\": 1.4043179714679719, \"step\": 600000}\n",
      "{\"learning_rate\": 2.5633014121084242e-05, \"loss\": 1.400249579191208, \"step\": 600500}\n",
      "{\"learning_rate\": 2.5612725206946925e-05, \"loss\": 1.3522665935754776, \"step\": 601000}\n",
      "{\"learning_rate\": 2.5592436292809608e-05, \"loss\": 1.4331367433071136, \"step\": 601500}\n",
      "{\"learning_rate\": 2.5572147378672297e-05, \"loss\": 1.4020761781930924, \"step\": 602000}\n",
      "{\"learning_rate\": 2.555185846453498e-05, \"loss\": 1.4210708594322206, \"step\": 602500}\n",
      "{\"learning_rate\": 2.5531569550397665e-05, \"loss\": 1.4068502805233, \"step\": 603000}\n",
      "{\"learning_rate\": 2.5511280636260348e-05, \"loss\": 1.4103406974077224, \"step\": 603500}\n",
      "{\"learning_rate\": 2.549099172212303e-05, \"loss\": 1.393931507408619, \"step\": 604000}\n",
      "{\"learning_rate\": 2.547070280798572e-05, \"loss\": 1.3801934387683867, \"step\": 604500}\n",
      "{\"learning_rate\": 2.5450413893848402e-05, \"loss\": 1.4100346237421035, \"step\": 605000}\n",
      "{\"learning_rate\": 2.543012497971109e-05, \"loss\": 1.3875394438505173, \"step\": 605500}\n",
      "{\"learning_rate\": 2.540983606557377e-05, \"loss\": 1.3869582505226135, \"step\": 606000}\n",
      "{\"learning_rate\": 2.5389547151436453e-05, \"loss\": 1.428262961626053, \"step\": 606500}\n",
      "{\"learning_rate\": 2.5369258237299143e-05, \"loss\": 1.4086311287879945, \"step\": 607000}\n",
      "{\"learning_rate\": 2.5348969323161825e-05, \"loss\": 1.3708480732440949, \"step\": 607500}\n",
      "{\"learning_rate\": 2.5328680409024508e-05, \"loss\": 1.378946390748024, \"step\": 608000}\n",
      "{\"learning_rate\": 2.5308391494887197e-05, \"loss\": 1.412055042028427, \"step\": 608500}\n",
      "{\"learning_rate\": 2.528810258074988e-05, \"loss\": 1.4114020919799806, \"step\": 609000}\n",
      "{\"learning_rate\": 2.5267813666612566e-05, \"loss\": 1.4022903697490692, \"step\": 609500}\n",
      "{\"learning_rate\": 2.5247524752475248e-05, \"loss\": 1.3907463192343712, \"step\": 610000}\n",
      "{\"learning_rate\": 2.522723583833793e-05, \"loss\": 1.4192880419492722, \"step\": 610500}\n",
      "{\"learning_rate\": 2.520694692420062e-05, \"loss\": 1.4206690394282342, \"step\": 611000}\n",
      "{\"learning_rate\": 2.5186658010063303e-05, \"loss\": 1.407245882511139, \"step\": 611500}\n",
      "{\"learning_rate\": 2.5166369095925985e-05, \"loss\": 1.3930261495113372, \"step\": 612000}\n",
      "{\"learning_rate\": 2.514608018178867e-05, \"loss\": 1.3934433031082154, \"step\": 612500}\n",
      "{\"learning_rate\": 2.5125791267651354e-05, \"loss\": 1.416324886918068, \"step\": 613000}\n",
      "{\"learning_rate\": 2.5105502353514043e-05, \"loss\": 1.4048293621540069, \"step\": 613500}\n",
      "{\"learning_rate\": 2.5085213439376726e-05, \"loss\": 1.4113107137680054, \"step\": 614000}\n",
      "{\"learning_rate\": 2.5064924525239408e-05, \"loss\": 1.3975459669828414, \"step\": 614500}\n",
      "{\"learning_rate\": 2.5044635611102098e-05, \"loss\": 1.3881091666221619, \"step\": 615000}\n",
      "{\"learning_rate\": 2.502434669696478e-05, \"loss\": 1.3950091180801392, \"step\": 615500}\n",
      "{\"learning_rate\": 2.5004057782827466e-05, \"loss\": 1.379660039305687, \"step\": 616000}\n",
      "{\"learning_rate\": 2.498376886869015e-05, \"loss\": 1.4003086228370667, \"step\": 616500}\n",
      "{\"learning_rate\": 2.4963479954552835e-05, \"loss\": 1.4121335335969925, \"step\": 617000}\n",
      "{\"learning_rate\": 2.4943191040415517e-05, \"loss\": 1.4101647766828538, \"step\": 617500}\n",
      "{\"learning_rate\": 2.4922902126278203e-05, \"loss\": 1.4182381855249404, \"step\": 618000}\n",
      "{\"learning_rate\": 2.490261321214089e-05, \"loss\": 1.3929075434207916, \"step\": 618500}\n",
      "{\"learning_rate\": 2.488232429800357e-05, \"loss\": 1.3934167767763137, \"step\": 619000}\n",
      "{\"learning_rate\": 2.4862035383866254e-05, \"loss\": 1.3941739809513092, \"step\": 619500}\n",
      "{\"learning_rate\": 2.484174646972894e-05, \"loss\": 1.4062564355134963, \"step\": 620000}\n",
      "{\"learning_rate\": 2.4821457555591626e-05, \"loss\": 1.3866409547328948, \"step\": 620500}\n",
      "{\"learning_rate\": 2.4801168641454312e-05, \"loss\": 1.386498158454895, \"step\": 621000}\n",
      "{\"learning_rate\": 2.4780879727316994e-05, \"loss\": 1.3845814245939254, \"step\": 621500}\n",
      "{\"learning_rate\": 2.476059081317968e-05, \"loss\": 1.4137337037324906, \"step\": 622000}\n",
      "{\"learning_rate\": 2.4740301899042363e-05, \"loss\": 1.422067403435707, \"step\": 622500}\n",
      "{\"learning_rate\": 2.472001298490505e-05, \"loss\": 1.4132672444581986, \"step\": 623000}\n",
      "{\"learning_rate\": 2.469972407076773e-05, \"loss\": 1.4019344826936722, \"step\": 623500}\n",
      "{\"learning_rate\": 2.4679435156630417e-05, \"loss\": 1.3795037660598755, \"step\": 624000}\n",
      "{\"learning_rate\": 2.4659146242493103e-05, \"loss\": 1.3813316329717635, \"step\": 624500}\n",
      "{\"learning_rate\": 2.463885732835579e-05, \"loss\": 1.382624788761139, \"step\": 625000}\n",
      "{\"learning_rate\": 2.4618568414218472e-05, \"loss\": 1.4047893981933595, \"step\": 625500}\n",
      "{\"learning_rate\": 2.4598279500081154e-05, \"loss\": 1.4085849388837814, \"step\": 626000}\n",
      "{\"learning_rate\": 2.457799058594384e-05, \"loss\": 1.3882756880521774, \"step\": 626500}\n",
      "{\"learning_rate\": 2.4557701671806526e-05, \"loss\": 1.3958735411167145, \"step\": 627000}\n",
      "{\"learning_rate\": 2.4537412757669212e-05, \"loss\": 1.4124154250621797, \"step\": 627500}\n",
      "{\"learning_rate\": 2.4517123843531895e-05, \"loss\": 1.3947936418056488, \"step\": 628000}\n",
      "{\"learning_rate\": 2.449683492939458e-05, \"loss\": 1.3933967663049698, \"step\": 628500}\n",
      "{\"learning_rate\": 2.4476546015257267e-05, \"loss\": 1.3868954077959061, \"step\": 629000}\n",
      "{\"learning_rate\": 2.445625710111995e-05, \"loss\": 1.387317702293396, \"step\": 629500}\n",
      "{\"learning_rate\": 2.4435968186982632e-05, \"loss\": 1.3653446151018143, \"step\": 630000}\n",
      "{\"learning_rate\": 2.4415679272845318e-05, \"loss\": 1.4066911945343017, \"step\": 630500}\n",
      "{\"learning_rate\": 2.4395390358708004e-05, \"loss\": 1.4068247958421707, \"step\": 631000}\n",
      "{\"learning_rate\": 2.437510144457069e-05, \"loss\": 1.3645278638601304, \"step\": 631500}\n",
      "{\"learning_rate\": 2.4354812530433372e-05, \"loss\": 1.4011681847572326, \"step\": 632000}\n",
      "{\"learning_rate\": 2.4334523616296058e-05, \"loss\": 1.402387251496315, \"step\": 632500}\n",
      "{\"learning_rate\": 2.431423470215874e-05, \"loss\": 1.386367782831192, \"step\": 633000}\n",
      "{\"learning_rate\": 2.4293945788021427e-05, \"loss\": 1.4153834266662597, \"step\": 633500}\n",
      "{\"learning_rate\": 2.427365687388411e-05, \"loss\": 1.3816714210510255, \"step\": 634000}\n",
      "{\"learning_rate\": 2.4253367959746795e-05, \"loss\": 1.38120057117939, \"step\": 634500}\n",
      "{\"learning_rate\": 2.423307904560948e-05, \"loss\": 1.409700012564659, \"step\": 635000}\n",
      "{\"learning_rate\": 2.4212790131472167e-05, \"loss\": 1.4285682270526885, \"step\": 635500}\n",
      "{\"learning_rate\": 2.419250121733485e-05, \"loss\": 1.3975205887556077, \"step\": 636000}\n",
      "{\"learning_rate\": 2.4172212303197532e-05, \"loss\": 1.3821627324819565, \"step\": 636500}\n",
      "{\"learning_rate\": 2.4151923389060218e-05, \"loss\": 1.3814034212827682, \"step\": 637000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 2.4131634474922904e-05, \"loss\": 1.3966151776313782, \"step\": 637500}\n",
      "{\"learning_rate\": 2.411134556078559e-05, \"loss\": 1.3808111408948898, \"step\": 638000}\n",
      "{\"learning_rate\": 2.4091056646648273e-05, \"loss\": 1.4130213742256164, \"step\": 638500}\n",
      "{\"learning_rate\": 2.407076773251096e-05, \"loss\": 1.3955873770713807, \"step\": 639000}\n",
      "{\"learning_rate\": 2.405047881837364e-05, \"loss\": 1.3763981648683548, \"step\": 639500}\n",
      "{\"learning_rate\": 2.4030189904236327e-05, \"loss\": 1.410669920027256, \"step\": 640000}\n",
      "{\"learning_rate\": 2.400990099009901e-05, \"loss\": 1.3749116407632829, \"step\": 640500}\n",
      "{\"learning_rate\": 2.3989612075961695e-05, \"loss\": 1.3950397911071777, \"step\": 641000}\n",
      "{\"learning_rate\": 2.396932316182438e-05, \"loss\": 1.3949546324014663, \"step\": 641500}\n",
      "{\"learning_rate\": 2.3949034247687067e-05, \"loss\": 1.3677165193557739, \"step\": 642000}\n",
      "{\"learning_rate\": 2.392874533354975e-05, \"loss\": 1.4090167031288148, \"step\": 642500}\n",
      "{\"learning_rate\": 2.3908456419412432e-05, \"loss\": 1.3807917561531067, \"step\": 643000}\n",
      "{\"learning_rate\": 2.388816750527512e-05, \"loss\": 1.383637887954712, \"step\": 643500}\n",
      "{\"learning_rate\": 2.3867878591137804e-05, \"loss\": 1.3865996661186217, \"step\": 644000}\n",
      "{\"learning_rate\": 2.3847589677000487e-05, \"loss\": 1.3700493355989456, \"step\": 644500}\n",
      "{\"learning_rate\": 2.3827300762863173e-05, \"loss\": 1.3910404226779938, \"step\": 645000}\n",
      "{\"learning_rate\": 2.380701184872586e-05, \"loss\": 1.395671532869339, \"step\": 645500}\n",
      "{\"learning_rate\": 2.378672293458854e-05, \"loss\": 1.3921895927190782, \"step\": 646000}\n",
      "{\"learning_rate\": 2.3766434020451224e-05, \"loss\": 1.3690537377595902, \"step\": 646500}\n",
      "{\"learning_rate\": 2.374614510631391e-05, \"loss\": 1.36386525285244, \"step\": 647000}\n",
      "{\"learning_rate\": 2.3725856192176596e-05, \"loss\": 1.3916795004606246, \"step\": 647500}\n",
      "{\"learning_rate\": 2.3705567278039282e-05, \"loss\": 1.3917993179559707, \"step\": 648000}\n",
      "{\"learning_rate\": 2.3685278363901964e-05, \"loss\": 1.3976186386942864, \"step\": 648500}\n",
      "{\"learning_rate\": 2.366498944976465e-05, \"loss\": 1.3928476189374923, \"step\": 649000}\n",
      "{\"learning_rate\": 2.3644700535627333e-05, \"loss\": 1.3860582515001296, \"step\": 649500}\n",
      "{\"learning_rate\": 2.362441162149002e-05, \"loss\": 1.3891895972490311, \"step\": 650000}\n",
      "{\"learning_rate\": 2.3604122707352705e-05, \"loss\": 1.3881759423017501, \"step\": 650500}\n",
      "{\"learning_rate\": 2.3583833793215387e-05, \"loss\": 1.3660936427116395, \"step\": 651000}\n",
      "{\"learning_rate\": 2.3563544879078073e-05, \"loss\": 1.3959279123544692, \"step\": 651500}\n",
      "{\"learning_rate\": 2.354325596494076e-05, \"loss\": 1.394971990585327, \"step\": 652000}\n",
      "{\"learning_rate\": 2.3522967050803442e-05, \"loss\": 1.3834964566230774, \"step\": 652500}\n",
      "{\"learning_rate\": 2.3502678136666124e-05, \"loss\": 1.380925805926323, \"step\": 653000}\n",
      "{\"learning_rate\": 2.348238922252881e-05, \"loss\": 1.4202949826717377, \"step\": 653500}\n",
      "{\"learning_rate\": 2.3462100308391496e-05, \"loss\": 1.38684567964077, \"step\": 654000}\n",
      "{\"learning_rate\": 2.3441811394254182e-05, \"loss\": 1.4041772488355637, \"step\": 654500}\n",
      "{\"learning_rate\": 2.3421522480116865e-05, \"loss\": 1.38392917406559, \"step\": 655000}\n",
      "{\"learning_rate\": 2.340123356597955e-05, \"loss\": 1.3809772436618806, \"step\": 655500}\n",
      "{\"learning_rate\": 2.3380944651842233e-05, \"loss\": 1.4020875313282013, \"step\": 656000}\n",
      "{\"learning_rate\": 2.336065573770492e-05, \"loss\": 1.3791664091348648, \"step\": 656500}\n",
      "{\"learning_rate\": 2.33403668235676e-05, \"loss\": 1.3740140240192413, \"step\": 657000}\n",
      "{\"learning_rate\": 2.3320077909430288e-05, \"loss\": 1.3948836908340454, \"step\": 657500}\n",
      "{\"learning_rate\": 2.3299788995292974e-05, \"loss\": 1.3786903964281083, \"step\": 658000}\n",
      "{\"learning_rate\": 2.327950008115566e-05, \"loss\": 1.3772097007036208, \"step\": 658500}\n",
      "{\"learning_rate\": 2.3259211167018342e-05, \"loss\": 1.4043431564569473, \"step\": 659000}\n",
      "{\"learning_rate\": 2.3238922252881028e-05, \"loss\": 1.3965469913482667, \"step\": 659500}\n",
      "{\"learning_rate\": 2.321863333874371e-05, \"loss\": 1.3803476098775864, \"step\": 660000}\n",
      "{\"learning_rate\": 2.3198344424606396e-05, \"loss\": 1.3703344311714172, \"step\": 660500}\n",
      "{\"learning_rate\": 2.3178055510469082e-05, \"loss\": 1.393793091773987, \"step\": 661000}\n",
      "{\"learning_rate\": 2.3157766596331765e-05, \"loss\": 1.4265367436408996, \"step\": 661500}\n",
      "{\"learning_rate\": 2.313747768219445e-05, \"loss\": 1.3997380197048188, \"step\": 662000}\n",
      "{\"learning_rate\": 2.3117188768057137e-05, \"loss\": 1.372659615278244, \"step\": 662500}\n",
      "{\"learning_rate\": 2.309689985391982e-05, \"loss\": 1.3958983300924301, \"step\": 663000}\n",
      "{\"learning_rate\": 2.3076610939782502e-05, \"loss\": 1.3805162561535835, \"step\": 663500}\n",
      "{\"learning_rate\": 2.3056322025645188e-05, \"loss\": 1.3584874402284621, \"step\": 664000}\n",
      "{\"learning_rate\": 2.3036033111507874e-05, \"loss\": 1.3984995832443237, \"step\": 664500}\n",
      "{\"learning_rate\": 2.301574419737056e-05, \"loss\": 1.3643845098018645, \"step\": 665000}\n",
      "{\"learning_rate\": 2.2995455283233242e-05, \"loss\": 1.4041718261837959, \"step\": 665500}\n",
      "{\"learning_rate\": 2.297516636909593e-05, \"loss\": 1.4019251157045365, \"step\": 666000}\n",
      "{\"learning_rate\": 2.295487745495861e-05, \"loss\": 1.3882006521224977, \"step\": 666500}\n",
      "{\"learning_rate\": 2.2934588540821297e-05, \"loss\": 1.379026518344879, \"step\": 667000}\n",
      "{\"learning_rate\": 2.291429962668398e-05, \"loss\": 1.394562892317772, \"step\": 667500}\n",
      "{\"learning_rate\": 2.2894010712546665e-05, \"loss\": 1.3614349899291993, \"step\": 668000}\n",
      "{\"learning_rate\": 2.287372179840935e-05, \"loss\": 1.3998137737512588, \"step\": 668500}\n",
      "{\"learning_rate\": 2.2853432884272037e-05, \"loss\": 1.3642800575494767, \"step\": 669000}\n",
      "{\"learning_rate\": 2.283314397013472e-05, \"loss\": 1.376633041381836, \"step\": 669500}\n",
      "{\"learning_rate\": 2.2812855055997402e-05, \"loss\": 1.3865667815208436, \"step\": 670000}\n",
      "{\"learning_rate\": 2.2792566141860088e-05, \"loss\": 1.3979563149213792, \"step\": 670500}\n",
      "{\"learning_rate\": 2.2772277227722774e-05, \"loss\": 1.3790152672529221, \"step\": 671000}\n",
      "{\"learning_rate\": 2.2751988313585457e-05, \"loss\": 1.3790192207098007, \"step\": 671500}\n",
      "{\"learning_rate\": 2.2731699399448143e-05, \"loss\": 1.3926543394327164, \"step\": 672000}\n",
      "{\"learning_rate\": 2.271141048531083e-05, \"loss\": 1.4038476078510285, \"step\": 672500}\n",
      "{\"learning_rate\": 2.269112157117351e-05, \"loss\": 1.3987923988103868, \"step\": 673000}\n",
      "{\"learning_rate\": 2.2670832657036197e-05, \"loss\": 1.3879452115297317, \"step\": 673500}\n",
      "{\"learning_rate\": 2.265054374289888e-05, \"loss\": 1.3972120691537857, \"step\": 674000}\n",
      "{\"learning_rate\": 2.2630254828761566e-05, \"loss\": 1.3440013757944107, \"step\": 674500}\n",
      "{\"learning_rate\": 2.260996591462425e-05, \"loss\": 1.4128405057191848, \"step\": 675000}\n",
      "{\"learning_rate\": 2.2589677000486938e-05, \"loss\": 1.3888899298906325, \"step\": 675500}\n",
      "{\"learning_rate\": 2.256938808634962e-05, \"loss\": 1.3913278517723084, \"step\": 676000}\n",
      "{\"learning_rate\": 2.2549099172212303e-05, \"loss\": 1.3698839491605759, \"step\": 676500}\n",
      "{\"learning_rate\": 2.252881025807499e-05, \"loss\": 1.3816383435726165, \"step\": 677000}\n",
      "{\"learning_rate\": 2.2508521343937675e-05, \"loss\": 1.3855657316446304, \"step\": 677500}\n",
      "{\"learning_rate\": 2.2488232429800357e-05, \"loss\": 1.3782025617957114, \"step\": 678000}\n",
      "{\"learning_rate\": 2.2467943515663043e-05, \"loss\": 1.3665930263996124, \"step\": 678500}\n",
      "{\"learning_rate\": 2.244765460152573e-05, \"loss\": 1.3949994764328002, \"step\": 679000}\n",
      "{\"learning_rate\": 2.242736568738841e-05, \"loss\": 1.383481028676033, \"step\": 679500}\n",
      "{\"learning_rate\": 2.2407076773251094e-05, \"loss\": 1.368899050116539, \"step\": 680000}\n",
      "{\"learning_rate\": 2.238678785911378e-05, \"loss\": 1.3619115223884584, \"step\": 680500}\n",
      "{\"learning_rate\": 2.2366498944976466e-05, \"loss\": 1.3794253334403037, \"step\": 681000}\n",
      "{\"learning_rate\": 2.2346210030839152e-05, \"loss\": 1.372204483270645, \"step\": 681500}\n",
      "{\"learning_rate\": 2.2325921116701834e-05, \"loss\": 1.3515936126708985, \"step\": 682000}\n",
      "{\"learning_rate\": 2.230563220256452e-05, \"loss\": 1.4069829868674277, \"step\": 682500}\n",
      "{\"learning_rate\": 2.2285343288427203e-05, \"loss\": 1.3805204951763153, \"step\": 683000}\n",
      "{\"learning_rate\": 2.226505437428989e-05, \"loss\": 1.36420183467865, \"step\": 683500}\n",
      "{\"learning_rate\": 2.224476546015257e-05, \"loss\": 1.3917526049613953, \"step\": 684000}\n",
      "{\"learning_rate\": 2.2224476546015257e-05, \"loss\": 1.385724488735199, \"step\": 684500}\n",
      "{\"learning_rate\": 2.2204187631877943e-05, \"loss\": 1.3668846892118454, \"step\": 685000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 2.218389871774063e-05, \"loss\": 1.3747013164758681, \"step\": 685500}\n",
      "{\"learning_rate\": 2.2163609803603312e-05, \"loss\": 1.381378919005394, \"step\": 686000}\n",
      "{\"learning_rate\": 2.2143320889465994e-05, \"loss\": 1.3979718990325927, \"step\": 686500}\n",
      "{\"learning_rate\": 2.212303197532868e-05, \"loss\": 1.4007807220220565, \"step\": 687000}\n",
      "{\"learning_rate\": 2.2102743061191366e-05, \"loss\": 1.3660761442184448, \"step\": 687500}\n",
      "{\"learning_rate\": 2.2082454147054052e-05, \"loss\": 1.3812437908649444, \"step\": 688000}\n",
      "{\"learning_rate\": 2.2062165232916735e-05, \"loss\": 1.3771176652908326, \"step\": 688500}\n",
      "{\"learning_rate\": 2.204187631877942e-05, \"loss\": 1.382931806206703, \"step\": 689000}\n",
      "{\"learning_rate\": 2.2021587404642107e-05, \"loss\": 1.3645994728803634, \"step\": 689500}\n",
      "{\"learning_rate\": 2.200129849050479e-05, \"loss\": 1.3799995934963227, \"step\": 690000}\n",
      "{\"learning_rate\": 2.1981009576367472e-05, \"loss\": 1.3639313107728959, \"step\": 690500}\n",
      "{\"learning_rate\": 2.1960720662230158e-05, \"loss\": 1.377469594359398, \"step\": 691000}\n",
      "{\"learning_rate\": 2.1940431748092844e-05, \"loss\": 1.3885682743787766, \"step\": 691500}\n",
      "{\"learning_rate\": 2.192014283395553e-05, \"loss\": 1.3982987008094787, \"step\": 692000}\n",
      "{\"learning_rate\": 2.1899853919818212e-05, \"loss\": 1.3835530430078506, \"step\": 692500}\n",
      "{\"learning_rate\": 2.1879565005680898e-05, \"loss\": 1.368730896949768, \"step\": 693000}\n",
      "{\"learning_rate\": 2.185927609154358e-05, \"loss\": 1.381609911441803, \"step\": 693500}\n",
      "{\"learning_rate\": 2.1838987177406267e-05, \"loss\": 1.389146073460579, \"step\": 694000}\n",
      "{\"learning_rate\": 2.181869826326895e-05, \"loss\": 1.3968774971961975, \"step\": 694500}\n",
      "{\"learning_rate\": 2.1798409349131635e-05, \"loss\": 1.3922883499860763, \"step\": 695000}\n",
      "{\"learning_rate\": 2.177812043499432e-05, \"loss\": 1.3727064777612685, \"step\": 695500}\n",
      "{\"learning_rate\": 2.1757831520857007e-05, \"loss\": 1.4051907325983048, \"step\": 696000}\n",
      "{\"learning_rate\": 2.173754260671969e-05, \"loss\": 1.3935222401618959, \"step\": 696500}\n",
      "{\"learning_rate\": 2.1717253692582372e-05, \"loss\": 1.3578126105070114, \"step\": 697000}\n",
      "{\"learning_rate\": 2.1696964778445058e-05, \"loss\": 1.3846907937526702, \"step\": 697500}\n",
      "{\"learning_rate\": 2.1676675864307744e-05, \"loss\": 1.3411294658184052, \"step\": 698000}\n",
      "{\"learning_rate\": 2.165638695017043e-05, \"loss\": 1.3625335061550141, \"step\": 698500}\n",
      "{\"learning_rate\": 2.1636098036033113e-05, \"loss\": 1.3819722784757613, \"step\": 699000}\n",
      "{\"learning_rate\": 2.16158091218958e-05, \"loss\": 1.3613126472234727, \"step\": 699500}\n",
      "{\"learning_rate\": 2.159552020775848e-05, \"loss\": 1.3697542065382005, \"step\": 700000}\n",
      "{\"learning_rate\": 2.1575231293621167e-05, \"loss\": 1.3560360983014106, \"step\": 700500}\n",
      "{\"learning_rate\": 2.155494237948385e-05, \"loss\": 1.3625399881601334, \"step\": 701000}\n",
      "{\"learning_rate\": 2.1534653465346535e-05, \"loss\": 1.3776370753049851, \"step\": 701500}\n",
      "{\"learning_rate\": 2.151436455120922e-05, \"loss\": 1.3849507719278336, \"step\": 702000}\n",
      "{\"learning_rate\": 2.1494075637071907e-05, \"loss\": 1.3764446324110031, \"step\": 702500}\n",
      "{\"learning_rate\": 2.147378672293459e-05, \"loss\": 1.3896049256324767, \"step\": 703000}\n",
      "{\"learning_rate\": 2.1453497808797272e-05, \"loss\": 1.3818383786082267, \"step\": 703500}\n",
      "{\"learning_rate\": 2.143320889465996e-05, \"loss\": 1.3751363787651063, \"step\": 704000}\n",
      "{\"learning_rate\": 2.1412919980522644e-05, \"loss\": 1.3618188506364823, \"step\": 704500}\n",
      "{\"learning_rate\": 2.1392631066385327e-05, \"loss\": 1.3595199620723724, \"step\": 705000}\n",
      "{\"learning_rate\": 2.1372342152248013e-05, \"loss\": 1.3898563369512558, \"step\": 705500}\n",
      "{\"learning_rate\": 2.13520532381107e-05, \"loss\": 1.3742403025627137, \"step\": 706000}\n",
      "{\"learning_rate\": 2.133176432397338e-05, \"loss\": 1.3727468131780625, \"step\": 706500}\n",
      "{\"learning_rate\": 2.1311475409836064e-05, \"loss\": 1.3703202877044678, \"step\": 707000}\n",
      "{\"learning_rate\": 2.129118649569875e-05, \"loss\": 1.363736032962799, \"step\": 707500}\n",
      "{\"learning_rate\": 2.1270897581561436e-05, \"loss\": 1.3894413056373596, \"step\": 708000}\n",
      "{\"learning_rate\": 2.1250608667424122e-05, \"loss\": 1.403958659529686, \"step\": 708500}\n",
      "{\"learning_rate\": 2.1230319753286808e-05, \"loss\": 1.3759155975580215, \"step\": 709000}\n",
      "{\"learning_rate\": 2.121003083914949e-05, \"loss\": 1.3471506822109223, \"step\": 709500}\n",
      "{\"learning_rate\": 2.1189741925012173e-05, \"loss\": 1.36253945851326, \"step\": 710000}\n",
      "{\"learning_rate\": 2.116945301087486e-05, \"loss\": 1.3765578991174698, \"step\": 710500}\n",
      "{\"learning_rate\": 2.1149164096737545e-05, \"loss\": 1.3561509703397752, \"step\": 711000}\n",
      "{\"learning_rate\": 2.1128875182600227e-05, \"loss\": 1.3783508187532425, \"step\": 711500}\n",
      "{\"learning_rate\": 2.1108586268462913e-05, \"loss\": 1.3573326281309128, \"step\": 712000}\n",
      "{\"learning_rate\": 2.10882973543256e-05, \"loss\": 1.3762427223920821, \"step\": 712500}\n",
      "{\"learning_rate\": 2.1068008440188282e-05, \"loss\": 1.347141826748848, \"step\": 713000}\n",
      "{\"learning_rate\": 2.1047719526050964e-05, \"loss\": 1.3927670282125473, \"step\": 713500}\n",
      "{\"learning_rate\": 2.102743061191365e-05, \"loss\": 1.3849357236623765, \"step\": 714000}\n",
      "{\"learning_rate\": 2.1007141697776336e-05, \"loss\": 1.3744901453852654, \"step\": 714500}\n",
      "{\"learning_rate\": 2.0986852783639022e-05, \"loss\": 1.3839685789346694, \"step\": 715000}\n",
      "{\"learning_rate\": 2.0966563869501705e-05, \"loss\": 1.356278108716011, \"step\": 715500}\n",
      "{\"learning_rate\": 2.094627495536439e-05, \"loss\": 1.3583613266944885, \"step\": 716000}\n",
      "{\"learning_rate\": 2.0925986041227073e-05, \"loss\": 1.3455490589141845, \"step\": 716500}\n",
      "{\"learning_rate\": 2.090569712708976e-05, \"loss\": 1.3592416502833367, \"step\": 717000}\n",
      "{\"learning_rate\": 2.088540821295244e-05, \"loss\": 1.3613276290893555, \"step\": 717500}\n",
      "{\"learning_rate\": 2.0865119298815128e-05, \"loss\": 1.3460098284482955, \"step\": 718000}\n",
      "{\"learning_rate\": 2.0844830384677814e-05, \"loss\": 1.3538334172964097, \"step\": 718500}\n",
      "{\"learning_rate\": 2.08245414705405e-05, \"loss\": 1.3722124377489089, \"step\": 719000}\n",
      "{\"learning_rate\": 2.0804252556403182e-05, \"loss\": 1.3571509577035903, \"step\": 719500}\n",
      "{\"learning_rate\": 2.0783963642265865e-05, \"loss\": 1.3624534690380097, \"step\": 720000}\n",
      "{\"learning_rate\": 2.076367472812855e-05, \"loss\": 1.358649640917778, \"step\": 720500}\n",
      "{\"learning_rate\": 2.0743385813991236e-05, \"loss\": 1.3547883363962174, \"step\": 721000}\n",
      "{\"learning_rate\": 2.0723096899853922e-05, \"loss\": 1.365455850481987, \"step\": 721500}\n",
      "{\"learning_rate\": 2.0702807985716605e-05, \"loss\": 1.3447538561820984, \"step\": 722000}\n",
      "{\"learning_rate\": 2.068251907157929e-05, \"loss\": 1.3656385515928269, \"step\": 722500}\n",
      "{\"learning_rate\": 2.0662230157441977e-05, \"loss\": 1.3843030128479004, \"step\": 723000}\n",
      "{\"learning_rate\": 2.064194124330466e-05, \"loss\": 1.3758572313785553, \"step\": 723500}\n",
      "{\"learning_rate\": 2.0621652329167342e-05, \"loss\": 1.3632282420396804, \"step\": 724000}\n",
      "{\"learning_rate\": 2.0601363415030028e-05, \"loss\": 1.3555511014461517, \"step\": 724500}\n",
      "{\"learning_rate\": 2.0581074500892714e-05, \"loss\": 1.3647098608016968, \"step\": 725000}\n",
      "{\"learning_rate\": 2.05607855867554e-05, \"loss\": 1.389084699511528, \"step\": 725500}\n",
      "{\"learning_rate\": 2.0540496672618082e-05, \"loss\": 1.3812715741395951, \"step\": 726000}\n",
      "{\"learning_rate\": 2.052020775848077e-05, \"loss\": 1.369214772939682, \"step\": 726500}\n",
      "{\"learning_rate\": 2.049991884434345e-05, \"loss\": 1.3743221324682235, \"step\": 727000}\n",
      "{\"learning_rate\": 2.0479629930206137e-05, \"loss\": 1.376610940694809, \"step\": 727500}\n",
      "{\"learning_rate\": 2.045934101606882e-05, \"loss\": 1.3439739203453065, \"step\": 728000}\n",
      "{\"learning_rate\": 2.0439052101931505e-05, \"loss\": 1.3867580722570418, \"step\": 728500}\n",
      "{\"learning_rate\": 2.041876318779419e-05, \"loss\": 1.373526969075203, \"step\": 729000}\n",
      "{\"learning_rate\": 2.0398474273656877e-05, \"loss\": 1.3772398024797439, \"step\": 729500}\n",
      "{\"learning_rate\": 2.037818535951956e-05, \"loss\": 1.3989385472536087, \"step\": 730000}\n",
      "{\"learning_rate\": 2.0357896445382242e-05, \"loss\": 1.3531644864082337, \"step\": 730500}\n",
      "{\"learning_rate\": 2.0337607531244928e-05, \"loss\": 1.370598967075348, \"step\": 731000}\n",
      "{\"learning_rate\": 2.0317318617107614e-05, \"loss\": 1.3741668026447296, \"step\": 731500}\n",
      "{\"learning_rate\": 2.02970297029703e-05, \"loss\": 1.3585643173456192, \"step\": 732000}\n",
      "{\"learning_rate\": 2.0276740788832983e-05, \"loss\": 1.3733715856075286, \"step\": 732500}\n",
      "{\"learning_rate\": 2.025645187469567e-05, \"loss\": 1.3587219750881194, \"step\": 733000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 2.023616296055835e-05, \"loss\": 1.365504203915596, \"step\": 733500}\n",
      "{\"learning_rate\": 2.0215874046421037e-05, \"loss\": 1.3783961013555526, \"step\": 734000}\n",
      "{\"learning_rate\": 2.019558513228372e-05, \"loss\": 1.3705402365922927, \"step\": 734500}\n",
      "{\"learning_rate\": 2.0175296218146406e-05, \"loss\": 1.3530641012191773, \"step\": 735000}\n",
      "{\"learning_rate\": 2.015500730400909e-05, \"loss\": 1.3769248238801957, \"step\": 735500}\n",
      "{\"learning_rate\": 2.0134718389871778e-05, \"loss\": 1.3863266075849534, \"step\": 736000}\n",
      "{\"learning_rate\": 2.011442947573446e-05, \"loss\": 1.4057585242986679, \"step\": 736500}\n",
      "{\"learning_rate\": 2.0094140561597143e-05, \"loss\": 1.3602711684703828, \"step\": 737000}\n",
      "{\"learning_rate\": 2.007385164745983e-05, \"loss\": 1.3676246027946473, \"step\": 737500}\n",
      "{\"learning_rate\": 2.0053562733322515e-05, \"loss\": 1.3600405867099763, \"step\": 738000}\n",
      "{\"learning_rate\": 2.0033273819185197e-05, \"loss\": 1.3602644058465958, \"step\": 738500}\n",
      "{\"learning_rate\": 2.0012984905047883e-05, \"loss\": 1.3496823567152023, \"step\": 739000}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff7e0f6cb3d4c7e8d5423359676b769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=246440.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 1.999269599091057e-05, \"loss\": 1.3387557954788207, \"step\": 739500}\n",
      "{\"learning_rate\": 1.997240707677325e-05, \"loss\": 1.3461408115625382, \"step\": 740000}\n",
      "{\"learning_rate\": 1.9952118162635934e-05, \"loss\": 1.3523745130300522, \"step\": 740500}\n",
      "{\"learning_rate\": 1.993182924849862e-05, \"loss\": 1.3588051514029502, \"step\": 741000}\n",
      "{\"learning_rate\": 1.9911540334361306e-05, \"loss\": 1.3533748210668564, \"step\": 741500}\n",
      "{\"learning_rate\": 1.9891251420223992e-05, \"loss\": 1.3523860224485398, \"step\": 742000}\n",
      "{\"learning_rate\": 1.9870962506086674e-05, \"loss\": 1.3365569578409195, \"step\": 742500}\n",
      "{\"learning_rate\": 1.985067359194936e-05, \"loss\": 1.3363545098304748, \"step\": 743000}\n",
      "{\"learning_rate\": 1.9830384677812043e-05, \"loss\": 1.3496023089885711, \"step\": 743500}\n",
      "{\"learning_rate\": 1.981009576367473e-05, \"loss\": 1.3657423913478852, \"step\": 744000}\n",
      "{\"learning_rate\": 1.9789806849537415e-05, \"loss\": 1.3497359300851821, \"step\": 744500}\n",
      "{\"learning_rate\": 1.9769517935400097e-05, \"loss\": 1.358051295876503, \"step\": 745000}\n",
      "{\"learning_rate\": 1.9749229021262783e-05, \"loss\": 1.3411202046871185, \"step\": 745500}\n",
      "{\"learning_rate\": 1.972894010712547e-05, \"loss\": 1.367419026374817, \"step\": 746000}\n",
      "{\"learning_rate\": 1.9708651192988152e-05, \"loss\": 1.3583136820793151, \"step\": 746500}\n",
      "{\"learning_rate\": 1.9688362278850834e-05, \"loss\": 1.3646017554998398, \"step\": 747000}\n",
      "{\"learning_rate\": 1.966807336471352e-05, \"loss\": 1.3451094574928284, \"step\": 747500}\n",
      "{\"learning_rate\": 1.9647784450576206e-05, \"loss\": 1.35304647564888, \"step\": 748000}\n",
      "{\"learning_rate\": 1.9627495536438892e-05, \"loss\": 1.3540971862077713, \"step\": 748500}\n",
      "{\"learning_rate\": 1.9607206622301575e-05, \"loss\": 1.3689023234844209, \"step\": 749000}\n",
      "{\"learning_rate\": 1.958691770816426e-05, \"loss\": 1.3831933159828187, \"step\": 749500}\n",
      "{\"learning_rate\": 1.9566628794026943e-05, \"loss\": 1.3549407125711441, \"step\": 750000}\n",
      "{\"learning_rate\": 1.954633987988963e-05, \"loss\": 1.3510748492479325, \"step\": 750500}\n",
      "{\"learning_rate\": 1.9526050965752312e-05, \"loss\": 1.3639635761976243, \"step\": 751000}\n",
      "{\"learning_rate\": 1.9505762051614998e-05, \"loss\": 1.3614739611148834, \"step\": 751500}\n",
      "{\"learning_rate\": 1.9485473137477684e-05, \"loss\": 1.3467103414535522, \"step\": 752000}\n",
      "{\"learning_rate\": 1.946518422334037e-05, \"loss\": 1.345688812971115, \"step\": 752500}\n",
      "{\"learning_rate\": 1.9444895309203052e-05, \"loss\": 1.378246222615242, \"step\": 753000}\n",
      "{\"learning_rate\": 1.9424606395065735e-05, \"loss\": 1.3387569154500962, \"step\": 753500}\n",
      "{\"learning_rate\": 1.940431748092842e-05, \"loss\": 1.3170604289770127, \"step\": 754000}\n",
      "{\"learning_rate\": 1.9384028566791107e-05, \"loss\": 1.3339672354459762, \"step\": 754500}\n",
      "{\"learning_rate\": 1.936373965265379e-05, \"loss\": 1.372530497252941, \"step\": 755000}\n",
      "{\"learning_rate\": 1.9343450738516475e-05, \"loss\": 1.3573041311502456, \"step\": 755500}\n",
      "{\"learning_rate\": 1.932316182437916e-05, \"loss\": 1.360688523054123, \"step\": 756000}\n",
      "{\"learning_rate\": 1.9302872910241847e-05, \"loss\": 1.3486298315525056, \"step\": 756500}\n",
      "{\"learning_rate\": 1.928258399610453e-05, \"loss\": 1.3531258746385575, \"step\": 757000}\n",
      "{\"learning_rate\": 1.9262295081967212e-05, \"loss\": 1.3642280876636506, \"step\": 757500}\n",
      "{\"learning_rate\": 1.9242006167829898e-05, \"loss\": 1.3678547658920288, \"step\": 758000}\n",
      "{\"learning_rate\": 1.9221717253692584e-05, \"loss\": 1.3620381538271904, \"step\": 758500}\n",
      "{\"learning_rate\": 1.920142833955527e-05, \"loss\": 1.345678437590599, \"step\": 759000}\n",
      "{\"learning_rate\": 1.9181139425417953e-05, \"loss\": 1.35095389521122, \"step\": 759500}\n",
      "{\"learning_rate\": 1.916085051128064e-05, \"loss\": 1.364257930994034, \"step\": 760000}\n",
      "{\"learning_rate\": 1.914056159714332e-05, \"loss\": 1.3537921049594879, \"step\": 760500}\n",
      "{\"learning_rate\": 1.9120272683006007e-05, \"loss\": 1.3686083825826645, \"step\": 761000}\n",
      "{\"learning_rate\": 1.909998376886869e-05, \"loss\": 1.3450826528072357, \"step\": 761500}\n",
      "{\"learning_rate\": 1.9079694854731375e-05, \"loss\": 1.3637692034244537, \"step\": 762000}\n",
      "{\"learning_rate\": 1.905940594059406e-05, \"loss\": 1.343119776725769, \"step\": 762500}\n",
      "{\"learning_rate\": 1.9039117026456747e-05, \"loss\": 1.340337737083435, \"step\": 763000}\n",
      "{\"learning_rate\": 1.901882811231943e-05, \"loss\": 1.3550393028259278, \"step\": 763500}\n",
      "{\"learning_rate\": 1.8998539198182112e-05, \"loss\": 1.3457102926969529, \"step\": 764000}\n",
      "{\"learning_rate\": 1.89782502840448e-05, \"loss\": 1.3515260185003282, \"step\": 764500}\n",
      "{\"learning_rate\": 1.8957961369907484e-05, \"loss\": 1.3505040731430054, \"step\": 765000}\n",
      "{\"learning_rate\": 1.8937672455770167e-05, \"loss\": 1.3428070558309555, \"step\": 765500}\n",
      "{\"learning_rate\": 1.8917383541632853e-05, \"loss\": 1.3489228923916816, \"step\": 766000}\n",
      "{\"learning_rate\": 1.889709462749554e-05, \"loss\": 1.3684050332307816, \"step\": 766500}\n",
      "{\"learning_rate\": 1.887680571335822e-05, \"loss\": 1.3577771990299226, \"step\": 767000}\n",
      "{\"learning_rate\": 1.8856516799220907e-05, \"loss\": 1.350962790608406, \"step\": 767500}\n",
      "{\"learning_rate\": 1.883622788508359e-05, \"loss\": 1.3620948357582092, \"step\": 768000}\n",
      "{\"learning_rate\": 1.8815938970946276e-05, \"loss\": 1.3333939272165298, \"step\": 768500}\n",
      "{\"learning_rate\": 1.8795650056808962e-05, \"loss\": 1.3445970368981361, \"step\": 769000}\n",
      "{\"learning_rate\": 1.8775361142671648e-05, \"loss\": 1.3361305322647095, \"step\": 769500}\n",
      "{\"learning_rate\": 1.875507222853433e-05, \"loss\": 1.3801344380378724, \"step\": 770000}\n",
      "{\"learning_rate\": 1.8734783314397013e-05, \"loss\": 1.3806888632774352, \"step\": 770500}\n",
      "{\"learning_rate\": 1.87144944002597e-05, \"loss\": 1.3655123903751374, \"step\": 771000}\n",
      "{\"learning_rate\": 1.8694205486122385e-05, \"loss\": 1.354142917394638, \"step\": 771500}\n",
      "{\"learning_rate\": 1.8673916571985067e-05, \"loss\": 1.3621445300579071, \"step\": 772000}\n",
      "{\"learning_rate\": 1.8653627657847753e-05, \"loss\": 1.3434504833221435, \"step\": 772500}\n",
      "{\"learning_rate\": 1.863333874371044e-05, \"loss\": 1.3574224971532822, \"step\": 773000}\n",
      "{\"learning_rate\": 1.8613049829573122e-05, \"loss\": 1.3402327735424042, \"step\": 773500}\n",
      "{\"learning_rate\": 1.8592760915435804e-05, \"loss\": 1.338960711836815, \"step\": 774000}\n",
      "{\"learning_rate\": 1.857247200129849e-05, \"loss\": 1.3440314565896987, \"step\": 774500}\n",
      "{\"learning_rate\": 1.8552183087161176e-05, \"loss\": 1.3476142033338547, \"step\": 775000}\n",
      "{\"learning_rate\": 1.8531894173023862e-05, \"loss\": 1.322776573061943, \"step\": 775500}\n",
      "{\"learning_rate\": 1.8511605258886545e-05, \"loss\": 1.3467906970977783, \"step\": 776000}\n",
      "{\"learning_rate\": 1.849131634474923e-05, \"loss\": 1.3433038634061814, \"step\": 776500}\n",
      "{\"learning_rate\": 1.8471027430611913e-05, \"loss\": 1.3498544842600821, \"step\": 777000}\n",
      "{\"learning_rate\": 1.84507385164746e-05, \"loss\": 1.3811385840177537, \"step\": 777500}\n",
      "{\"learning_rate\": 1.843044960233728e-05, \"loss\": 1.3442311443090438, \"step\": 778000}\n",
      "{\"learning_rate\": 1.8410160688199968e-05, \"loss\": 1.358973501265049, \"step\": 778500}\n",
      "{\"learning_rate\": 1.8389871774062654e-05, \"loss\": 1.3363881375789641, \"step\": 779000}\n",
      "{\"learning_rate\": 1.836958285992534e-05, \"loss\": 1.3610650310516357, \"step\": 779500}\n",
      "{\"learning_rate\": 1.8349293945788022e-05, \"loss\": 1.341023341178894, \"step\": 780000}\n",
      "{\"learning_rate\": 1.8329005031650705e-05, \"loss\": 1.3469625465869903, \"step\": 780500}\n",
      "{\"learning_rate\": 1.830871611751339e-05, \"loss\": 1.3582858711481094, \"step\": 781000}\n",
      "{\"learning_rate\": 1.8288427203376076e-05, \"loss\": 1.3875149381160736, \"step\": 781500}\n",
      "{\"learning_rate\": 1.8268138289238762e-05, \"loss\": 1.3630558626651763, \"step\": 782000}\n",
      "{\"learning_rate\": 1.8247849375101445e-05, \"loss\": 1.3653074172735213, \"step\": 782500}\n",
      "{\"learning_rate\": 1.822756046096413e-05, \"loss\": 1.3545667423009873, \"step\": 783000}\n",
      "{\"learning_rate\": 1.8207271546826813e-05, \"loss\": 1.3375779443979263, \"step\": 783500}\n",
      "{\"learning_rate\": 1.81869826326895e-05, \"loss\": 1.338520981669426, \"step\": 784000}\n",
      "{\"learning_rate\": 1.8166693718552182e-05, \"loss\": 1.361800450026989, \"step\": 784500}\n",
      "{\"learning_rate\": 1.8146404804414868e-05, \"loss\": 1.3386671400070191, \"step\": 785000}\n",
      "{\"learning_rate\": 1.8126115890277554e-05, \"loss\": 1.364869193315506, \"step\": 785500}\n",
      "{\"learning_rate\": 1.810582697614024e-05, \"loss\": 1.3647959831357002, \"step\": 786000}\n",
      "{\"learning_rate\": 1.8085538062002922e-05, \"loss\": 1.3353816055059433, \"step\": 786500}\n",
      "{\"learning_rate\": 1.806524914786561e-05, \"loss\": 1.3626839586496353, \"step\": 787000}\n",
      "{\"learning_rate\": 1.804496023372829e-05, \"loss\": 1.345643077135086, \"step\": 787500}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 1.8024671319590977e-05, \"loss\": 1.3578760102391243, \"step\": 788000}\n",
      "{\"learning_rate\": 1.800438240545366e-05, \"loss\": 1.3297338378429413, \"step\": 788500}\n",
      "{\"learning_rate\": 1.7984093491316345e-05, \"loss\": 1.342516992330551, \"step\": 789000}\n",
      "{\"learning_rate\": 1.796380457717903e-05, \"loss\": 1.3373197013139724, \"step\": 789500}\n",
      "{\"learning_rate\": 1.7943515663041717e-05, \"loss\": 1.3224813375473023, \"step\": 790000}\n",
      "{\"learning_rate\": 1.79232267489044e-05, \"loss\": 1.3556777563095093, \"step\": 790500}\n",
      "{\"learning_rate\": 1.7902937834767082e-05, \"loss\": 1.3604735733270645, \"step\": 791000}\n",
      "{\"learning_rate\": 1.7882648920629768e-05, \"loss\": 1.349819734454155, \"step\": 791500}\n",
      "{\"learning_rate\": 1.7862360006492454e-05, \"loss\": 1.3540546241998672, \"step\": 792000}\n",
      "{\"learning_rate\": 1.784207109235514e-05, \"loss\": 1.3349113218784332, \"step\": 792500}\n",
      "{\"learning_rate\": 1.7821782178217823e-05, \"loss\": 1.3422654752731322, \"step\": 793000}\n",
      "{\"learning_rate\": 1.780149326408051e-05, \"loss\": 1.3399999147057533, \"step\": 793500}\n",
      "{\"learning_rate\": 1.778120434994319e-05, \"loss\": 1.3400665191411971, \"step\": 794000}\n",
      "{\"learning_rate\": 1.7760915435805877e-05, \"loss\": 1.3379146206378936, \"step\": 794500}\n",
      "{\"learning_rate\": 1.774062652166856e-05, \"loss\": 1.3429632759094239, \"step\": 795000}\n",
      "{\"learning_rate\": 1.7720337607531246e-05, \"loss\": 1.3438384532928467, \"step\": 795500}\n",
      "{\"learning_rate\": 1.770004869339393e-05, \"loss\": 1.3351188082098961, \"step\": 796000}\n",
      "{\"learning_rate\": 1.7679759779256618e-05, \"loss\": 1.337328570008278, \"step\": 796500}\n",
      "{\"learning_rate\": 1.76594708651193e-05, \"loss\": 1.3580558765530586, \"step\": 797000}\n",
      "{\"learning_rate\": 1.7639181950981983e-05, \"loss\": 1.3286350251436234, \"step\": 797500}\n",
      "{\"learning_rate\": 1.761889303684467e-05, \"loss\": 1.3497716442346572, \"step\": 798000}\n",
      "{\"learning_rate\": 1.7598604122707355e-05, \"loss\": 1.3561639199852944, \"step\": 798500}\n",
      "{\"learning_rate\": 1.7578315208570037e-05, \"loss\": 1.3261202723383902, \"step\": 799000}\n",
      "{\"learning_rate\": 1.7558026294432723e-05, \"loss\": 1.3484841595888137, \"step\": 799500}\n",
      "{\"learning_rate\": 1.753773738029541e-05, \"loss\": 1.345954773426056, \"step\": 800000}\n",
      "{\"learning_rate\": 1.751744846615809e-05, \"loss\": 1.3512897635698318, \"step\": 800500}\n",
      "{\"learning_rate\": 1.7497159552020774e-05, \"loss\": 1.3582990516424178, \"step\": 801000}\n",
      "{\"learning_rate\": 1.747687063788346e-05, \"loss\": 1.35549842607975, \"step\": 801500}\n",
      "{\"learning_rate\": 1.7456581723746146e-05, \"loss\": 1.3288130532503128, \"step\": 802000}\n",
      "{\"learning_rate\": 1.7436292809608832e-05, \"loss\": 1.3466223295927047, \"step\": 802500}\n",
      "{\"learning_rate\": 1.7416003895471518e-05, \"loss\": 1.361782865524292, \"step\": 803000}\n",
      "{\"learning_rate\": 1.73957149813342e-05, \"loss\": 1.3381079075336457, \"step\": 803500}\n",
      "{\"learning_rate\": 1.7375426067196883e-05, \"loss\": 1.3416615780591965, \"step\": 804000}\n",
      "{\"learning_rate\": 1.735513715305957e-05, \"loss\": 1.3498333625793457, \"step\": 804500}\n",
      "{\"learning_rate\": 1.7334848238922255e-05, \"loss\": 1.3212076777219772, \"step\": 805000}\n",
      "{\"learning_rate\": 1.7314559324784937e-05, \"loss\": 1.3130394637584686, \"step\": 805500}\n",
      "{\"learning_rate\": 1.7294270410647623e-05, \"loss\": 1.3576078367233277, \"step\": 806000}\n",
      "{\"learning_rate\": 1.727398149651031e-05, \"loss\": 1.3680348477363586, \"step\": 806500}\n",
      "{\"learning_rate\": 1.7253692582372992e-05, \"loss\": 1.3458805696368217, \"step\": 807000}\n",
      "{\"learning_rate\": 1.7233403668235674e-05, \"loss\": 1.3246407585144042, \"step\": 807500}\n",
      "{\"learning_rate\": 1.721311475409836e-05, \"loss\": 1.3421236618757248, \"step\": 808000}\n",
      "{\"learning_rate\": 1.7192825839961046e-05, \"loss\": 1.3097960983514785, \"step\": 808500}\n",
      "{\"learning_rate\": 1.7172536925823732e-05, \"loss\": 1.3154571956396104, \"step\": 809000}\n",
      "{\"learning_rate\": 1.7152248011686415e-05, \"loss\": 1.3411303012371063, \"step\": 809500}\n",
      "{\"learning_rate\": 1.71319590975491e-05, \"loss\": 1.3266671779155732, \"step\": 810000}\n",
      "{\"learning_rate\": 1.7111670183411783e-05, \"loss\": 1.3166800845861435, \"step\": 810500}\n",
      "{\"learning_rate\": 1.709138126927447e-05, \"loss\": 1.3437353624105453, \"step\": 811000}\n",
      "{\"learning_rate\": 1.7071092355137152e-05, \"loss\": 1.340023551940918, \"step\": 811500}\n",
      "{\"learning_rate\": 1.7050803440999838e-05, \"loss\": 1.338726542711258, \"step\": 812000}\n",
      "{\"learning_rate\": 1.7030514526862524e-05, \"loss\": 1.3533906593322753, \"step\": 812500}\n",
      "{\"learning_rate\": 1.701022561272521e-05, \"loss\": 1.3593781961202622, \"step\": 813000}\n",
      "{\"learning_rate\": 1.6989936698587892e-05, \"loss\": 1.3462009879350663, \"step\": 813500}\n",
      "{\"learning_rate\": 1.6969647784450575e-05, \"loss\": 1.3401185170412064, \"step\": 814000}\n",
      "{\"learning_rate\": 1.694935887031326e-05, \"loss\": 1.3275899506807327, \"step\": 814500}\n",
      "{\"learning_rate\": 1.6929069956175947e-05, \"loss\": 1.3498446134328843, \"step\": 815000}\n",
      "{\"learning_rate\": 1.6908781042038633e-05, \"loss\": 1.3320769377946853, \"step\": 815500}\n",
      "{\"learning_rate\": 1.6888492127901315e-05, \"loss\": 1.315255410194397, \"step\": 816000}\n",
      "{\"learning_rate\": 1.6868203213764e-05, \"loss\": 1.3240930334329606, \"step\": 816500}\n",
      "{\"learning_rate\": 1.6847914299626684e-05, \"loss\": 1.3357218363285064, \"step\": 817000}\n",
      "{\"learning_rate\": 1.682762538548937e-05, \"loss\": 1.3473903213739395, \"step\": 817500}\n",
      "{\"learning_rate\": 1.6807336471352052e-05, \"loss\": 1.3322714740037918, \"step\": 818000}\n",
      "{\"learning_rate\": 1.6787047557214738e-05, \"loss\": 1.3293266031742097, \"step\": 818500}\n",
      "{\"learning_rate\": 1.6766758643077424e-05, \"loss\": 1.3380186527967453, \"step\": 819000}\n",
      "{\"learning_rate\": 1.674646972894011e-05, \"loss\": 1.3353614383935928, \"step\": 819500}\n",
      "{\"learning_rate\": 1.6726180814802793e-05, \"loss\": 1.3372453608512878, \"step\": 820000}\n",
      "{\"learning_rate\": 1.670589190066548e-05, \"loss\": 1.3191453312635422, \"step\": 820500}\n",
      "{\"learning_rate\": 1.668560298652816e-05, \"loss\": 1.3357833783626556, \"step\": 821000}\n",
      "{\"learning_rate\": 1.6665314072390847e-05, \"loss\": 1.3502975894212723, \"step\": 821500}\n",
      "{\"learning_rate\": 1.664502515825353e-05, \"loss\": 1.3236029317379, \"step\": 822000}\n",
      "{\"learning_rate\": 1.6624736244116215e-05, \"loss\": 1.3333736946582795, \"step\": 822500}\n",
      "{\"learning_rate\": 1.66044473299789e-05, \"loss\": 1.328357812643051, \"step\": 823000}\n",
      "{\"learning_rate\": 1.6584158415841587e-05, \"loss\": 1.327504924416542, \"step\": 823500}\n",
      "{\"learning_rate\": 1.656386950170427e-05, \"loss\": 1.3340561083555222, \"step\": 824000}\n",
      "{\"learning_rate\": 1.6543580587566952e-05, \"loss\": 1.3540589168071746, \"step\": 824500}\n",
      "{\"learning_rate\": 1.652329167342964e-05, \"loss\": 1.341767893910408, \"step\": 825000}\n",
      "{\"learning_rate\": 1.6503002759292324e-05, \"loss\": 1.3537894434928894, \"step\": 825500}\n",
      "{\"learning_rate\": 1.6482713845155007e-05, \"loss\": 1.334267138838768, \"step\": 826000}\n",
      "{\"learning_rate\": 1.6462424931017693e-05, \"loss\": 1.329279943227768, \"step\": 826500}\n",
      "{\"learning_rate\": 1.644213601688038e-05, \"loss\": 1.3592297122478485, \"step\": 827000}\n",
      "{\"learning_rate\": 1.642184710274306e-05, \"loss\": 1.3461554254293442, \"step\": 827500}\n",
      "{\"learning_rate\": 1.6401558188605747e-05, \"loss\": 1.335449850797653, \"step\": 828000}\n",
      "{\"learning_rate\": 1.638126927446843e-05, \"loss\": 1.3577097560167313, \"step\": 828500}\n",
      "{\"learning_rate\": 1.6360980360331116e-05, \"loss\": 1.369112201333046, \"step\": 829000}\n",
      "{\"learning_rate\": 1.6340691446193802e-05, \"loss\": 1.3534598079919815, \"step\": 829500}\n",
      "{\"learning_rate\": 1.6320402532056488e-05, \"loss\": 1.3257804902791976, \"step\": 830000}\n",
      "{\"learning_rate\": 1.630011361791917e-05, \"loss\": 1.3235811787843703, \"step\": 830500}\n",
      "{\"learning_rate\": 1.6279824703781853e-05, \"loss\": 1.325315693974495, \"step\": 831000}\n",
      "{\"learning_rate\": 1.625953578964454e-05, \"loss\": 1.3220139226913452, \"step\": 831500}\n",
      "{\"learning_rate\": 1.6239246875507225e-05, \"loss\": 1.3248052179217338, \"step\": 832000}\n",
      "{\"learning_rate\": 1.6218957961369907e-05, \"loss\": 1.3223830617666243, \"step\": 832500}\n",
      "{\"learning_rate\": 1.6198669047232593e-05, \"loss\": 1.3417544479370118, \"step\": 833000}\n",
      "{\"learning_rate\": 1.617838013309528e-05, \"loss\": 1.336886837244034, \"step\": 833500}\n",
      "{\"learning_rate\": 1.6158091218957962e-05, \"loss\": 1.3732027117013932, \"step\": 834000}\n",
      "{\"learning_rate\": 1.6137802304820644e-05, \"loss\": 1.3263231830596924, \"step\": 834500}\n",
      "{\"learning_rate\": 1.611751339068333e-05, \"loss\": 1.3374571261405945, \"step\": 835000}\n",
      "{\"learning_rate\": 1.6097224476546016e-05, \"loss\": 1.323751172065735, \"step\": 835500}\n",
      "{\"learning_rate\": 1.6076935562408702e-05, \"loss\": 1.3610016278028487, \"step\": 836000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 1.6056646648271385e-05, \"loss\": 1.3332064895629883, \"step\": 836500}\n",
      "{\"learning_rate\": 1.603635773413407e-05, \"loss\": 1.3292752977609634, \"step\": 837000}\n",
      "{\"learning_rate\": 1.6016068819996753e-05, \"loss\": 1.3397505968809127, \"step\": 837500}\n",
      "{\"learning_rate\": 1.599577990585944e-05, \"loss\": 1.3051401509046554, \"step\": 838000}\n",
      "{\"learning_rate\": 1.5975490991722125e-05, \"loss\": 1.3340400949716569, \"step\": 838500}\n",
      "{\"learning_rate\": 1.5955202077584808e-05, \"loss\": 1.3375668610930442, \"step\": 839000}\n",
      "{\"learning_rate\": 1.5934913163447494e-05, \"loss\": 1.3353790278434754, \"step\": 839500}\n",
      "{\"learning_rate\": 1.591462424931018e-05, \"loss\": 1.306329852104187, \"step\": 840000}\n",
      "{\"learning_rate\": 1.5894335335172862e-05, \"loss\": 1.3349035919904708, \"step\": 840500}\n",
      "{\"learning_rate\": 1.5874046421035545e-05, \"loss\": 1.3404281212687492, \"step\": 841000}\n",
      "{\"learning_rate\": 1.585375750689823e-05, \"loss\": 1.3121871932148934, \"step\": 841500}\n",
      "{\"learning_rate\": 1.5833468592760916e-05, \"loss\": 1.3567345654964447, \"step\": 842000}\n",
      "{\"learning_rate\": 1.5813179678623602e-05, \"loss\": 1.3450003342628478, \"step\": 842500}\n",
      "{\"learning_rate\": 1.5792890764486285e-05, \"loss\": 1.3496445680856706, \"step\": 843000}\n",
      "{\"learning_rate\": 1.577260185034897e-05, \"loss\": 1.337412917613983, \"step\": 843500}\n",
      "{\"learning_rate\": 1.5752312936211653e-05, \"loss\": 1.3405206061601638, \"step\": 844000}\n",
      "{\"learning_rate\": 1.573202402207434e-05, \"loss\": 1.3519946037530899, \"step\": 844500}\n",
      "{\"learning_rate\": 1.5711735107937022e-05, \"loss\": 1.332374013543129, \"step\": 845000}\n",
      "{\"learning_rate\": 1.5691446193799708e-05, \"loss\": 1.3264330316781998, \"step\": 845500}\n",
      "{\"learning_rate\": 1.5671157279662394e-05, \"loss\": 1.3193618260622024, \"step\": 846000}\n",
      "{\"learning_rate\": 1.565086836552508e-05, \"loss\": 1.3371456562280655, \"step\": 846500}\n",
      "{\"learning_rate\": 1.5630579451387762e-05, \"loss\": 1.3310950297117232, \"step\": 847000}\n",
      "{\"learning_rate\": 1.5610290537250445e-05, \"loss\": 1.333064692258835, \"step\": 847500}\n",
      "{\"learning_rate\": 1.559000162311313e-05, \"loss\": 1.3167789402008057, \"step\": 848000}\n",
      "{\"learning_rate\": 1.5569712708975817e-05, \"loss\": 1.3185130636692046, \"step\": 848500}\n",
      "{\"learning_rate\": 1.55494237948385e-05, \"loss\": 1.3348761268854141, \"step\": 849000}\n",
      "{\"learning_rate\": 1.5529134880701185e-05, \"loss\": 1.3384451040029526, \"step\": 849500}\n",
      "{\"learning_rate\": 1.550884596656387e-05, \"loss\": 1.3338964465856553, \"step\": 850000}\n",
      "{\"learning_rate\": 1.5488557052426557e-05, \"loss\": 1.3324367165565492, \"step\": 850500}\n",
      "{\"learning_rate\": 1.546826813828924e-05, \"loss\": 1.3131298122406005, \"step\": 851000}\n",
      "{\"learning_rate\": 1.5447979224151922e-05, \"loss\": 1.3314374741911887, \"step\": 851500}\n",
      "{\"learning_rate\": 1.5427690310014608e-05, \"loss\": 1.342066329717636, \"step\": 852000}\n",
      "{\"learning_rate\": 1.5407401395877294e-05, \"loss\": 1.3349994090795516, \"step\": 852500}\n",
      "{\"learning_rate\": 1.538711248173998e-05, \"loss\": 1.3308049246668816, \"step\": 853000}\n",
      "{\"learning_rate\": 1.5366823567602663e-05, \"loss\": 1.3229147837162019, \"step\": 853500}\n",
      "{\"learning_rate\": 1.534653465346535e-05, \"loss\": 1.3152509134411812, \"step\": 854000}\n",
      "{\"learning_rate\": 1.532624573932803e-05, \"loss\": 1.3183643256425857, \"step\": 854500}\n",
      "{\"learning_rate\": 1.5305956825190717e-05, \"loss\": 1.3255710475444793, \"step\": 855000}\n",
      "{\"learning_rate\": 1.52856679110534e-05, \"loss\": 1.3274916921854019, \"step\": 855500}\n",
      "{\"learning_rate\": 1.5265378996916086e-05, \"loss\": 1.3420305250883102, \"step\": 856000}\n",
      "{\"learning_rate\": 1.524509008277877e-05, \"loss\": 1.3407137829065323, \"step\": 856500}\n",
      "{\"learning_rate\": 1.5224801168641456e-05, \"loss\": 1.3173088525533676, \"step\": 857000}\n",
      "{\"learning_rate\": 1.5204512254504138e-05, \"loss\": 1.3209855778813362, \"step\": 857500}\n",
      "{\"learning_rate\": 1.5184223340366824e-05, \"loss\": 1.3429331344366073, \"step\": 858000}\n",
      "{\"learning_rate\": 1.5163934426229509e-05, \"loss\": 1.3404398188591002, \"step\": 858500}\n",
      "{\"learning_rate\": 1.5143645512092195e-05, \"loss\": 1.3205457893013954, \"step\": 859000}\n",
      "{\"learning_rate\": 1.5123356597954877e-05, \"loss\": 1.3314382860660552, \"step\": 859500}\n",
      "{\"learning_rate\": 1.5103067683817563e-05, \"loss\": 1.3205889545679093, \"step\": 860000}\n",
      "{\"learning_rate\": 1.5082778769680247e-05, \"loss\": 1.3449281526803971, \"step\": 860500}\n",
      "{\"learning_rate\": 1.5062489855542933e-05, \"loss\": 1.311521677494049, \"step\": 861000}\n",
      "{\"learning_rate\": 1.5042200941405616e-05, \"loss\": 1.3299044518470764, \"step\": 861500}\n",
      "{\"learning_rate\": 1.50219120272683e-05, \"loss\": 1.312600418806076, \"step\": 862000}\n",
      "{\"learning_rate\": 1.5001623113130986e-05, \"loss\": 1.3101966655254365, \"step\": 862500}\n",
      "{\"learning_rate\": 1.4981334198993672e-05, \"loss\": 1.3387761688232422, \"step\": 863000}\n",
      "{\"learning_rate\": 1.4961045284856356e-05, \"loss\": 1.3163362293839456, \"step\": 863500}\n",
      "{\"learning_rate\": 1.4940756370719039e-05, \"loss\": 1.32356809425354, \"step\": 864000}\n",
      "{\"learning_rate\": 1.4920467456581725e-05, \"loss\": 1.325794760465622, \"step\": 864500}\n",
      "{\"learning_rate\": 1.4900178542444409e-05, \"loss\": 1.3491566812992095, \"step\": 865000}\n",
      "{\"learning_rate\": 1.4879889628307095e-05, \"loss\": 1.337695617198944, \"step\": 865500}\n",
      "{\"learning_rate\": 1.4859600714169777e-05, \"loss\": 1.3377069883346557, \"step\": 866000}\n",
      "{\"learning_rate\": 1.4839311800032463e-05, \"loss\": 1.344881018280983, \"step\": 866500}\n",
      "{\"learning_rate\": 1.4819022885895148e-05, \"loss\": 1.333335134267807, \"step\": 867000}\n",
      "{\"learning_rate\": 1.4798733971757834e-05, \"loss\": 1.345919715642929, \"step\": 867500}\n",
      "{\"learning_rate\": 1.4778445057620516e-05, \"loss\": 1.3376029539108276, \"step\": 868000}\n",
      "{\"learning_rate\": 1.47581561434832e-05, \"loss\": 1.3513602831363678, \"step\": 868500}\n",
      "{\"learning_rate\": 1.4737867229345886e-05, \"loss\": 1.337812794804573, \"step\": 869000}\n",
      "{\"learning_rate\": 1.4717578315208572e-05, \"loss\": 1.3216337860822678, \"step\": 869500}\n",
      "{\"learning_rate\": 1.4697289401071255e-05, \"loss\": 1.3405031123161315, \"step\": 870000}\n",
      "{\"learning_rate\": 1.4677000486933939e-05, \"loss\": 1.3365982179641724, \"step\": 870500}\n",
      "{\"learning_rate\": 1.4656711572796625e-05, \"loss\": 1.3248927255868912, \"step\": 871000}\n",
      "{\"learning_rate\": 1.463642265865931e-05, \"loss\": 1.322005334198475, \"step\": 871500}\n",
      "{\"learning_rate\": 1.4616133744521992e-05, \"loss\": 1.3216564956903458, \"step\": 872000}\n",
      "{\"learning_rate\": 1.4595844830384678e-05, \"loss\": 1.345955710709095, \"step\": 872500}\n",
      "{\"learning_rate\": 1.4575555916247364e-05, \"loss\": 1.3268169665336609, \"step\": 873000}\n",
      "{\"learning_rate\": 1.4555267002110048e-05, \"loss\": 1.3210766026973724, \"step\": 873500}\n",
      "{\"learning_rate\": 1.4534978087972734e-05, \"loss\": 1.3360627952814101, \"step\": 874000}\n",
      "{\"learning_rate\": 1.4514689173835416e-05, \"loss\": 1.340155601143837, \"step\": 874500}\n",
      "{\"learning_rate\": 1.4494400259698102e-05, \"loss\": 1.319246385395527, \"step\": 875000}\n",
      "{\"learning_rate\": 1.4474111345560787e-05, \"loss\": 1.3266352756023407, \"step\": 875500}\n",
      "{\"learning_rate\": 1.4453822431423473e-05, \"loss\": 1.330156035065651, \"step\": 876000}\n",
      "{\"learning_rate\": 1.4433533517286155e-05, \"loss\": 1.3383344574570655, \"step\": 876500}\n",
      "{\"learning_rate\": 1.441324460314884e-05, \"loss\": 1.3242424628734588, \"step\": 877000}\n",
      "{\"learning_rate\": 1.4392955689011525e-05, \"loss\": 1.3037854598760605, \"step\": 877500}\n",
      "{\"learning_rate\": 1.4372666774874211e-05, \"loss\": 1.358043776869774, \"step\": 878000}\n",
      "{\"learning_rate\": 1.4352377860736894e-05, \"loss\": 1.3167980902194978, \"step\": 878500}\n",
      "{\"learning_rate\": 1.4332088946599578e-05, \"loss\": 1.3345854886770248, \"step\": 879000}\n",
      "{\"learning_rate\": 1.4311800032462264e-05, \"loss\": 1.3333622254133224, \"step\": 879500}\n",
      "{\"learning_rate\": 1.4291511118324948e-05, \"loss\": 1.3006996355056764, \"step\": 880000}\n",
      "{\"learning_rate\": 1.427122220418763e-05, \"loss\": 1.3445419406294823, \"step\": 880500}\n",
      "{\"learning_rate\": 1.4250933290050317e-05, \"loss\": 1.3140675327777862, \"step\": 881000}\n",
      "{\"learning_rate\": 1.4230644375913003e-05, \"loss\": 1.3190645557641982, \"step\": 881500}\n",
      "{\"learning_rate\": 1.4210355461775687e-05, \"loss\": 1.3309774219989776, \"step\": 882000}\n",
      "{\"learning_rate\": 1.419006654763837e-05, \"loss\": 1.3381217507123948, \"step\": 882500}\n",
      "{\"learning_rate\": 1.4169777633501055e-05, \"loss\": 1.3302723671197891, \"step\": 883000}\n",
      "{\"learning_rate\": 1.414948871936374e-05, \"loss\": 1.3467745258808137, \"step\": 883500}\n",
      "{\"learning_rate\": 1.4129199805226426e-05, \"loss\": 1.323515531897545, \"step\": 884000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 1.4108910891089108e-05, \"loss\": 1.3227641572952271, \"step\": 884500}\n",
      "{\"learning_rate\": 1.4088621976951794e-05, \"loss\": 1.3160849746465684, \"step\": 885000}\n",
      "{\"learning_rate\": 1.4068333062814478e-05, \"loss\": 1.3251977037191391, \"step\": 885500}\n",
      "{\"learning_rate\": 1.4048044148677164e-05, \"loss\": 1.3236295803785325, \"step\": 886000}\n",
      "{\"learning_rate\": 1.4027755234539849e-05, \"loss\": 1.3035841497778893, \"step\": 886500}\n",
      "{\"learning_rate\": 1.4007466320402531e-05, \"loss\": 1.3272311924099922, \"step\": 887000}\n",
      "{\"learning_rate\": 1.3987177406265217e-05, \"loss\": 1.3279775449037552, \"step\": 887500}\n",
      "{\"learning_rate\": 1.3966888492127903e-05, \"loss\": 1.3046665771007537, \"step\": 888000}\n",
      "{\"learning_rate\": 1.3946599577990587e-05, \"loss\": 1.30213351726532, \"step\": 888500}\n",
      "{\"learning_rate\": 1.392631066385327e-05, \"loss\": 1.3365437886714935, \"step\": 889000}\n",
      "{\"learning_rate\": 1.3906021749715956e-05, \"loss\": 1.3433624626398086, \"step\": 889500}\n",
      "{\"learning_rate\": 1.388573283557864e-05, \"loss\": 1.3322858997583389, \"step\": 890000}\n",
      "{\"learning_rate\": 1.3865443921441326e-05, \"loss\": 1.3238551536798477, \"step\": 890500}\n",
      "{\"learning_rate\": 1.3845155007304009e-05, \"loss\": 1.342788293004036, \"step\": 891000}\n",
      "{\"learning_rate\": 1.3824866093166695e-05, \"loss\": 1.3241114592552186, \"step\": 891500}\n",
      "{\"learning_rate\": 1.3804577179029379e-05, \"loss\": 1.3414622554779052, \"step\": 892000}\n",
      "{\"learning_rate\": 1.3784288264892065e-05, \"loss\": 1.3397636359930039, \"step\": 892500}\n",
      "{\"learning_rate\": 1.3763999350754747e-05, \"loss\": 1.3163645733594895, \"step\": 893000}\n",
      "{\"learning_rate\": 1.3743710436617433e-05, \"loss\": 1.3158474826216697, \"step\": 893500}\n",
      "{\"learning_rate\": 1.3723421522480117e-05, \"loss\": 1.3031371532678604, \"step\": 894000}\n",
      "{\"learning_rate\": 1.3703132608342803e-05, \"loss\": 1.3080845426917076, \"step\": 894500}\n",
      "{\"learning_rate\": 1.3682843694205486e-05, \"loss\": 1.3255734429359436, \"step\": 895000}\n",
      "{\"learning_rate\": 1.366255478006817e-05, \"loss\": 1.3213184444904327, \"step\": 895500}\n",
      "{\"learning_rate\": 1.3642265865930856e-05, \"loss\": 1.3277996668815613, \"step\": 896000}\n",
      "{\"learning_rate\": 1.3621976951793542e-05, \"loss\": 1.3264787147045136, \"step\": 896500}\n",
      "{\"learning_rate\": 1.3601688037656225e-05, \"loss\": 1.3219108028411866, \"step\": 897000}\n",
      "{\"learning_rate\": 1.3581399123518909e-05, \"loss\": 1.3171125712394713, \"step\": 897500}\n",
      "{\"learning_rate\": 1.3561110209381595e-05, \"loss\": 1.3177448647022247, \"step\": 898000}\n",
      "{\"learning_rate\": 1.3540821295244279e-05, \"loss\": 1.3205358436107635, \"step\": 898500}\n",
      "{\"learning_rate\": 1.3520532381106965e-05, \"loss\": 1.3275323716402054, \"step\": 899000}\n",
      "{\"learning_rate\": 1.3500243466969648e-05, \"loss\": 1.3361965465545653, \"step\": 899500}\n",
      "{\"learning_rate\": 1.3479954552832334e-05, \"loss\": 1.2991935942173005, \"step\": 900000}\n",
      "{\"learning_rate\": 1.3459665638695018e-05, \"loss\": 1.3355812209844589, \"step\": 900500}\n",
      "{\"learning_rate\": 1.3439376724557704e-05, \"loss\": 1.3343523602485656, \"step\": 901000}\n",
      "{\"learning_rate\": 1.3419087810420386e-05, \"loss\": 1.3232965584993361, \"step\": 901500}\n",
      "{\"learning_rate\": 1.339879889628307e-05, \"loss\": 1.3301715081334113, \"step\": 902000}\n",
      "{\"learning_rate\": 1.3378509982145756e-05, \"loss\": 1.3119274813532829, \"step\": 902500}\n",
      "{\"learning_rate\": 1.3358221068008442e-05, \"loss\": 1.3106995429396628, \"step\": 903000}\n",
      "{\"learning_rate\": 1.3337932153871125e-05, \"loss\": 1.3030653331279756, \"step\": 903500}\n",
      "{\"learning_rate\": 1.331764323973381e-05, \"loss\": 1.3136835844516754, \"step\": 904000}\n",
      "{\"learning_rate\": 1.3297354325596495e-05, \"loss\": 1.3473094788193702, \"step\": 904500}\n",
      "{\"learning_rate\": 1.327706541145918e-05, \"loss\": 1.2918696269989014, \"step\": 905000}\n",
      "{\"learning_rate\": 1.3256776497321862e-05, \"loss\": 1.3317126873731613, \"step\": 905500}\n",
      "{\"learning_rate\": 1.3236487583184548e-05, \"loss\": 1.3330129072666168, \"step\": 906000}\n",
      "{\"learning_rate\": 1.3216198669047234e-05, \"loss\": 1.3153360104560852, \"step\": 906500}\n",
      "{\"learning_rate\": 1.3195909754909918e-05, \"loss\": 1.317763351917267, \"step\": 907000}\n",
      "{\"learning_rate\": 1.31756208407726e-05, \"loss\": 1.3484994131326675, \"step\": 907500}\n",
      "{\"learning_rate\": 1.3155331926635287e-05, \"loss\": 1.3377236627340316, \"step\": 908000}\n",
      "{\"learning_rate\": 1.3135043012497973e-05, \"loss\": 1.3167396854758262, \"step\": 908500}\n",
      "{\"learning_rate\": 1.3114754098360657e-05, \"loss\": 1.3044701006412507, \"step\": 909000}\n",
      "{\"learning_rate\": 1.3094465184223343e-05, \"loss\": 1.3265392278432846, \"step\": 909500}\n",
      "{\"learning_rate\": 1.3074176270086025e-05, \"loss\": 1.3157156566381454, \"step\": 910000}\n",
      "{\"learning_rate\": 1.305388735594871e-05, \"loss\": 1.3351037465929985, \"step\": 910500}\n",
      "{\"learning_rate\": 1.3033598441811396e-05, \"loss\": 1.3257455540299417, \"step\": 911000}\n",
      "{\"learning_rate\": 1.3013309527674081e-05, \"loss\": 1.3108325264453888, \"step\": 911500}\n",
      "{\"learning_rate\": 1.2993020613536764e-05, \"loss\": 1.3253990290164948, \"step\": 912000}\n",
      "{\"learning_rate\": 1.2972731699399448e-05, \"loss\": 1.2994235812425614, \"step\": 912500}\n",
      "{\"learning_rate\": 1.2952442785262134e-05, \"loss\": 1.3192464872598648, \"step\": 913000}\n",
      "{\"learning_rate\": 1.2932153871124818e-05, \"loss\": 1.3362418152093887, \"step\": 913500}\n",
      "{\"learning_rate\": 1.2911864956987501e-05, \"loss\": 1.3151952372789384, \"step\": 914000}\n",
      "{\"learning_rate\": 1.2891576042850187e-05, \"loss\": 1.3316001141071319, \"step\": 914500}\n",
      "{\"learning_rate\": 1.2871287128712873e-05, \"loss\": 1.3174345186948777, \"step\": 915000}\n",
      "{\"learning_rate\": 1.2850998214575557e-05, \"loss\": 1.314706190109253, \"step\": 915500}\n",
      "{\"learning_rate\": 1.283070930043824e-05, \"loss\": 1.3131136827468872, \"step\": 916000}\n",
      "{\"learning_rate\": 1.2810420386300926e-05, \"loss\": 1.3141131608486176, \"step\": 916500}\n",
      "{\"learning_rate\": 1.279013147216361e-05, \"loss\": 1.3344302915334703, \"step\": 917000}\n",
      "{\"learning_rate\": 1.2769842558026296e-05, \"loss\": 1.2998719984292983, \"step\": 917500}\n",
      "{\"learning_rate\": 1.2749553643888978e-05, \"loss\": 1.311436767578125, \"step\": 918000}\n",
      "{\"learning_rate\": 1.2729264729751664e-05, \"loss\": 1.3067249020338059, \"step\": 918500}\n",
      "{\"learning_rate\": 1.2708975815614349e-05, \"loss\": 1.320580850481987, \"step\": 919000}\n",
      "{\"learning_rate\": 1.2688686901477035e-05, \"loss\": 1.303546490907669, \"step\": 919500}\n",
      "{\"learning_rate\": 1.2668397987339717e-05, \"loss\": 1.3332745784521103, \"step\": 920000}\n",
      "{\"learning_rate\": 1.2648109073202401e-05, \"loss\": 1.3044197428226472, \"step\": 920500}\n",
      "{\"learning_rate\": 1.2627820159065087e-05, \"loss\": 1.3300364905595778, \"step\": 921000}\n",
      "{\"learning_rate\": 1.2607531244927773e-05, \"loss\": 1.324483905673027, \"step\": 921500}\n",
      "{\"learning_rate\": 1.2587242330790457e-05, \"loss\": 1.3232884587049485, \"step\": 922000}\n",
      "{\"learning_rate\": 1.256695341665314e-05, \"loss\": 1.3093127194643022, \"step\": 922500}\n",
      "{\"learning_rate\": 1.2546664502515826e-05, \"loss\": 1.3088669904470445, \"step\": 923000}\n",
      "{\"learning_rate\": 1.2526375588378512e-05, \"loss\": 1.3083778125047685, \"step\": 923500}\n",
      "{\"learning_rate\": 1.2506086674241196e-05, \"loss\": 1.3144807053804397, \"step\": 924000}\n",
      "{\"learning_rate\": 1.248579776010388e-05, \"loss\": 1.3196031180620194, \"step\": 924500}\n",
      "{\"learning_rate\": 1.2465508845966565e-05, \"loss\": 1.318321002960205, \"step\": 925000}\n",
      "{\"learning_rate\": 1.2445219931829249e-05, \"loss\": 1.2971185405254364, \"step\": 925500}\n",
      "{\"learning_rate\": 1.2424931017691933e-05, \"loss\": 1.3333774564266205, \"step\": 926000}\n",
      "{\"learning_rate\": 1.2404642103554619e-05, \"loss\": 1.3117175685167313, \"step\": 926500}\n",
      "{\"learning_rate\": 1.2384353189417303e-05, \"loss\": 1.3632756608724594, \"step\": 927000}\n",
      "{\"learning_rate\": 1.2364064275279988e-05, \"loss\": 1.3108475489616394, \"step\": 927500}\n",
      "{\"learning_rate\": 1.2343775361142672e-05, \"loss\": 1.3358015716075897, \"step\": 928000}\n",
      "{\"learning_rate\": 1.2323486447005358e-05, \"loss\": 1.3147526960372924, \"step\": 928500}\n",
      "{\"learning_rate\": 1.230319753286804e-05, \"loss\": 1.300729650735855, \"step\": 929000}\n",
      "{\"learning_rate\": 1.2282908618730726e-05, \"loss\": 1.3252140786647797, \"step\": 929500}\n",
      "{\"learning_rate\": 1.226261970459341e-05, \"loss\": 1.3150280406475068, \"step\": 930000}\n",
      "{\"learning_rate\": 1.2242330790456095e-05, \"loss\": 1.309969875574112, \"step\": 930500}\n",
      "{\"learning_rate\": 1.2222041876318779e-05, \"loss\": 1.3059049913287162, \"step\": 931000}\n",
      "{\"learning_rate\": 1.2201752962181465e-05, \"loss\": 1.2792647622823716, \"step\": 931500}\n",
      "{\"learning_rate\": 1.218146404804415e-05, \"loss\": 1.298720274925232, \"step\": 932000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 1.2161175133906834e-05, \"loss\": 1.31106216275692, \"step\": 932500}\n",
      "{\"learning_rate\": 1.214088621976952e-05, \"loss\": 1.3402301832437515, \"step\": 933000}\n",
      "{\"learning_rate\": 1.2120597305632204e-05, \"loss\": 1.3150762270689011, \"step\": 933500}\n",
      "{\"learning_rate\": 1.2100308391494888e-05, \"loss\": 1.3265742626190185, \"step\": 934000}\n",
      "{\"learning_rate\": 1.2080019477357572e-05, \"loss\": 1.3320905768871307, \"step\": 934500}\n",
      "{\"learning_rate\": 1.2059730563220258e-05, \"loss\": 1.3166250885725022, \"step\": 935000}\n",
      "{\"learning_rate\": 1.203944164908294e-05, \"loss\": 1.3158378969430924, \"step\": 935500}\n",
      "{\"learning_rate\": 1.2019152734945627e-05, \"loss\": 1.2974478902816773, \"step\": 936000}\n",
      "{\"learning_rate\": 1.1998863820808311e-05, \"loss\": 1.3162614876031875, \"step\": 936500}\n",
      "{\"learning_rate\": 1.1978574906670995e-05, \"loss\": 1.3155238993167877, \"step\": 937000}\n",
      "{\"learning_rate\": 1.195828599253368e-05, \"loss\": 1.31269797539711, \"step\": 937500}\n",
      "{\"learning_rate\": 1.1937997078396365e-05, \"loss\": 1.3409275901913642, \"step\": 938000}\n",
      "{\"learning_rate\": 1.191770816425905e-05, \"loss\": 1.3427429602146148, \"step\": 938500}\n",
      "{\"learning_rate\": 1.1897419250121734e-05, \"loss\": 1.297416061282158, \"step\": 939000}\n",
      "{\"learning_rate\": 1.1877130335984418e-05, \"loss\": 1.3158653440475463, \"step\": 939500}\n",
      "{\"learning_rate\": 1.1856841421847104e-05, \"loss\": 1.3017428375482558, \"step\": 940000}\n",
      "{\"learning_rate\": 1.1836552507709788e-05, \"loss\": 1.3061119484305381, \"step\": 940500}\n",
      "{\"learning_rate\": 1.1816263593572473e-05, \"loss\": 1.3169890998601914, \"step\": 941000}\n",
      "{\"learning_rate\": 1.1795974679435157e-05, \"loss\": 1.2836201891899108, \"step\": 941500}\n",
      "{\"learning_rate\": 1.1775685765297843e-05, \"loss\": 1.2903574030399323, \"step\": 942000}\n",
      "{\"learning_rate\": 1.1755396851160525e-05, \"loss\": 1.2942245531082153, \"step\": 942500}\n",
      "{\"learning_rate\": 1.1735107937023211e-05, \"loss\": 1.320965391755104, \"step\": 943000}\n",
      "{\"learning_rate\": 1.1714819022885895e-05, \"loss\": 1.3069727721214295, \"step\": 943500}\n",
      "{\"learning_rate\": 1.169453010874858e-05, \"loss\": 1.3121515226364135, \"step\": 944000}\n",
      "{\"learning_rate\": 1.1674241194611266e-05, \"loss\": 1.2767228858470916, \"step\": 944500}\n",
      "{\"learning_rate\": 1.165395228047395e-05, \"loss\": 1.3053608759641648, \"step\": 945000}\n",
      "{\"learning_rate\": 1.1633663366336634e-05, \"loss\": 1.3256169510483742, \"step\": 945500}\n",
      "{\"learning_rate\": 1.1613374452199318e-05, \"loss\": 1.3123834071159364, \"step\": 946000}\n",
      "{\"learning_rate\": 1.1593085538062004e-05, \"loss\": 1.301105622291565, \"step\": 946500}\n",
      "{\"learning_rate\": 1.1572796623924689e-05, \"loss\": 1.3050978524684906, \"step\": 947000}\n",
      "{\"learning_rate\": 1.1552507709787373e-05, \"loss\": 1.310951813519001, \"step\": 947500}\n",
      "{\"learning_rate\": 1.1532218795650057e-05, \"loss\": 1.3362375831604003, \"step\": 948000}\n",
      "{\"learning_rate\": 1.1511929881512743e-05, \"loss\": 1.2876466788053513, \"step\": 948500}\n",
      "{\"learning_rate\": 1.1491640967375426e-05, \"loss\": 1.2995616821050644, \"step\": 949000}\n",
      "{\"learning_rate\": 1.1471352053238112e-05, \"loss\": 1.3060765253305435, \"step\": 949500}\n",
      "{\"learning_rate\": 1.1451063139100796e-05, \"loss\": 1.3177579256296157, \"step\": 950000}\n",
      "{\"learning_rate\": 1.143077422496348e-05, \"loss\": 1.312354439496994, \"step\": 950500}\n",
      "{\"learning_rate\": 1.1410485310826164e-05, \"loss\": 1.31308265042305, \"step\": 951000}\n",
      "{\"learning_rate\": 1.139019639668885e-05, \"loss\": 1.3085153367519378, \"step\": 951500}\n",
      "{\"learning_rate\": 1.1369907482551535e-05, \"loss\": 1.3154673098325729, \"step\": 952000}\n",
      "{\"learning_rate\": 1.1349618568414219e-05, \"loss\": 1.289511372566223, \"step\": 952500}\n",
      "{\"learning_rate\": 1.1329329654276903e-05, \"loss\": 1.3060422534942626, \"step\": 953000}\n",
      "{\"learning_rate\": 1.1309040740139589e-05, \"loss\": 1.3319526597261429, \"step\": 953500}\n",
      "{\"learning_rate\": 1.1288751826002272e-05, \"loss\": 1.3162093873023988, \"step\": 954000}\n",
      "{\"learning_rate\": 1.1268462911864957e-05, \"loss\": 1.2925345360040665, \"step\": 954500}\n",
      "{\"learning_rate\": 1.1248173997727642e-05, \"loss\": 1.3103041738271712, \"step\": 955000}\n",
      "{\"learning_rate\": 1.1227885083590328e-05, \"loss\": 1.3067278106212616, \"step\": 955500}\n",
      "{\"learning_rate\": 1.120759616945301e-05, \"loss\": 1.3239154106378554, \"step\": 956000}\n",
      "{\"learning_rate\": 1.1187307255315696e-05, \"loss\": 1.3017369729280472, \"step\": 956500}\n",
      "{\"learning_rate\": 1.1167018341178382e-05, \"loss\": 1.3043440096974372, \"step\": 957000}\n",
      "{\"learning_rate\": 1.1146729427041065e-05, \"loss\": 1.2927744512557984, \"step\": 957500}\n",
      "{\"learning_rate\": 1.112644051290375e-05, \"loss\": 1.303490015387535, \"step\": 958000}\n",
      "{\"learning_rate\": 1.1106151598766435e-05, \"loss\": 1.310294085085392, \"step\": 958500}\n",
      "{\"learning_rate\": 1.1085862684629119e-05, \"loss\": 1.3192225497961045, \"step\": 959000}\n",
      "{\"learning_rate\": 1.1065573770491803e-05, \"loss\": 1.2904648818969726, \"step\": 959500}\n",
      "{\"learning_rate\": 1.104528485635449e-05, \"loss\": 1.302490013718605, \"step\": 960000}\n",
      "{\"learning_rate\": 1.1024995942217174e-05, \"loss\": 1.3100479977726935, \"step\": 960500}\n",
      "{\"learning_rate\": 1.1004707028079858e-05, \"loss\": 1.3070923416614533, \"step\": 961000}\n",
      "{\"learning_rate\": 1.0984418113942542e-05, \"loss\": 1.2938164155483245, \"step\": 961500}\n",
      "{\"learning_rate\": 1.0964129199805228e-05, \"loss\": 1.297573192536831, \"step\": 962000}\n",
      "{\"learning_rate\": 1.094384028566791e-05, \"loss\": 1.3267010637521743, \"step\": 962500}\n",
      "{\"learning_rate\": 1.0923551371530596e-05, \"loss\": 1.2774768356084825, \"step\": 963000}\n",
      "{\"learning_rate\": 1.090326245739328e-05, \"loss\": 1.3167831366062164, \"step\": 963500}\n",
      "{\"learning_rate\": 1.0882973543255965e-05, \"loss\": 1.303874078452587, \"step\": 964000}\n",
      "{\"learning_rate\": 1.086268462911865e-05, \"loss\": 1.2897569360733032, \"step\": 964500}\n",
      "{\"learning_rate\": 1.0842395714981335e-05, \"loss\": 1.3232716983556747, \"step\": 965000}\n",
      "{\"learning_rate\": 1.082210680084402e-05, \"loss\": 1.3355316724181174, \"step\": 965500}\n",
      "{\"learning_rate\": 1.0801817886706704e-05, \"loss\": 1.3210318145751954, \"step\": 966000}\n",
      "{\"learning_rate\": 1.0781528972569388e-05, \"loss\": 1.307443044066429, \"step\": 966500}\n",
      "{\"learning_rate\": 1.0761240058432074e-05, \"loss\": 1.2817198628187179, \"step\": 967000}\n",
      "{\"learning_rate\": 1.0740951144294756e-05, \"loss\": 1.325012376666069, \"step\": 967500}\n",
      "{\"learning_rate\": 1.0720662230157442e-05, \"loss\": 1.330408500313759, \"step\": 968000}\n",
      "{\"learning_rate\": 1.0700373316020128e-05, \"loss\": 1.3559224784374238, \"step\": 968500}\n",
      "{\"learning_rate\": 1.0680084401882811e-05, \"loss\": 1.2844645668268204, \"step\": 969000}\n",
      "{\"learning_rate\": 1.0659795487745497e-05, \"loss\": 1.302486527323723, \"step\": 969500}\n",
      "{\"learning_rate\": 1.0639506573608181e-05, \"loss\": 1.2890965964198113, \"step\": 970000}\n",
      "{\"learning_rate\": 1.0619217659470867e-05, \"loss\": 1.3068724901676179, \"step\": 970500}\n",
      "{\"learning_rate\": 1.059892874533355e-05, \"loss\": 1.2948502666950226, \"step\": 971000}\n",
      "{\"learning_rate\": 1.0578639831196236e-05, \"loss\": 1.3060869252681733, \"step\": 971500}\n",
      "{\"learning_rate\": 1.055835091705892e-05, \"loss\": 1.31449975502491, \"step\": 972000}\n",
      "{\"learning_rate\": 1.0538062002921604e-05, \"loss\": 1.3417563061714173, \"step\": 972500}\n",
      "{\"learning_rate\": 1.0517773088784288e-05, \"loss\": 1.2775877679586412, \"step\": 973000}\n",
      "{\"learning_rate\": 1.0497484174646974e-05, \"loss\": 1.2921332483291625, \"step\": 973500}\n",
      "{\"learning_rate\": 1.0477195260509658e-05, \"loss\": 1.320921920835972, \"step\": 974000}\n",
      "{\"learning_rate\": 1.0456906346372343e-05, \"loss\": 1.308268311738968, \"step\": 974500}\n",
      "{\"learning_rate\": 1.0436617432235027e-05, \"loss\": 1.29866277885437, \"step\": 975000}\n",
      "{\"learning_rate\": 1.0416328518097713e-05, \"loss\": 1.308483524799347, \"step\": 975500}\n",
      "{\"learning_rate\": 1.0396039603960395e-05, \"loss\": 1.3065525377988816, \"step\": 976000}\n",
      "{\"learning_rate\": 1.0375750689823081e-05, \"loss\": 1.3313197630643845, \"step\": 976500}\n",
      "{\"learning_rate\": 1.0355461775685766e-05, \"loss\": 1.3083402434587479, \"step\": 977000}\n",
      "{\"learning_rate\": 1.033517286154845e-05, \"loss\": 1.2971457978487015, \"step\": 977500}\n",
      "{\"learning_rate\": 1.0314883947411134e-05, \"loss\": 1.311527938723564, \"step\": 978000}\n",
      "{\"learning_rate\": 1.029459503327382e-05, \"loss\": 1.3124946123361587, \"step\": 978500}\n",
      "{\"learning_rate\": 1.0274306119136504e-05, \"loss\": 1.3054685130119323, \"step\": 979000}\n",
      "{\"learning_rate\": 1.0254017204999189e-05, \"loss\": 1.2909026435613633, \"step\": 979500}\n",
      "{\"learning_rate\": 1.0233728290861875e-05, \"loss\": 1.310058287024498, \"step\": 980000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 1.0213439376724559e-05, \"loss\": 1.3029207339286804, \"step\": 980500}\n",
      "{\"learning_rate\": 1.0193150462587243e-05, \"loss\": 1.2904956755638122, \"step\": 981000}\n",
      "{\"learning_rate\": 1.0172861548449927e-05, \"loss\": 1.3023320500850677, \"step\": 981500}\n",
      "{\"learning_rate\": 1.0152572634312613e-05, \"loss\": 1.2791064519882203, \"step\": 982000}\n",
      "{\"learning_rate\": 1.0132283720175296e-05, \"loss\": 1.313620969414711, \"step\": 982500}\n",
      "{\"learning_rate\": 1.0111994806037982e-05, \"loss\": 1.2930543764829636, \"step\": 983000}\n",
      "{\"learning_rate\": 1.0091705891900666e-05, \"loss\": 1.2986779861450195, \"step\": 983500}\n",
      "{\"learning_rate\": 1.007141697776335e-05, \"loss\": 1.2897263371944427, \"step\": 984000}\n",
      "{\"learning_rate\": 1.0051128063626034e-05, \"loss\": 1.3246774456501007, \"step\": 984500}\n",
      "{\"learning_rate\": 1.003083914948872e-05, \"loss\": 1.338060205221176, \"step\": 985000}\n",
      "{\"learning_rate\": 1.0010550235351405e-05, \"loss\": 1.293686448097229, \"step\": 985500}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "076b3b7cf80a4706af242dc7e37cd345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=246440.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 9.990261321214089e-06, \"loss\": 1.297412528216839, \"step\": 986000}\n",
      "{\"learning_rate\": 9.969972407076773e-06, \"loss\": 1.282992022573948, \"step\": 986500}\n",
      "{\"learning_rate\": 9.949683492939459e-06, \"loss\": 1.2940843108892441, \"step\": 987000}\n",
      "{\"learning_rate\": 9.929394578802143e-06, \"loss\": 1.283890133857727, \"step\": 987500}\n",
      "{\"learning_rate\": 9.909105664664828e-06, \"loss\": 1.3096230722665787, \"step\": 988000}\n",
      "{\"learning_rate\": 9.888816750527512e-06, \"loss\": 1.2764560493230819, \"step\": 988500}\n",
      "{\"learning_rate\": 9.868527836390198e-06, \"loss\": 1.2951607362031936, \"step\": 989000}\n",
      "{\"learning_rate\": 9.84823892225288e-06, \"loss\": 1.2720163358449936, \"step\": 989500}\n",
      "{\"learning_rate\": 9.827950008115566e-06, \"loss\": 1.3180661995410918, \"step\": 990000}\n",
      "{\"learning_rate\": 9.80766109397825e-06, \"loss\": 1.2849779943823814, \"step\": 990500}\n",
      "{\"learning_rate\": 9.787372179840935e-06, \"loss\": 1.2958510301709174, \"step\": 991000}\n",
      "{\"learning_rate\": 9.76708326570362e-06, \"loss\": 1.3101927233934403, \"step\": 991500}\n",
      "{\"learning_rate\": 9.746794351566305e-06, \"loss\": 1.318072112083435, \"step\": 992000}\n",
      "{\"learning_rate\": 9.72650543742899e-06, \"loss\": 1.2928240740299224, \"step\": 992500}\n",
      "{\"learning_rate\": 9.706216523291674e-06, \"loss\": 1.3098156245350838, \"step\": 993000}\n",
      "{\"learning_rate\": 9.68592760915436e-06, \"loss\": 1.3198120535612106, \"step\": 993500}\n",
      "{\"learning_rate\": 9.665638695017044e-06, \"loss\": 1.2950229555368424, \"step\": 994000}\n",
      "{\"learning_rate\": 9.645349780879728e-06, \"loss\": 1.3118118883371352, \"step\": 994500}\n",
      "{\"learning_rate\": 9.625060866742412e-06, \"loss\": 1.3193933304548264, \"step\": 995000}\n",
      "{\"learning_rate\": 9.604771952605098e-06, \"loss\": 1.3133441860675812, \"step\": 995500}\n",
      "{\"learning_rate\": 9.58448303846778e-06, \"loss\": 1.2925994510650636, \"step\": 996000}\n",
      "{\"learning_rate\": 9.564194124330467e-06, \"loss\": 1.2710798715949059, \"step\": 996500}\n",
      "{\"learning_rate\": 9.543905210193151e-06, \"loss\": 1.296040770292282, \"step\": 997000}\n",
      "{\"learning_rate\": 9.523616296055835e-06, \"loss\": 1.3025653575658798, \"step\": 997500}\n",
      "{\"learning_rate\": 9.50332738191852e-06, \"loss\": 1.2900243041515351, \"step\": 998000}\n",
      "{\"learning_rate\": 9.483038467781205e-06, \"loss\": 1.2663397719860077, \"step\": 998500}\n",
      "{\"learning_rate\": 9.46274955364389e-06, \"loss\": 1.308232297539711, \"step\": 999000}\n",
      "{\"learning_rate\": 9.442460639506574e-06, \"loss\": 1.2725001359581947, \"step\": 999500}\n",
      "{\"learning_rate\": 9.422171725369258e-06, \"loss\": 1.2885503751635552, \"step\": 1000000}\n",
      "{\"learning_rate\": 9.401882811231944e-06, \"loss\": 1.2771827572584151, \"step\": 1000500}\n",
      "{\"learning_rate\": 9.381593897094627e-06, \"loss\": 1.282825756907463, \"step\": 1001000}\n",
      "{\"learning_rate\": 9.361304982957313e-06, \"loss\": 1.2842954971790315, \"step\": 1001500}\n",
      "{\"learning_rate\": 9.341016068819997e-06, \"loss\": 1.2888853932023048, \"step\": 1002000}\n",
      "{\"learning_rate\": 9.320727154682681e-06, \"loss\": 1.3042433755993843, \"step\": 1002500}\n",
      "{\"learning_rate\": 9.300438240545365e-06, \"loss\": 1.277362290084362, \"step\": 1003000}\n",
      "{\"learning_rate\": 9.280149326408051e-06, \"loss\": 1.2875830891132354, \"step\": 1003500}\n",
      "{\"learning_rate\": 9.259860412270737e-06, \"loss\": 1.2898390781283378, \"step\": 1004000}\n",
      "{\"learning_rate\": 9.23957149813342e-06, \"loss\": 1.3088447909355163, \"step\": 1004500}\n",
      "{\"learning_rate\": 9.219282583996106e-06, \"loss\": 1.295101213335991, \"step\": 1005000}\n",
      "{\"learning_rate\": 9.19899366985879e-06, \"loss\": 1.3043654814958572, \"step\": 1005500}\n",
      "{\"learning_rate\": 9.178704755721474e-06, \"loss\": 1.304851368188858, \"step\": 1006000}\n",
      "{\"learning_rate\": 9.158415841584158e-06, \"loss\": 1.2645714808702468, \"step\": 1006500}\n",
      "{\"learning_rate\": 9.138126927446844e-06, \"loss\": 1.3150404229164123, \"step\": 1007000}\n",
      "{\"learning_rate\": 9.117838013309529e-06, \"loss\": 1.3087666691541673, \"step\": 1007500}\n",
      "{\"learning_rate\": 9.097549099172213e-06, \"loss\": 1.283764777302742, \"step\": 1008000}\n",
      "{\"learning_rate\": 9.077260185034897e-06, \"loss\": 1.2811906559467316, \"step\": 1008500}\n",
      "{\"learning_rate\": 9.056971270897583e-06, \"loss\": 1.2707783011198044, \"step\": 1009000}\n",
      "{\"learning_rate\": 9.036682356760266e-06, \"loss\": 1.2741923187971116, \"step\": 1009500}\n",
      "{\"learning_rate\": 9.016393442622952e-06, \"loss\": 1.2906892766952516, \"step\": 1010000}\n",
      "{\"learning_rate\": 8.996104528485636e-06, \"loss\": 1.3004575452804565, \"step\": 1010500}\n",
      "{\"learning_rate\": 8.97581561434832e-06, \"loss\": 1.2805178171396256, \"step\": 1011000}\n",
      "{\"learning_rate\": 8.955526700211004e-06, \"loss\": 1.2894300751686096, \"step\": 1011500}\n",
      "{\"learning_rate\": 8.93523778607369e-06, \"loss\": 1.28270003926754, \"step\": 1012000}\n",
      "{\"learning_rate\": 8.914948871936375e-06, \"loss\": 1.29064654815197, \"step\": 1012500}\n",
      "{\"learning_rate\": 8.894659957799059e-06, \"loss\": 1.3169814896583558, \"step\": 1013000}\n",
      "{\"learning_rate\": 8.874371043661743e-06, \"loss\": 1.292824587225914, \"step\": 1013500}\n",
      "{\"learning_rate\": 8.854082129524429e-06, \"loss\": 1.3159494074583054, \"step\": 1014000}\n",
      "{\"learning_rate\": 8.833793215387112e-06, \"loss\": 1.280269102692604, \"step\": 1014500}\n",
      "{\"learning_rate\": 8.813504301249797e-06, \"loss\": 1.2967410778999329, \"step\": 1015000}\n",
      "{\"learning_rate\": 8.793215387112483e-06, \"loss\": 1.2932874122858047, \"step\": 1015500}\n",
      "{\"learning_rate\": 8.772926472975166e-06, \"loss\": 1.303285253763199, \"step\": 1016000}\n",
      "{\"learning_rate\": 8.752637558837852e-06, \"loss\": 1.2859361877441406, \"step\": 1016500}\n",
      "{\"learning_rate\": 8.732348644700536e-06, \"loss\": 1.265197582244873, \"step\": 1017000}\n",
      "{\"learning_rate\": 8.71205973056322e-06, \"loss\": 1.3216838448047639, \"step\": 1017500}\n",
      "{\"learning_rate\": 8.691770816425905e-06, \"loss\": 1.2930197224617004, \"step\": 1018000}\n",
      "{\"learning_rate\": 8.67148190228859e-06, \"loss\": 1.283702375292778, \"step\": 1018500}\n",
      "{\"learning_rate\": 8.651192988151275e-06, \"loss\": 1.2762084350585938, \"step\": 1019000}\n",
      "{\"learning_rate\": 8.630904074013959e-06, \"loss\": 1.2816371432542801, \"step\": 1019500}\n",
      "{\"learning_rate\": 8.610615159876643e-06, \"loss\": 1.2899345442056656, \"step\": 1020000}\n",
      "{\"learning_rate\": 8.59032624573933e-06, \"loss\": 1.2809112627506256, \"step\": 1020500}\n",
      "{\"learning_rate\": 8.570037331602014e-06, \"loss\": 1.290067847251892, \"step\": 1021000}\n",
      "{\"learning_rate\": 8.549748417464698e-06, \"loss\": 1.2940769625902175, \"step\": 1021500}\n",
      "{\"learning_rate\": 8.529459503327382e-06, \"loss\": 1.2849481325149537, \"step\": 1022000}\n",
      "{\"learning_rate\": 8.509170589190068e-06, \"loss\": 1.2972494735717774, \"step\": 1022500}\n",
      "{\"learning_rate\": 8.48888167505275e-06, \"loss\": 1.3249121071100236, \"step\": 1023000}\n",
      "{\"learning_rate\": 8.468592760915436e-06, \"loss\": 1.287493678689003, \"step\": 1023500}\n",
      "{\"learning_rate\": 8.44830384677812e-06, \"loss\": 1.2851585416793823, \"step\": 1024000}\n",
      "{\"learning_rate\": 8.428014932640805e-06, \"loss\": 1.306053432226181, \"step\": 1024500}\n",
      "{\"learning_rate\": 8.40772601850349e-06, \"loss\": 1.293576139330864, \"step\": 1025000}\n",
      "{\"learning_rate\": 8.387437104366175e-06, \"loss\": 1.2968010631799698, \"step\": 1025500}\n",
      "{\"learning_rate\": 8.36714819022886e-06, \"loss\": 1.2939455289840698, \"step\": 1026000}\n",
      "{\"learning_rate\": 8.346859276091544e-06, \"loss\": 1.274492864191532, \"step\": 1026500}\n",
      "{\"learning_rate\": 8.32657036195423e-06, \"loss\": 1.2884793059825896, \"step\": 1027000}\n",
      "{\"learning_rate\": 8.306281447816914e-06, \"loss\": 1.2746299489736557, \"step\": 1027500}\n",
      "{\"learning_rate\": 8.285992533679598e-06, \"loss\": 1.285900092959404, \"step\": 1028000}\n",
      "{\"learning_rate\": 8.265703619542282e-06, \"loss\": 1.2778826830387116, \"step\": 1028500}\n",
      "{\"learning_rate\": 8.245414705404968e-06, \"loss\": 1.2855619007349015, \"step\": 1029000}\n",
      "{\"learning_rate\": 8.225125791267651e-06, \"loss\": 1.2923288912177087, \"step\": 1029500}\n",
      "{\"learning_rate\": 8.204836877130337e-06, \"loss\": 1.2747415984869004, \"step\": 1030000}\n",
      "{\"learning_rate\": 8.184547962993021e-06, \"loss\": 1.3196102701425552, \"step\": 1030500}\n",
      "{\"learning_rate\": 8.164259048855705e-06, \"loss\": 1.2976817938089371, \"step\": 1031000}\n",
      "{\"learning_rate\": 8.14397013471839e-06, \"loss\": 1.2873682187795639, \"step\": 1031500}\n",
      "{\"learning_rate\": 8.123681220581076e-06, \"loss\": 1.2847949203252793, \"step\": 1032000}\n",
      "{\"learning_rate\": 8.10339230644376e-06, \"loss\": 1.3174824588298797, \"step\": 1032500}\n",
      "{\"learning_rate\": 8.083103392306444e-06, \"loss\": 1.2901889646053315, \"step\": 1033000}\n",
      "{\"learning_rate\": 8.062814478169128e-06, \"loss\": 1.302708749294281, \"step\": 1033500}\n",
      "{\"learning_rate\": 8.042525564031814e-06, \"loss\": 1.2732622151374817, \"step\": 1034000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 8.022236649894497e-06, \"loss\": 1.3007326887845994, \"step\": 1034500}\n",
      "{\"learning_rate\": 8.001947735757183e-06, \"loss\": 1.296877972126007, \"step\": 1035000}\n",
      "{\"learning_rate\": 7.981658821619867e-06, \"loss\": 1.3061036437749862, \"step\": 1035500}\n",
      "{\"learning_rate\": 7.961369907482553e-06, \"loss\": 1.3106937417984008, \"step\": 1036000}\n",
      "{\"learning_rate\": 7.941080993345235e-06, \"loss\": 1.2955031903386116, \"step\": 1036500}\n",
      "{\"learning_rate\": 7.920792079207921e-06, \"loss\": 1.2886796119213104, \"step\": 1037000}\n",
      "{\"learning_rate\": 7.900503165070606e-06, \"loss\": 1.2985824863910675, \"step\": 1037500}\n",
      "{\"learning_rate\": 7.88021425093329e-06, \"loss\": 1.2920254402160645, \"step\": 1038000}\n",
      "{\"learning_rate\": 7.859925336795974e-06, \"loss\": 1.3107896807193755, \"step\": 1038500}\n",
      "{\"learning_rate\": 7.83963642265866e-06, \"loss\": 1.295791655421257, \"step\": 1039000}\n",
      "{\"learning_rate\": 7.819347508521344e-06, \"loss\": 1.2694955052137376, \"step\": 1039500}\n",
      "{\"learning_rate\": 7.799058594384029e-06, \"loss\": 1.2821785681843758, \"step\": 1040000}\n",
      "{\"learning_rate\": 7.778769680246715e-06, \"loss\": 1.2978761638402938, \"step\": 1040500}\n",
      "{\"learning_rate\": 7.758480766109399e-06, \"loss\": 1.2886476731300354, \"step\": 1041000}\n",
      "{\"learning_rate\": 7.738191851972083e-06, \"loss\": 1.2834008151292802, \"step\": 1041500}\n",
      "{\"learning_rate\": 7.717902937834767e-06, \"loss\": 1.2914203808307647, \"step\": 1042000}\n",
      "{\"learning_rate\": 7.697614023697453e-06, \"loss\": 1.2792416307926178, \"step\": 1042500}\n",
      "{\"learning_rate\": 7.677325109560136e-06, \"loss\": 1.2676851923465728, \"step\": 1043000}\n",
      "{\"learning_rate\": 7.657036195422822e-06, \"loss\": 1.2782994953393936, \"step\": 1043500}\n",
      "{\"learning_rate\": 7.636747281285506e-06, \"loss\": 1.2941959153413773, \"step\": 1044000}\n",
      "{\"learning_rate\": 7.616458367148191e-06, \"loss\": 1.268427155852318, \"step\": 1044500}\n",
      "{\"learning_rate\": 7.5961694530108745e-06, \"loss\": 1.2823145228624344, \"step\": 1045000}\n",
      "{\"learning_rate\": 7.57588053887356e-06, \"loss\": 1.2795816308259964, \"step\": 1045500}\n",
      "{\"learning_rate\": 7.555591624736244e-06, \"loss\": 1.2826324832439422, \"step\": 1046000}\n",
      "{\"learning_rate\": 7.535302710598929e-06, \"loss\": 1.2741638145446776, \"step\": 1046500}\n",
      "{\"learning_rate\": 7.515013796461613e-06, \"loss\": 1.2922607280015945, \"step\": 1047000}\n",
      "{\"learning_rate\": 7.494724882324298e-06, \"loss\": 1.2950848927497864, \"step\": 1047500}\n",
      "{\"learning_rate\": 7.4744359681869825e-06, \"loss\": 1.2838673534989358, \"step\": 1048000}\n",
      "{\"learning_rate\": 7.454147054049668e-06, \"loss\": 1.3231811728477478, \"step\": 1048500}\n",
      "{\"learning_rate\": 7.433858139912352e-06, \"loss\": 1.2873562523126603, \"step\": 1049000}\n",
      "{\"learning_rate\": 7.413569225775037e-06, \"loss\": 1.2807553262114524, \"step\": 1049500}\n",
      "{\"learning_rate\": 7.393280311637721e-06, \"loss\": 1.3049361119270324, \"step\": 1050000}\n",
      "{\"learning_rate\": 7.372991397500406e-06, \"loss\": 1.285604440331459, \"step\": 1050500}\n",
      "{\"learning_rate\": 7.352702483363091e-06, \"loss\": 1.3036362419128418, \"step\": 1051000}\n",
      "{\"learning_rate\": 7.332413569225776e-06, \"loss\": 1.299599950194359, \"step\": 1051500}\n",
      "{\"learning_rate\": 7.312124655088461e-06, \"loss\": 1.2773937985301018, \"step\": 1052000}\n",
      "{\"learning_rate\": 7.291835740951144e-06, \"loss\": 1.2869894572496414, \"step\": 1052500}\n",
      "{\"learning_rate\": 7.27154682681383e-06, \"loss\": 1.3029350531101227, \"step\": 1053000}\n",
      "{\"learning_rate\": 7.2512579126765135e-06, \"loss\": 1.3088702049255372, \"step\": 1053500}\n",
      "{\"learning_rate\": 7.230968998539199e-06, \"loss\": 1.2636050896644593, \"step\": 1054000}\n",
      "{\"learning_rate\": 7.210680084401883e-06, \"loss\": 1.3199131371974946, \"step\": 1054500}\n",
      "{\"learning_rate\": 7.190391170264568e-06, \"loss\": 1.2660476939678191, \"step\": 1055000}\n",
      "{\"learning_rate\": 7.170102256127252e-06, \"loss\": 1.2727761593461038, \"step\": 1055500}\n",
      "{\"learning_rate\": 7.149813341989937e-06, \"loss\": 1.2950724182724953, \"step\": 1056000}\n",
      "{\"learning_rate\": 7.1295244278526215e-06, \"loss\": 1.3018843103647233, \"step\": 1056500}\n",
      "{\"learning_rate\": 7.109235513715307e-06, \"loss\": 1.2966168256998063, \"step\": 1057000}\n",
      "{\"learning_rate\": 7.088946599577991e-06, \"loss\": 1.2788157726526261, \"step\": 1057500}\n",
      "{\"learning_rate\": 7.068657685440676e-06, \"loss\": 1.2884348516464232, \"step\": 1058000}\n",
      "{\"learning_rate\": 7.048368771303359e-06, \"loss\": 1.2589299386739732, \"step\": 1058500}\n",
      "{\"learning_rate\": 7.028079857166045e-06, \"loss\": 1.284942223072052, \"step\": 1059000}\n",
      "{\"learning_rate\": 7.007790943028729e-06, \"loss\": 1.301850962996483, \"step\": 1059500}\n",
      "{\"learning_rate\": 6.987502028891414e-06, \"loss\": 1.2747658420801162, \"step\": 1060000}\n",
      "{\"learning_rate\": 6.967213114754098e-06, \"loss\": 1.2615261201262473, \"step\": 1060500}\n",
      "{\"learning_rate\": 6.946924200616783e-06, \"loss\": 1.280904317498207, \"step\": 1061000}\n",
      "{\"learning_rate\": 6.9266352864794674e-06, \"loss\": 1.2915501227378845, \"step\": 1061500}\n",
      "{\"learning_rate\": 6.9063463723421525e-06, \"loss\": 1.2703914663791656, \"step\": 1062000}\n",
      "{\"learning_rate\": 6.886057458204838e-06, \"loss\": 1.28902649641037, \"step\": 1062500}\n",
      "{\"learning_rate\": 6.865768544067522e-06, \"loss\": 1.290257918715477, \"step\": 1063000}\n",
      "{\"learning_rate\": 6.845479629930207e-06, \"loss\": 1.2834222450256347, \"step\": 1063500}\n",
      "{\"learning_rate\": 6.825190715792891e-06, \"loss\": 1.280002691924572, \"step\": 1064000}\n",
      "{\"learning_rate\": 6.804901801655576e-06, \"loss\": 1.2720373781919478, \"step\": 1064500}\n",
      "{\"learning_rate\": 6.7846128875182606e-06, \"loss\": 1.2785824239253998, \"step\": 1065000}\n",
      "{\"learning_rate\": 6.764323973380946e-06, \"loss\": 1.2773402267694474, \"step\": 1065500}\n",
      "{\"learning_rate\": 6.744035059243629e-06, \"loss\": 1.279895363330841, \"step\": 1066000}\n",
      "{\"learning_rate\": 6.723746145106315e-06, \"loss\": 1.2817276747226716, \"step\": 1066500}\n",
      "{\"learning_rate\": 6.703457230968998e-06, \"loss\": 1.2865154454708099, \"step\": 1067000}\n",
      "{\"learning_rate\": 6.6831683168316835e-06, \"loss\": 1.2799727424383163, \"step\": 1067500}\n",
      "{\"learning_rate\": 6.662879402694368e-06, \"loss\": 1.287459684431553, \"step\": 1068000}\n",
      "{\"learning_rate\": 6.642590488557053e-06, \"loss\": 1.2850864789485932, \"step\": 1068500}\n",
      "{\"learning_rate\": 6.622301574419737e-06, \"loss\": 1.2916127426624298, \"step\": 1069000}\n",
      "{\"learning_rate\": 6.602012660282422e-06, \"loss\": 1.296526391506195, \"step\": 1069500}\n",
      "{\"learning_rate\": 6.5817237461451065e-06, \"loss\": 1.2899410568475724, \"step\": 1070000}\n",
      "{\"learning_rate\": 6.5614348320077916e-06, \"loss\": 1.2958514944314956, \"step\": 1070500}\n",
      "{\"learning_rate\": 6.541145917870475e-06, \"loss\": 1.2800371817350387, \"step\": 1071000}\n",
      "{\"learning_rate\": 6.520857003733161e-06, \"loss\": 1.2893733652234078, \"step\": 1071500}\n",
      "{\"learning_rate\": 6.500568089595844e-06, \"loss\": 1.283579546689987, \"step\": 1072000}\n",
      "{\"learning_rate\": 6.48027917545853e-06, \"loss\": 1.2661037409305573, \"step\": 1072500}\n",
      "{\"learning_rate\": 6.459990261321214e-06, \"loss\": 1.2789920573234559, \"step\": 1073000}\n",
      "{\"learning_rate\": 6.439701347183899e-06, \"loss\": 1.2938292413949966, \"step\": 1073500}\n",
      "{\"learning_rate\": 6.419412433046583e-06, \"loss\": 1.278942031085491, \"step\": 1074000}\n",
      "{\"learning_rate\": 6.399123518909268e-06, \"loss\": 1.2755051590800286, \"step\": 1074500}\n",
      "{\"learning_rate\": 6.378834604771953e-06, \"loss\": 1.2774629398584365, \"step\": 1075000}\n",
      "{\"learning_rate\": 6.3585456906346374e-06, \"loss\": 1.2908997930288315, \"step\": 1075500}\n",
      "{\"learning_rate\": 6.3382567764973225e-06, \"loss\": 1.2823131651878357, \"step\": 1076000}\n",
      "{\"learning_rate\": 6.317967862360007e-06, \"loss\": 1.287897777736187, \"step\": 1076500}\n",
      "{\"learning_rate\": 6.297678948222692e-06, \"loss\": 1.2856739900112153, \"step\": 1077000}\n",
      "{\"learning_rate\": 6.277390034085376e-06, \"loss\": 1.3056979141235352, \"step\": 1077500}\n",
      "{\"learning_rate\": 6.257101119948061e-06, \"loss\": 1.2857628856897354, \"step\": 1078000}\n",
      "{\"learning_rate\": 6.236812205810745e-06, \"loss\": 1.2686660380363464, \"step\": 1078500}\n",
      "{\"learning_rate\": 6.21652329167343e-06, \"loss\": 1.2750104290246964, \"step\": 1079000}\n",
      "{\"learning_rate\": 6.196234377536114e-06, \"loss\": 1.2739577966928481, \"step\": 1079500}\n",
      "{\"learning_rate\": 6.1759454633988e-06, \"loss\": 1.2735277297496796, \"step\": 1080000}\n",
      "{\"learning_rate\": 6.155656549261484e-06, \"loss\": 1.2680149790048598, \"step\": 1080500}\n",
      "{\"learning_rate\": 6.1353676351241684e-06, \"loss\": 1.2771728882789612, \"step\": 1081000}\n",
      "{\"learning_rate\": 6.1150787209868535e-06, \"loss\": 1.287314023911953, \"step\": 1081500}\n",
      "{\"learning_rate\": 6.094789806849538e-06, \"loss\": 1.3060330832600593, \"step\": 1082000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 6.074500892712223e-06, \"loss\": 1.292912920475006, \"step\": 1082500}\n",
      "{\"learning_rate\": 6.054211978574907e-06, \"loss\": 1.2878412790298461, \"step\": 1083000}\n",
      "{\"learning_rate\": 6.033923064437591e-06, \"loss\": 1.2598158628344536, \"step\": 1083500}\n",
      "{\"learning_rate\": 6.0136341503002765e-06, \"loss\": 1.263903661608696, \"step\": 1084000}\n",
      "{\"learning_rate\": 5.993345236162961e-06, \"loss\": 1.3000698479413986, \"step\": 1084500}\n",
      "{\"learning_rate\": 5.973056322025646e-06, \"loss\": 1.2746466190218926, \"step\": 1085000}\n",
      "{\"learning_rate\": 5.95276740788833e-06, \"loss\": 1.2741111152768134, \"step\": 1085500}\n",
      "{\"learning_rate\": 5.932478493751014e-06, \"loss\": 1.2962345304489136, \"step\": 1086000}\n",
      "{\"learning_rate\": 5.912189579613699e-06, \"loss\": 1.2986977437138558, \"step\": 1086500}\n",
      "{\"learning_rate\": 5.891900665476384e-06, \"loss\": 1.26608571267128, \"step\": 1087000}\n",
      "{\"learning_rate\": 5.871611751339069e-06, \"loss\": 1.2718926829099655, \"step\": 1087500}\n",
      "{\"learning_rate\": 5.851322837201753e-06, \"loss\": 1.2577878987789155, \"step\": 1088000}\n",
      "{\"learning_rate\": 5.831033923064438e-06, \"loss\": 1.323761290371418, \"step\": 1088500}\n",
      "{\"learning_rate\": 5.810745008927122e-06, \"loss\": 1.2819894588589669, \"step\": 1089000}\n",
      "{\"learning_rate\": 5.790456094789807e-06, \"loss\": 1.294419147849083, \"step\": 1089500}\n",
      "{\"learning_rate\": 5.770167180652492e-06, \"loss\": 1.3185263097286224, \"step\": 1090000}\n",
      "{\"learning_rate\": 5.749878266515176e-06, \"loss\": 1.3038004686832427, \"step\": 1090500}\n",
      "{\"learning_rate\": 5.729589352377861e-06, \"loss\": 1.288038035452366, \"step\": 1091000}\n",
      "{\"learning_rate\": 5.709300438240545e-06, \"loss\": 1.2941738464832306, \"step\": 1091500}\n",
      "{\"learning_rate\": 5.68901152410323e-06, \"loss\": 1.2988030157089234, \"step\": 1092000}\n",
      "{\"learning_rate\": 5.6687226099659155e-06, \"loss\": 1.2858803843259812, \"step\": 1092500}\n",
      "{\"learning_rate\": 5.6484336958286e-06, \"loss\": 1.2943674784898758, \"step\": 1093000}\n",
      "{\"learning_rate\": 5.628144781691284e-06, \"loss\": 1.290493052959442, \"step\": 1093500}\n",
      "{\"learning_rate\": 5.607855867553969e-06, \"loss\": 1.298401086807251, \"step\": 1094000}\n",
      "{\"learning_rate\": 5.587566953416653e-06, \"loss\": 1.3013337012529373, \"step\": 1094500}\n",
      "{\"learning_rate\": 5.5672780392793384e-06, \"loss\": 1.2803178744316102, \"step\": 1095000}\n",
      "{\"learning_rate\": 5.546989125142023e-06, \"loss\": 1.2728695734739304, \"step\": 1095500}\n",
      "{\"learning_rate\": 5.526700211004708e-06, \"loss\": 1.2809513193964959, \"step\": 1096000}\n",
      "{\"learning_rate\": 5.506411296867392e-06, \"loss\": 1.2655246690511703, \"step\": 1096500}\n",
      "{\"learning_rate\": 5.486122382730076e-06, \"loss\": 1.2753174121379853, \"step\": 1097000}\n",
      "{\"learning_rate\": 5.465833468592761e-06, \"loss\": 1.2581139373779298, \"step\": 1097500}\n",
      "{\"learning_rate\": 5.445544554455446e-06, \"loss\": 1.2820371397733688, \"step\": 1098000}\n",
      "{\"learning_rate\": 5.425255640318131e-06, \"loss\": 1.2514461447000504, \"step\": 1098500}\n",
      "{\"learning_rate\": 5.404966726180815e-06, \"loss\": 1.293602131009102, \"step\": 1099000}\n",
      "{\"learning_rate\": 5.384677812043499e-06, \"loss\": 1.2839645923376084, \"step\": 1099500}\n",
      "{\"learning_rate\": 5.364388897906184e-06, \"loss\": 1.286577236354351, \"step\": 1100000}\n",
      "{\"learning_rate\": 5.344099983768869e-06, \"loss\": 1.2707313933372497, \"step\": 1100500}\n",
      "{\"learning_rate\": 5.323811069631554e-06, \"loss\": 1.2554243408441543, \"step\": 1101000}\n",
      "{\"learning_rate\": 5.303522155494238e-06, \"loss\": 1.2793061056137085, \"step\": 1101500}\n",
      "{\"learning_rate\": 5.283233241356922e-06, \"loss\": 1.3011284223794937, \"step\": 1102000}\n",
      "{\"learning_rate\": 5.262944327219607e-06, \"loss\": 1.2558212835788727, \"step\": 1102500}\n",
      "{\"learning_rate\": 5.2426554130822915e-06, \"loss\": 1.3139840848445892, \"step\": 1103000}\n",
      "{\"learning_rate\": 5.222366498944977e-06, \"loss\": 1.2909349077939987, \"step\": 1103500}\n",
      "{\"learning_rate\": 5.202077584807662e-06, \"loss\": 1.276606158733368, \"step\": 1104000}\n",
      "{\"learning_rate\": 5.181788670670346e-06, \"loss\": 1.2902150083780288, \"step\": 1104500}\n",
      "{\"learning_rate\": 5.161499756533031e-06, \"loss\": 1.2854539752602576, \"step\": 1105000}\n",
      "{\"learning_rate\": 5.141210842395715e-06, \"loss\": 1.2854711855053902, \"step\": 1105500}\n",
      "{\"learning_rate\": 5.1209219282584e-06, \"loss\": 1.265256151676178, \"step\": 1106000}\n",
      "{\"learning_rate\": 5.100633014121085e-06, \"loss\": 1.284097796201706, \"step\": 1106500}\n",
      "{\"learning_rate\": 5.080344099983769e-06, \"loss\": 1.2865251499414443, \"step\": 1107000}\n",
      "{\"learning_rate\": 5.060055185846454e-06, \"loss\": 1.3125762246847152, \"step\": 1107500}\n",
      "{\"learning_rate\": 5.039766271709138e-06, \"loss\": 1.2746390787363053, \"step\": 1108000}\n",
      "{\"learning_rate\": 5.019477357571823e-06, \"loss\": 1.2965911203622817, \"step\": 1108500}\n",
      "{\"learning_rate\": 4.999188443434508e-06, \"loss\": 1.2838654432296752, \"step\": 1109000}\n",
      "{\"learning_rate\": 4.978899529297192e-06, \"loss\": 1.2814078236818314, \"step\": 1109500}\n",
      "{\"learning_rate\": 4.958610615159877e-06, \"loss\": 1.2895119825601578, \"step\": 1110000}\n",
      "{\"learning_rate\": 4.938321701022561e-06, \"loss\": 1.2633988621234893, \"step\": 1110500}\n",
      "{\"learning_rate\": 4.918032786885246e-06, \"loss\": 1.30195956325531, \"step\": 1111000}\n",
      "{\"learning_rate\": 4.8977438727479306e-06, \"loss\": 1.2734852129220962, \"step\": 1111500}\n",
      "{\"learning_rate\": 4.877454958610616e-06, \"loss\": 1.28170260232687, \"step\": 1112000}\n",
      "{\"learning_rate\": 4.8571660444733e-06, \"loss\": 1.2680394232273102, \"step\": 1112500}\n",
      "{\"learning_rate\": 4.836877130335984e-06, \"loss\": 1.2818198689222335, \"step\": 1113000}\n",
      "{\"learning_rate\": 4.816588216198669e-06, \"loss\": 1.2820971798300742, \"step\": 1113500}\n",
      "{\"learning_rate\": 4.7962993020613535e-06, \"loss\": 1.297011323571205, \"step\": 1114000}\n",
      "{\"learning_rate\": 4.776010387924039e-06, \"loss\": 1.2564845241308211, \"step\": 1114500}\n",
      "{\"learning_rate\": 4.755721473786723e-06, \"loss\": 1.2673327308893203, \"step\": 1115000}\n",
      "{\"learning_rate\": 4.735432559649408e-06, \"loss\": 1.265816578745842, \"step\": 1115500}\n",
      "{\"learning_rate\": 4.715143645512093e-06, \"loss\": 1.3025323364138603, \"step\": 1116000}\n",
      "{\"learning_rate\": 4.694854731374777e-06, \"loss\": 1.2663398283720015, \"step\": 1116500}\n",
      "{\"learning_rate\": 4.6745658172374615e-06, \"loss\": 1.2711772026419639, \"step\": 1117000}\n",
      "{\"learning_rate\": 4.654276903100147e-06, \"loss\": 1.2840347592830659, \"step\": 1117500}\n",
      "{\"learning_rate\": 4.633987988962831e-06, \"loss\": 1.2891830178499222, \"step\": 1118000}\n",
      "{\"learning_rate\": 4.613699074825516e-06, \"loss\": 1.2957699239253997, \"step\": 1118500}\n",
      "{\"learning_rate\": 4.5934101606882e-06, \"loss\": 1.293587618947029, \"step\": 1119000}\n",
      "{\"learning_rate\": 4.573121246550885e-06, \"loss\": 1.2726745522022247, \"step\": 1119500}\n",
      "{\"learning_rate\": 4.55283233241357e-06, \"loss\": 1.2816054021120071, \"step\": 1120000}\n",
      "{\"learning_rate\": 4.532543418276254e-06, \"loss\": 1.2734773709774017, \"step\": 1120500}\n",
      "{\"learning_rate\": 4.512254504138939e-06, \"loss\": 1.2628661581277847, \"step\": 1121000}\n",
      "{\"learning_rate\": 4.491965590001623e-06, \"loss\": 1.2638963245749473, \"step\": 1121500}\n",
      "{\"learning_rate\": 4.471676675864308e-06, \"loss\": 1.263294180035591, \"step\": 1122000}\n",
      "{\"learning_rate\": 4.4513877617269925e-06, \"loss\": 1.2717469948530198, \"step\": 1122500}\n",
      "{\"learning_rate\": 4.431098847589677e-06, \"loss\": 1.276927609860897, \"step\": 1123000}\n",
      "{\"learning_rate\": 4.410809933452362e-06, \"loss\": 1.2833084264993668, \"step\": 1123500}\n",
      "{\"learning_rate\": 4.390521019315046e-06, \"loss\": 1.2878593648672103, \"step\": 1124000}\n",
      "{\"learning_rate\": 4.370232105177731e-06, \"loss\": 1.2811158097982407, \"step\": 1124500}\n",
      "{\"learning_rate\": 4.3499431910404155e-06, \"loss\": 1.2853933371305466, \"step\": 1125000}\n",
      "{\"learning_rate\": 4.3296542769031e-06, \"loss\": 1.2865681511163711, \"step\": 1125500}\n",
      "{\"learning_rate\": 4.309365362765785e-06, \"loss\": 1.2737429599761962, \"step\": 1126000}\n",
      "{\"learning_rate\": 4.289076448628469e-06, \"loss\": 1.2609219529032707, \"step\": 1126500}\n",
      "{\"learning_rate\": 4.268787534491154e-06, \"loss\": 1.273177013874054, \"step\": 1127000}\n",
      "{\"learning_rate\": 4.248498620353839e-06, \"loss\": 1.2594988309144974, \"step\": 1127500}\n",
      "{\"learning_rate\": 4.2282097062165235e-06, \"loss\": 1.277026026248932, \"step\": 1128000}\n",
      "{\"learning_rate\": 4.207920792079209e-06, \"loss\": 1.2724016828536988, \"step\": 1128500}\n",
      "{\"learning_rate\": 4.187631877941893e-06, \"loss\": 1.2844851167201996, \"step\": 1129000}\n",
      "{\"learning_rate\": 4.167342963804578e-06, \"loss\": 1.2868270307779313, \"step\": 1129500}\n",
      "{\"learning_rate\": 4.147054049667262e-06, \"loss\": 1.255919836640358, \"step\": 1130000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 4.1267651355299465e-06, \"loss\": 1.2860627691745758, \"step\": 1130500}\n",
      "{\"learning_rate\": 4.1064762213926316e-06, \"loss\": 1.2795404821634293, \"step\": 1131000}\n",
      "{\"learning_rate\": 4.086187307255316e-06, \"loss\": 1.2630192734599113, \"step\": 1131500}\n",
      "{\"learning_rate\": 4.065898393118001e-06, \"loss\": 1.2701977671980857, \"step\": 1132000}\n",
      "{\"learning_rate\": 4.045609478980685e-06, \"loss\": 1.3126185117959976, \"step\": 1132500}\n",
      "{\"learning_rate\": 4.025320564843369e-06, \"loss\": 1.270764562010765, \"step\": 1133000}\n",
      "{\"learning_rate\": 4.0050316507060545e-06, \"loss\": 1.3107987071871758, \"step\": 1133500}\n",
      "{\"learning_rate\": 3.984742736568739e-06, \"loss\": 1.249496756196022, \"step\": 1134000}\n",
      "{\"learning_rate\": 3.964453822431424e-06, \"loss\": 1.2781783623695373, \"step\": 1134500}\n",
      "{\"learning_rate\": 3.944164908294108e-06, \"loss\": 1.2932086094617843, \"step\": 1135000}\n",
      "{\"learning_rate\": 3.923875994156793e-06, \"loss\": 1.2802577686309815, \"step\": 1135500}\n",
      "{\"learning_rate\": 3.9035870800194774e-06, \"loss\": 1.2876799652576447, \"step\": 1136000}\n",
      "{\"learning_rate\": 3.883298165882162e-06, \"loss\": 1.2853895604610444, \"step\": 1136500}\n",
      "{\"learning_rate\": 3.863009251744847e-06, \"loss\": 1.2653143308162689, \"step\": 1137000}\n",
      "{\"learning_rate\": 3.842720337607531e-06, \"loss\": 1.2831129597425461, \"step\": 1137500}\n",
      "{\"learning_rate\": 3.822431423470216e-06, \"loss\": 1.2618896262645722, \"step\": 1138000}\n",
      "{\"learning_rate\": 3.8021425093329004e-06, \"loss\": 1.2821702893972398, \"step\": 1138500}\n",
      "{\"learning_rate\": 3.7818535951955855e-06, \"loss\": 1.2873184472322463, \"step\": 1139000}\n",
      "{\"learning_rate\": 3.76156468105827e-06, \"loss\": 1.2683695557117463, \"step\": 1139500}\n",
      "{\"learning_rate\": 3.741275766920955e-06, \"loss\": 1.2997972956299781, \"step\": 1140000}\n",
      "{\"learning_rate\": 3.7209868527836395e-06, \"loss\": 1.2750193046331406, \"step\": 1140500}\n",
      "{\"learning_rate\": 3.700697938646324e-06, \"loss\": 1.2843751584291458, \"step\": 1141000}\n",
      "{\"learning_rate\": 3.680409024509009e-06, \"loss\": 1.2745566934347152, \"step\": 1141500}\n",
      "{\"learning_rate\": 3.660120110371693e-06, \"loss\": 1.2730067299604415, \"step\": 1142000}\n",
      "{\"learning_rate\": 3.6398311962343778e-06, \"loss\": 1.267901265025139, \"step\": 1142500}\n",
      "{\"learning_rate\": 3.6195422820970624e-06, \"loss\": 1.2488822244405746, \"step\": 1143000}\n",
      "{\"learning_rate\": 3.599253367959747e-06, \"loss\": 1.264123208284378, \"step\": 1143500}\n",
      "{\"learning_rate\": 3.578964453822432e-06, \"loss\": 1.2632874767780304, \"step\": 1144000}\n",
      "{\"learning_rate\": 3.558675539685116e-06, \"loss\": 1.2605720143318175, \"step\": 1144500}\n",
      "{\"learning_rate\": 3.5383866255478007e-06, \"loss\": 1.2538650567531586, \"step\": 1145000}\n",
      "{\"learning_rate\": 3.5180977114104854e-06, \"loss\": 1.2786929013729096, \"step\": 1145500}\n",
      "{\"learning_rate\": 3.49780879727317e-06, \"loss\": 1.2803748487234115, \"step\": 1146000}\n",
      "{\"learning_rate\": 3.4775198831358547e-06, \"loss\": 1.2643045536279678, \"step\": 1146500}\n",
      "{\"learning_rate\": 3.4572309689985394e-06, \"loss\": 1.2506554571390152, \"step\": 1147000}\n",
      "{\"learning_rate\": 3.4369420548612237e-06, \"loss\": 1.272179603934288, \"step\": 1147500}\n",
      "{\"learning_rate\": 3.4166531407239083e-06, \"loss\": 1.2846651685237884, \"step\": 1148000}\n",
      "{\"learning_rate\": 3.396364226586593e-06, \"loss\": 1.2541692064404488, \"step\": 1148500}\n",
      "{\"learning_rate\": 3.3760753124492777e-06, \"loss\": 1.2834952520728111, \"step\": 1149000}\n",
      "{\"learning_rate\": 3.3557863983119624e-06, \"loss\": 1.2810562596321107, \"step\": 1149500}\n",
      "{\"learning_rate\": 3.335497484174647e-06, \"loss\": 1.2610943037867546, \"step\": 1150000}\n",
      "{\"learning_rate\": 3.3152085700373313e-06, \"loss\": 1.2755086454153062, \"step\": 1150500}\n",
      "{\"learning_rate\": 3.294919655900017e-06, \"loss\": 1.2649264886379241, \"step\": 1151000}\n",
      "{\"learning_rate\": 3.2746307417627015e-06, \"loss\": 1.281141788482666, \"step\": 1151500}\n",
      "{\"learning_rate\": 3.2543418276253857e-06, \"loss\": 1.2905592836141586, \"step\": 1152000}\n",
      "{\"learning_rate\": 3.2340529134880704e-06, \"loss\": 1.259898368000984, \"step\": 1152500}\n",
      "{\"learning_rate\": 3.213763999350755e-06, \"loss\": 1.294165340781212, \"step\": 1153000}\n",
      "{\"learning_rate\": 3.1934750852134397e-06, \"loss\": 1.237852099776268, \"step\": 1153500}\n",
      "{\"learning_rate\": 3.1731861710761244e-06, \"loss\": 1.2904492294788361, \"step\": 1154000}\n",
      "{\"learning_rate\": 3.152897256938809e-06, \"loss\": 1.2585542860031127, \"step\": 1154500}\n",
      "{\"learning_rate\": 3.1326083428014933e-06, \"loss\": 1.250845831990242, \"step\": 1155000}\n",
      "{\"learning_rate\": 3.112319428664178e-06, \"loss\": 1.2815064048171043, \"step\": 1155500}\n",
      "{\"learning_rate\": 3.0920305145268627e-06, \"loss\": 1.2695950025320053, \"step\": 1156000}\n",
      "{\"learning_rate\": 3.0717416003895474e-06, \"loss\": 1.2700753989219666, \"step\": 1156500}\n",
      "{\"learning_rate\": 3.051452686252232e-06, \"loss\": 1.2749027314186097, \"step\": 1157000}\n",
      "{\"learning_rate\": 3.0311637721149167e-06, \"loss\": 1.265216968536377, \"step\": 1157500}\n",
      "{\"learning_rate\": 3.010874857977601e-06, \"loss\": 1.266046585381031, \"step\": 1158000}\n",
      "{\"learning_rate\": 2.9905859438402856e-06, \"loss\": 1.2567941040992736, \"step\": 1158500}\n",
      "{\"learning_rate\": 2.9702970297029703e-06, \"loss\": 1.2696788074970244, \"step\": 1159000}\n",
      "{\"learning_rate\": 2.950008115565655e-06, \"loss\": 1.2723165242671965, \"step\": 1159500}\n",
      "{\"learning_rate\": 2.9297192014283397e-06, \"loss\": 1.2657705047130585, \"step\": 1160000}\n",
      "{\"learning_rate\": 2.9094302872910243e-06, \"loss\": 1.283043578982353, \"step\": 1160500}\n",
      "{\"learning_rate\": 2.889141373153709e-06, \"loss\": 1.2939718910455704, \"step\": 1161000}\n",
      "{\"learning_rate\": 2.8688524590163937e-06, \"loss\": 1.2833309254646301, \"step\": 1161500}\n",
      "{\"learning_rate\": 2.8485635448790784e-06, \"loss\": 1.281777992606163, \"step\": 1162000}\n",
      "{\"learning_rate\": 2.828274630741763e-06, \"loss\": 1.260770722270012, \"step\": 1162500}\n",
      "{\"learning_rate\": 2.8079857166044473e-06, \"loss\": 1.2852282030582427, \"step\": 1163000}\n",
      "{\"learning_rate\": 2.787696802467132e-06, \"loss\": 1.2755725318193436, \"step\": 1163500}\n",
      "{\"learning_rate\": 2.7674078883298166e-06, \"loss\": 1.3028960472345352, \"step\": 1164000}\n",
      "{\"learning_rate\": 2.7471189741925013e-06, \"loss\": 1.2869747859239578, \"step\": 1164500}\n",
      "{\"learning_rate\": 2.726830060055186e-06, \"loss\": 1.236807362496853, \"step\": 1165000}\n",
      "{\"learning_rate\": 2.7065411459178706e-06, \"loss\": 1.2772029774188995, \"step\": 1165500}\n",
      "{\"learning_rate\": 2.6862522317805553e-06, \"loss\": 1.266820859670639, \"step\": 1166000}\n",
      "{\"learning_rate\": 2.66596331764324e-06, \"loss\": 1.248164877653122, \"step\": 1166500}\n",
      "{\"learning_rate\": 2.6456744035059247e-06, \"loss\": 1.272085983991623, \"step\": 1167000}\n",
      "{\"learning_rate\": 2.6253854893686093e-06, \"loss\": 1.2872915672063827, \"step\": 1167500}\n",
      "{\"learning_rate\": 2.6050965752312936e-06, \"loss\": 1.2750843216776848, \"step\": 1168000}\n",
      "{\"learning_rate\": 2.5848076610939783e-06, \"loss\": 1.2668722579479217, \"step\": 1168500}\n",
      "{\"learning_rate\": 2.564518746956663e-06, \"loss\": 1.2642142308950424, \"step\": 1169000}\n",
      "{\"learning_rate\": 2.5442298328193476e-06, \"loss\": 1.2660574314594268, \"step\": 1169500}\n",
      "{\"learning_rate\": 2.5239409186820323e-06, \"loss\": 1.2747586357593537, \"step\": 1170000}\n",
      "{\"learning_rate\": 2.503652004544717e-06, \"loss\": 1.2680486540794373, \"step\": 1170500}\n",
      "{\"learning_rate\": 2.483363090407401e-06, \"loss\": 1.2506197711229325, \"step\": 1171000}\n",
      "{\"learning_rate\": 2.4630741762700863e-06, \"loss\": 1.279146179974079, \"step\": 1171500}\n",
      "{\"learning_rate\": 2.442785262132771e-06, \"loss\": 1.256977962255478, \"step\": 1172000}\n",
      "{\"learning_rate\": 2.4224963479954556e-06, \"loss\": 1.2602233459949495, \"step\": 1172500}\n",
      "{\"learning_rate\": 2.40220743385814e-06, \"loss\": 1.2645567157268525, \"step\": 1173000}\n",
      "{\"learning_rate\": 2.3819185197208246e-06, \"loss\": 1.2752232432365418, \"step\": 1173500}\n",
      "{\"learning_rate\": 2.3616296055835092e-06, \"loss\": 1.2731939115524291, \"step\": 1174000}\n",
      "{\"learning_rate\": 2.341340691446194e-06, \"loss\": 1.256206056535244, \"step\": 1174500}\n",
      "{\"learning_rate\": 2.3210517773088786e-06, \"loss\": 1.2805390623807906, \"step\": 1175000}\n",
      "{\"learning_rate\": 2.3007628631715633e-06, \"loss\": 1.275649371266365, \"step\": 1175500}\n",
      "{\"learning_rate\": 2.2804739490342475e-06, \"loss\": 1.2744654084444047, \"step\": 1176000}\n",
      "{\"learning_rate\": 2.260185034896932e-06, \"loss\": 1.2910036009550094, \"step\": 1176500}\n",
      "{\"learning_rate\": 2.239896120759617e-06, \"loss\": 1.2803010058403015, \"step\": 1177000}\n",
      "{\"learning_rate\": 2.219607206622302e-06, \"loss\": 1.275838103532791, \"step\": 1177500}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 2.1993182924849866e-06, \"loss\": 1.2816464748382568, \"step\": 1178000}\n",
      "{\"learning_rate\": 2.179029378347671e-06, \"loss\": 1.2825721714496612, \"step\": 1178500}\n",
      "{\"learning_rate\": 2.1587404642103556e-06, \"loss\": 1.2556605181694032, \"step\": 1179000}\n",
      "{\"learning_rate\": 2.1384515500730402e-06, \"loss\": 1.2885964673757553, \"step\": 1179500}\n",
      "{\"learning_rate\": 2.118162635935725e-06, \"loss\": 1.249369080543518, \"step\": 1180000}\n",
      "{\"learning_rate\": 2.0978737217984096e-06, \"loss\": 1.2701292046904564, \"step\": 1180500}\n",
      "{\"learning_rate\": 2.077584807661094e-06, \"loss\": 1.285576274752617, \"step\": 1181000}\n",
      "{\"learning_rate\": 2.0572958935237785e-06, \"loss\": 1.2585791773200035, \"step\": 1181500}\n",
      "{\"learning_rate\": 2.037006979386463e-06, \"loss\": 1.2575023874044418, \"step\": 1182000}\n",
      "{\"learning_rate\": 2.016718065249148e-06, \"loss\": 1.25357055413723, \"step\": 1182500}\n",
      "{\"learning_rate\": 1.9964291511118325e-06, \"loss\": 1.284180515050888, \"step\": 1183000}\n",
      "{\"learning_rate\": 1.976140236974517e-06, \"loss\": 1.2584062000513077, \"step\": 1183500}\n",
      "{\"learning_rate\": 1.955851322837202e-06, \"loss\": 1.2439664338827132, \"step\": 1184000}\n",
      "{\"learning_rate\": 1.9355624086998865e-06, \"loss\": 1.235211269378662, \"step\": 1184500}\n",
      "{\"learning_rate\": 1.9152734945625712e-06, \"loss\": 1.2727633982896804, \"step\": 1185000}\n",
      "{\"learning_rate\": 1.8949845804252557e-06, \"loss\": 1.2757261338233947, \"step\": 1185500}\n",
      "{\"learning_rate\": 1.8746956662879404e-06, \"loss\": 1.2590840801000596, \"step\": 1186000}\n",
      "{\"learning_rate\": 1.854406752150625e-06, \"loss\": 1.262640137910843, \"step\": 1186500}\n",
      "{\"learning_rate\": 1.8341178380133095e-06, \"loss\": 1.2801517832279206, \"step\": 1187000}\n",
      "{\"learning_rate\": 1.8138289238759942e-06, \"loss\": 1.2493548253774642, \"step\": 1187500}\n",
      "{\"learning_rate\": 1.7935400097386788e-06, \"loss\": 1.2766280517578126, \"step\": 1188000}\n",
      "{\"learning_rate\": 1.7732510956013633e-06, \"loss\": 1.2539626134634019, \"step\": 1188500}\n",
      "{\"learning_rate\": 1.752962181464048e-06, \"loss\": 1.252569410264492, \"step\": 1189000}\n",
      "{\"learning_rate\": 1.7326732673267329e-06, \"loss\": 1.2533240270614625, \"step\": 1189500}\n",
      "{\"learning_rate\": 1.7123843531894175e-06, \"loss\": 1.2724157292246818, \"step\": 1190000}\n",
      "{\"learning_rate\": 1.6920954390521022e-06, \"loss\": 1.2678588438034057, \"step\": 1190500}\n",
      "{\"learning_rate\": 1.6718065249147867e-06, \"loss\": 1.278431539773941, \"step\": 1191000}\n",
      "{\"learning_rate\": 1.6515176107774713e-06, \"loss\": 1.2689028760194778, \"step\": 1191500}\n",
      "{\"learning_rate\": 1.6312286966401558e-06, \"loss\": 1.2720962216854095, \"step\": 1192000}\n",
      "{\"learning_rate\": 1.6109397825028405e-06, \"loss\": 1.2715965960025788, \"step\": 1192500}\n",
      "{\"learning_rate\": 1.5906508683655251e-06, \"loss\": 1.2835130162835122, \"step\": 1193000}\n",
      "{\"learning_rate\": 1.5703619542282096e-06, \"loss\": 1.2681643791198731, \"step\": 1193500}\n",
      "{\"learning_rate\": 1.5500730400908945e-06, \"loss\": 1.2554615045189856, \"step\": 1194000}\n",
      "{\"learning_rate\": 1.5297841259535792e-06, \"loss\": 1.2390561725497247, \"step\": 1194500}\n",
      "{\"learning_rate\": 1.5094952118162636e-06, \"loss\": 1.2730340452194213, \"step\": 1195000}\n",
      "{\"learning_rate\": 1.4892062976789483e-06, \"loss\": 1.29069932949543, \"step\": 1195500}\n",
      "{\"learning_rate\": 1.4689173835416328e-06, \"loss\": 1.2600564848184586, \"step\": 1196000}\n",
      "{\"learning_rate\": 1.4486284694043177e-06, \"loss\": 1.2653383142948151, \"step\": 1196500}\n",
      "{\"learning_rate\": 1.4283395552670023e-06, \"loss\": 1.2476530027985573, \"step\": 1197000}\n",
      "{\"learning_rate\": 1.4080506411296868e-06, \"loss\": 1.2790828609466554, \"step\": 1197500}\n",
      "{\"learning_rate\": 1.3877617269923715e-06, \"loss\": 1.2617303974628449, \"step\": 1198000}\n",
      "{\"learning_rate\": 1.3674728128550561e-06, \"loss\": 1.2700569235682488, \"step\": 1198500}\n",
      "{\"learning_rate\": 1.3471838987177406e-06, \"loss\": 1.2867628467082977, \"step\": 1199000}\n",
      "{\"learning_rate\": 1.3268949845804255e-06, \"loss\": 1.2774835688471795, \"step\": 1199500}\n",
      "{\"learning_rate\": 1.30660607044311e-06, \"loss\": 1.286367233991623, \"step\": 1200000}\n",
      "{\"learning_rate\": 1.2863171563057946e-06, \"loss\": 1.280008747935295, \"step\": 1200500}\n",
      "{\"learning_rate\": 1.2660282421684793e-06, \"loss\": 1.2480769160985947, \"step\": 1201000}\n",
      "{\"learning_rate\": 1.2457393280311638e-06, \"loss\": 1.2628439067602157, \"step\": 1201500}\n",
      "{\"learning_rate\": 1.2254504138938484e-06, \"loss\": 1.2561920692324637, \"step\": 1202000}\n",
      "{\"learning_rate\": 1.205161499756533e-06, \"loss\": 1.285955210208893, \"step\": 1202500}\n",
      "{\"learning_rate\": 1.1848725856192178e-06, \"loss\": 1.280221493780613, \"step\": 1203000}\n",
      "{\"learning_rate\": 1.1645836714819024e-06, \"loss\": 1.2678554902076722, \"step\": 1203500}\n",
      "{\"learning_rate\": 1.144294757344587e-06, \"loss\": 1.2504609497189523, \"step\": 1204000}\n",
      "{\"learning_rate\": 1.1240058432072716e-06, \"loss\": 1.2737493636012078, \"step\": 1204500}\n",
      "{\"learning_rate\": 1.1037169290699563e-06, \"loss\": 1.2530434823036194, \"step\": 1205000}\n",
      "{\"learning_rate\": 1.083428014932641e-06, \"loss\": 1.2752179302573203, \"step\": 1205500}\n",
      "{\"learning_rate\": 1.0631391007953256e-06, \"loss\": 1.2692068526744842, \"step\": 1206000}\n",
      "{\"learning_rate\": 1.04285018665801e-06, \"loss\": 1.2659202057123184, \"step\": 1206500}\n",
      "{\"learning_rate\": 1.0225612725206947e-06, \"loss\": 1.2649435160160065, \"step\": 1207000}\n",
      "{\"learning_rate\": 1.0022723583833794e-06, \"loss\": 1.275912752866745, \"step\": 1207500}\n",
      "{\"learning_rate\": 9.819834442460639e-07, \"loss\": 1.2795134501457215, \"step\": 1208000}\n",
      "{\"learning_rate\": 9.616945301087488e-07, \"loss\": 1.270499779701233, \"step\": 1208500}\n",
      "{\"learning_rate\": 9.414056159714333e-07, \"loss\": 1.2699477834105493, \"step\": 1209000}\n",
      "{\"learning_rate\": 9.211167018341179e-07, \"loss\": 1.2777443317174912, \"step\": 1209500}\n",
      "{\"learning_rate\": 9.008277876968025e-07, \"loss\": 1.265716783642769, \"step\": 1210000}\n",
      "{\"learning_rate\": 8.805388735594871e-07, \"loss\": 1.25007581448555, \"step\": 1210500}\n",
      "{\"learning_rate\": 8.602499594221717e-07, \"loss\": 1.2761895272135735, \"step\": 1211000}\n",
      "{\"learning_rate\": 8.399610452848565e-07, \"loss\": 1.2736136362552644, \"step\": 1211500}\n",
      "{\"learning_rate\": 8.19672131147541e-07, \"loss\": 1.2685374561548233, \"step\": 1212000}\n",
      "{\"learning_rate\": 7.993832170102256e-07, \"loss\": 1.273026468396187, \"step\": 1212500}\n",
      "{\"learning_rate\": 7.790943028729103e-07, \"loss\": 1.2425272332429886, \"step\": 1213000}\n",
      "{\"learning_rate\": 7.58805388735595e-07, \"loss\": 1.2575844720602036, \"step\": 1213500}\n",
      "{\"learning_rate\": 7.385164745982795e-07, \"loss\": 1.2467664930820466, \"step\": 1214000}\n",
      "{\"learning_rate\": 7.182275604609641e-07, \"loss\": 1.2564211984872817, \"step\": 1214500}\n",
      "{\"learning_rate\": 6.979386463236489e-07, \"loss\": 1.266613142490387, \"step\": 1215000}\n",
      "{\"learning_rate\": 6.776497321863334e-07, \"loss\": 1.2654033505916595, \"step\": 1215500}\n",
      "{\"learning_rate\": 6.57360818049018e-07, \"loss\": 1.2548811490535736, \"step\": 1216000}\n",
      "{\"learning_rate\": 6.370719039117027e-07, \"loss\": 1.2804806252717973, \"step\": 1216500}\n",
      "{\"learning_rate\": 6.167829897743874e-07, \"loss\": 1.283573160648346, \"step\": 1217000}\n",
      "{\"learning_rate\": 5.964940756370719e-07, \"loss\": 1.2673717939257623, \"step\": 1217500}\n",
      "{\"learning_rate\": 5.762051614997566e-07, \"loss\": 1.2472767378091811, \"step\": 1218000}\n",
      "{\"learning_rate\": 5.559162473624412e-07, \"loss\": 1.2733855448961258, \"step\": 1218500}\n",
      "{\"learning_rate\": 5.356273332251258e-07, \"loss\": 1.2972687001228334, \"step\": 1219000}\n",
      "{\"learning_rate\": 5.153384190878105e-07, \"loss\": 1.2667286232709885, \"step\": 1219500}\n",
      "{\"learning_rate\": 4.950495049504951e-07, \"loss\": 1.2644273965358734, \"step\": 1220000}\n",
      "{\"learning_rate\": 4.7476059081317965e-07, \"loss\": 1.300865526676178, \"step\": 1220500}\n",
      "{\"learning_rate\": 4.544716766758644e-07, \"loss\": 1.2515097622871398, \"step\": 1221000}\n",
      "{\"learning_rate\": 4.3418276253854895e-07, \"loss\": 1.2574428456425666, \"step\": 1221500}\n",
      "{\"learning_rate\": 4.1389384840123357e-07, \"loss\": 1.2759389241933823, \"step\": 1222000}\n",
      "{\"learning_rate\": 3.9360493426391824e-07, \"loss\": 1.269349740087986, \"step\": 1222500}\n",
      "{\"learning_rate\": 3.7331602012660286e-07, \"loss\": 1.2543473119735717, \"step\": 1223000}\n",
      "{\"learning_rate\": 3.530271059892875e-07, \"loss\": 1.2552543151378632, \"step\": 1223500}\n",
      "{\"learning_rate\": 3.327381918519721e-07, \"loss\": 1.2630558253526687, \"step\": 1224000}\n",
      "{\"learning_rate\": 3.124492777146567e-07, \"loss\": 1.2627528767585754, \"step\": 1224500}\n",
      "{\"learning_rate\": 2.9216036357734135e-07, \"loss\": 1.2818343114852906, \"step\": 1225000}\n",
      "{\"learning_rate\": 2.7187144944002597e-07, \"loss\": 1.2845443329811097, \"step\": 1225500}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 2.515825353027106e-07, \"loss\": 1.2396953089237213, \"step\": 1226000}\n",
      "{\"learning_rate\": 2.3129362116539526e-07, \"loss\": 1.253200320005417, \"step\": 1226500}\n",
      "{\"learning_rate\": 2.1100470702807986e-07, \"loss\": 1.2877734628915787, \"step\": 1227000}\n",
      "{\"learning_rate\": 1.907157928907645e-07, \"loss\": 1.2784199369549751, \"step\": 1227500}\n",
      "{\"learning_rate\": 1.7042687875344912e-07, \"loss\": 1.2779794754981995, \"step\": 1228000}\n",
      "{\"learning_rate\": 1.5013796461613374e-07, \"loss\": 1.244050340652466, \"step\": 1228500}\n",
      "{\"learning_rate\": 1.2984905047881836e-07, \"loss\": 1.2739269877672195, \"step\": 1229000}\n",
      "{\"learning_rate\": 1.09560136341503e-07, \"loss\": 1.255731644630432, \"step\": 1229500}\n",
      "{\"learning_rate\": 8.927122220418765e-08, \"loss\": 1.2779735770821572, \"step\": 1230000}\n",
      "{\"learning_rate\": 6.898230806687227e-08, \"loss\": 1.2759363926649094, \"step\": 1230500}\n",
      "{\"learning_rate\": 4.869339392955689e-08, \"loss\": 1.2933054921627045, \"step\": 1231000}\n",
      "{\"learning_rate\": 2.8404479792241524e-08, \"loss\": 1.2767861474752427, \"step\": 1231500}\n",
      "{\"learning_rate\": 8.115565654926148e-09, \"loss\": 1.2800378948450089, \"step\": 1232000}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1232200, training_loss=1.473795949356173)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(os.path.join(PATH, 'distilbert'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
