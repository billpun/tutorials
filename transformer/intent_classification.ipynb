{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import multiprocessing\n",
    "from transformers import DistilBertTokenizer, DistilBertModel, AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead, AutoModel\n",
    "from tqdm.notebook import tqdm\n",
    "from common import Common, Timer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import random\n",
    "from apex import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'C:/Users/bill/Documents/projects/data/chatbot'\n",
    "MAX_WORKERS = multiprocessing.cpu_count() - 1\n",
    "B = 32\n",
    "E = 10\n",
    "T = 500\n",
    "Y = 199"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(PATH, 'train.tsv'), sep='\\t')[['utterance', 'intent']].dropna().reset_index(drop=True)\n",
    "valid_df = pd.read_csv(os.path.join(PATH, 'valid.tsv'), sep='\\t')[['utterance', 'intent']].dropna().reset_index(drop=True)\n",
    "\n",
    "intents = LabelEncoder()\n",
    "intents.fit(pd.concat([ train_df['intent'], valid_df['intent'] ]))\n",
    "train_df['intent'] = intents.transform(train_df['intent'])\n",
    "valid_df['intent'] = intents.transform(valid_df['intent'])\n",
    "\n",
    "# to ensure that BERT will run without problem on sequence length\n",
    "train_df['utterance'] = train_df['utterance'].apply(lambda x : x[:T])\n",
    "valid_df['utterance'] = valid_df['utterance'].apply(lambda x : x[:T])\n",
    "    \n",
    "itrain = Common.generator(train_df['utterance'], train_df['intent'], B)\n",
    "ivalid = Common.generator(valid_df['utterance'], valid_df['intent'], B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bill\\software\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = pd.concat([train_df['utterance'], valid_df['utterance']])\n",
    "ax = sns.distplot(x.str.split().apply(len))\n",
    "ax.set(xlabel='Title Length', ylabel='Distribution')\n",
    "ax.set_yticklabels(['{:,.0%}'.format(y) for y in ax.get_yticks()])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    #model = 'distilbert-base-cased'\n",
    "    def __init__(self, model, T, Y, device, L=0):\n",
    "        super(Model, self).__init__()\n",
    "        self.T = T\n",
    "        self.device = device\n",
    "        #self.tokenizer = DistilBertTokenizer.from_pretrained(\n",
    "        #    os.path.join(PATH, 'tokenizer'), do_lower_case=True)\n",
    "        #self.model = DistilBertModel.from_pretrained(\n",
    "        #    os.path.join(PATH, 'distilBERT')).to(self.device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model, do_lower_case=True)\n",
    "        self.model = AutoModel.from_pretrained(model)\n",
    "        # remove layers\n",
    "        for _ in range(L):\n",
    "            self.model.transformer.layer.__delitem__(0)\n",
    "        self.linear = nn.Linear(768, Y)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        tokens = self.tokenizer.batch_encode_plus(\n",
    "            inputs, \n",
    "            add_special_tokens=True, \n",
    "            return_tensors='pt', \n",
    "            pad_to_max_length=True\n",
    "            #max_length=self.T,\n",
    "            #return_attention_masks=False\n",
    "        )['input_ids'].to(self.device)\n",
    "        #with torch.no_grad():\n",
    "        output = self.model(tokens)[0][:,0,:]\n",
    "        #output = torch.flatten(output, start_dim=1)\n",
    "        output = self.dropout(output)\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "    \n",
    "def scoring(device, model, criterion, iterator):\n",
    "    with torch.no_grad():\n",
    "        total_loss = []\n",
    "        total_accy = []\n",
    "        for x, y, _ in iterator:\n",
    "            scores = model(x)\n",
    "            loss = criterion(scores, y.to(device).long())\n",
    "            total_loss.append(loss.item())\n",
    "            total_accy.append(Common.accuracy(scores, y, device))\n",
    "    return np.mean(total_loss), np.mean(total_accy)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of params: 66515911\n",
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b02baea42da0472cbef2dc2f225c682a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2631.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "\n",
      "epoch: 0, train_loss: 1.4, valid_loss: 1.0, train_accy: 71.41%, valid_accy: 76.76%, time: 00:03:19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c06d594af84d4ba64455cbcead3532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2631.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "\n",
      "epoch: 1, train_loss: 0.46, valid_loss: 0.94, train_accy: 88.99%, valid_accy: 77.97%, time: 00:03:20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cfc04a6d27e4450b52ac39bfcc3efed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2631.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 2, train_loss: 0.24, valid_loss: 0.94, train_accy: 94.09%, valid_accy: 78.31%, time: 00:03:18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79a55134a99c44eaa7740889aa80e6f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2631.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "\n",
      "epoch: 3, train_loss: 0.12, valid_loss: 0.98, train_accy: 97.23%, valid_accy: 78.85%, time: 00:03:18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f8a1180d7740ddb2e562486b640c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2631.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 4, train_loss: 0.061, valid_loss: 1.0, train_accy: 98.82%, valid_accy: 78.93%, time: 00:03:19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f73b96c6bb4420bb9212c45a7a09609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2631.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "\n",
      "epoch: 5, train_loss: 0.031, valid_loss: 1.1, train_accy: 99.46%, valid_accy: 78.51%, time: 00:03:17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "507e0527bc224682a9e242b62b756c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2631.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "\n",
      "epoch: 6, train_loss: 0.017, valid_loss: 1.1, train_accy: 99.73%, valid_accy: 78.74%, time: 00:03:17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "322fa298c7b74cc0b8115f738e37fd05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2631.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "\n",
      "epoch: 7, train_loss: 0.011, valid_loss: 1.1, train_accy: 99.83%, valid_accy: 79.17%, time: 00:03:17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4b8ebb01b1401098c7fc866c27b0a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2631.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "\n",
      "epoch: 8, train_loss: 0.0062, valid_loss: 1.2, train_accy: 99.93%, valid_accy: 78.98%, time: 00:03:17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84cb28c15d204975921d0ac750470de3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2631.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 9, train_loss: 0.0042, valid_loss: 1.2, train_accy: 99.94%, valid_accy: 79.09%, time: 00:03:17\n"
     ]
    }
   ],
   "source": [
    "lr = 2e-5 #[2e-5, 3e-5, 4e-5, 5e-5]:\n",
    "\n",
    "device = Common.device()\n",
    "# \n",
    "L = 0\n",
    "model = Model('distilbert-base-uncased', T, Y, device, L).to(device)\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('num of params: {}'.format(num_params))\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "    lr = lr, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "    eps = 1e-8, # args.adam_epsilon  - default is 1e-8.\n",
    "    weight_decay = 0.01\n",
    ")\n",
    "\n",
    "opt_level = 'O2'\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n",
    "\n",
    "criterion = Common.criterion()\n",
    "#criterion = FocalLoss(device)\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps = 1, # Default value in run_glue.py\n",
    "    num_training_steps = len(itrain) * E)\n",
    "\n",
    "#schedular = CosineAnnealingLR(optimizer, T_max=2)\n",
    "\n",
    "seed_val = 0\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "best_loss = 999\n",
    "best_model = None\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(E):\n",
    "    t = Timer()\n",
    "    total_loss = []\n",
    "    total_accy = []\n",
    "    for x, y, _ in tqdm(itrain):\n",
    "\n",
    "        # step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # step 3. Run our forward pass.\n",
    "        scores = model(x)\n",
    "\n",
    "        # step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = criterion(scores, y.to(device).long())\n",
    "        total_loss.append(loss.item())\n",
    "        #total_accy.append(sum(torch.argmax(scores, axis=1) == y.to(device)).true_divide(len(y)).item())\n",
    "        total_accy.append(Common.accuracy(scores, y, device))\n",
    "\n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "            \n",
    "        #loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    train_loss, train_accy = np.mean(total_loss), np.mean(total_accy)\n",
    "    valid_loss, valid_accy = scoring(device, model, criterion, ivalid)\n",
    "\n",
    "    if valid_loss < best_loss:\n",
    "        Common.save_checkpoint({\n",
    "            'loss': valid_loss,\n",
    "            'accuracy': valid_accy,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, './models/model.tar')\n",
    "        best_model = model\n",
    "        best_epoch = epoch\n",
    "        best_loss = valid_loss\n",
    "\n",
    "    print(', '.join([\n",
    "        'epoch: {}'.format(epoch),\n",
    "        'train_loss: {:3.2}'.format(train_loss),\n",
    "        'valid_loss: {:3.2}'.format(valid_loss),\n",
    "        'train_accy: {:3.2%}'.format(train_accy),\n",
    "        'valid_accy: {:3.2%}'.format(valid_accy),\n",
    "        'time: {}'.format(t.get())\n",
    "    ]))\n",
    "\n",
    "# test_loss, test_accy = scoring(device, best_model, criterion, itest)\n",
    "# Log.info(', '.join([\n",
    "#         'best_epoch: {}'.format(best_epoch),\n",
    "#         'test_loss: {:3.2}'.format(test_loss),\n",
    "#         'test_accy: {:3.2}'.format(test_accy)\n",
    "#     ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model, do_lower_case=True)\n",
    "model = AutoModel.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "cp = torch.load('./models/model.tar', map_location=device)\n",
    "model = Model('distilbert-base-uncased', T, Y, device, L).to(device)\n",
    "optimizer = AdamW(model.parameters(),\n",
    "    lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "    eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    ")\n",
    "#criterion = FocalLoss(device)\n",
    "criterion = Common.criterion()\n",
    "#qmodel = torch.quantization.quantize_dynamic(model, {torch.nn.Linear}, dtype=torch.qint8)\n",
    "model.load_state_dict(cp['state_dict'])\n",
    "optimizer.load_state_dict(cp['optimizer'])\n",
    "\n",
    "#torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "total = []\n",
    "_start = datetime.datetime.now()\n",
    "for i, x in enumerate(valid_df['utterance'].values):\n",
    "    start = datetime.datetime.now()\n",
    "    with torch.no_grad():\n",
    "        scores = model([x])\n",
    "    delta = datetime.datetime.now() - start\n",
    "    total.append(delta.total_seconds() * 1000)\n",
    "    if i % 500 == 0 and i > 0:\n",
    "        print((datetime.datetime.now() - _start).total_seconds())\n",
    "        _start = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = valid_df['utterance'].str.split().map(len).values\n",
    "y = np.array(total)\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "ax = sns.regplot(x, y, marker='+', color='b')\n",
    "ax.set(xlabel='# of tokens', ylabel='elapsed time (millisecond)')\n",
    "\n",
    "import scipy\n",
    "slope, intercept, r2, p_value, std_err = scipy.stats.linregress(x=x, y=y)\n",
    "print(f'line-fit: y = {round(intercept, 2)} + {round(slope, 2)} x')\n",
    "print(f'r2: {round(r2 ** 2, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "#model = DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_ids_to_tokens(tokenizer.encode('my cat ate my card.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\n",
    "    'change of address but not effective till 9 / 22',\n",
    "    'my cat sucks really bad',\n",
    "    'my day is going well',\n",
    "    'Here is the sentence I want embeddings for.'\n",
    "]\n",
    "tokens = tokenizer.batch_encode_plus(\n",
    "    inputs, \n",
    "    add_special_tokens=True, \n",
    "    return_tensors='pt', \n",
    "    pad_to_max_length=True,\n",
    "    max_length=50,\n",
    "    return_attention_masks=False\n",
    ")\n",
    "\n",
    "print(tokens)\n",
    "\n",
    "#for token in tokens:\n",
    "#    print(tokenizer.convert_ids_to_tokens(token))\n",
    "# tokens = []\n",
    "# for x in inputs:\n",
    "#     tokens.append(torch.tensor(tokenizer.encode(x, add_special_tokens=True, max_length=T, pad_to_max_length=True)))\n",
    "    \n",
    "# tokens = torch.stack(tokens).to(device)\n",
    "# _, output = model(**tokens)\n",
    "#output = torch.flatten(output, start_dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
