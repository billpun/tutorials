{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import multiprocessing\n",
    "from transformers import DistilBertTokenizer, DistilBertModel, AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead, AutoModel\n",
    "from tqdm.notebook import tqdm\n",
    "from common import Common, Timer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import random\n",
    "from apex import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'C:/Users/bill/Documents/projects/data/chatbot'\n",
    "MAX_WORKERS = multiprocessing.cpu_count() - 1\n",
    "B = 32\n",
    "E = 10\n",
    "T = 500\n",
    "Y = 199"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(PATH, 'train.tsv'), sep='\\t')[['utterance', 'intent']].dropna().reset_index(drop=True)\n",
    "valid_df = pd.read_csv(os.path.join(PATH, 'valid.tsv'), sep='\\t')[['utterance', 'intent']].dropna().reset_index(drop=True)\n",
    "\n",
    "intents = LabelEncoder()\n",
    "intents.fit(pd.concat([ train_df['intent'], valid_df['intent'] ]))\n",
    "train_df['intent'] = intents.transform(train_df['intent'])\n",
    "valid_df['intent'] = intents.transform(valid_df['intent'])\n",
    "\n",
    "# to ensure that BERT will run without problem on sequence length\n",
    "train_df['utterance'] = train_df['utterance'].apply(lambda x : x[:T])\n",
    "valid_df['utterance'] = valid_df['utterance'].apply(lambda x : x[:T])\n",
    "    \n",
    "itrain = Common.generator(train_df['utterance'], train_df['intent'], B)\n",
    "ivalid = Common.generator(valid_df['utterance'], valid_df['intent'], B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = pd.concat([train_df['utterance'], valid_df['utterance']])\n",
    "ax = sns.distplot(x.str.split().apply(len))\n",
    "ax.set(xlabel='Title Length', ylabel='Distribution')\n",
    "ax.set_yticklabels(['{:,.0%}'.format(y) for y in ax.get_yticks()])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    #model = 'distilbert-base-cased'\n",
    "    def __init__(self, model, T, Y, device, L=0):\n",
    "        super(Model, self).__init__()\n",
    "        self.T = T\n",
    "        self.device = device\n",
    "        #self.tokenizer = DistilBertTokenizer.from_pretrained(\n",
    "        #    os.path.join(PATH, 'tokenizer'), do_lower_case=True)\n",
    "        #self.model = DistilBertModel.from_pretrained(\n",
    "        #    os.path.join(PATH, 'distilBERT')).to(self.device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model, do_lower_case=True)\n",
    "        self.model = AutoModel.from_pretrained(model)\n",
    "        # remove layers\n",
    "        for _ in range(L):\n",
    "            self.model.transformer.layer.__delitem__(0)\n",
    "        self.linear = nn.Linear(768, Y)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        tokens = self.tokenizer.batch_encode_plus(\n",
    "            inputs, \n",
    "            add_special_tokens=True, \n",
    "            return_tensors='pt', \n",
    "            pad_to_max_length=True,\n",
    "            #max_length=self.T,\n",
    "            return_attention_masks=False\n",
    "        )['input_ids'].to(self.device)\n",
    "        #with torch.no_grad():\n",
    "        output = self.model(tokens)[0][:,0,:]\n",
    "        #output = torch.flatten(output, start_dim=1)\n",
    "        output = self.dropout(output)\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "    \n",
    "def scoring(device, model, criterion, iterator):\n",
    "    with torch.no_grad():\n",
    "        total_loss = []\n",
    "        total_accy = []\n",
    "        for x, y in iterator:\n",
    "            scores = model(x)\n",
    "            loss = criterion(scores, y.to(device).long())\n",
    "            total_loss.append(loss.item())\n",
    "            total_accy.append(Common.accuracy(scores, y, device))\n",
    "    return np.mean(total_loss), np.mean(total_accy)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of params: 66515911\n",
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c715116fbc924c90bc8c78518293643d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2631.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "\n",
      "epoch: 0, train_loss: 1.5, valid_loss: 1.0, train_accy: 70.12%, valid_accy: 77.05%, time: 00:03:21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad664b9cf57f4985bc4cce2efc6a92da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2631.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "\n",
      "epoch: 1, train_loss: 0.46, valid_loss: 0.92, train_accy: 88.98%, valid_accy: 77.77%, time: 00:03:20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d955e17a2345c0abe70539c18f507b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2631.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "\n",
      "epoch: 2, train_loss: 0.25, valid_loss: 0.96, train_accy: 94.02%, valid_accy: 78.17%, time: 00:03:20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdfb2d90af7a4b4e8531006b0862d6f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2631.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 3, train_loss: 0.12, valid_loss: 0.97, train_accy: 97.19%, valid_accy: 79.04%, time: 00:03:18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0541a4863a0e4cf8901a54b85053ce2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2631.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "\n",
      "epoch: 4, train_loss: 0.062, valid_loss: 1.0, train_accy: 98.77%, valid_accy: 79.13%, time: 00:03:20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e33f7e799d4d868b024236323a86b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2631.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "\n",
      "epoch: 5, train_loss: 0.031, valid_loss: 1.1, train_accy: 99.46%, valid_accy: 78.94%, time: 00:03:18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d135f7b9a5ad446ba1502011c667ab9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2631.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "\n",
      "epoch: 6, train_loss: 0.017, valid_loss: 1.1, train_accy: 99.73%, valid_accy: 78.90%, time: 00:03:18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625073ee69ed449fb6842d5d99b026cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2631.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "\n",
      "epoch: 7, train_loss: 0.01, valid_loss: 1.1, train_accy: 99.85%, valid_accy: 79.20%, time: 00:03:18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f26701bd0d94091984ad9e01b45842e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2631.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 8, train_loss: 0.0058, valid_loss: 1.2, train_accy: 99.92%, valid_accy: 79.00%, time: 00:03:19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abd9443847c9408c880185a16882d240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2631.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "\n",
      "epoch: 9, train_loss: 0.004, valid_loss: 1.2, train_accy: 99.94%, valid_accy: 79.20%, time: 00:03:19\n"
     ]
    }
   ],
   "source": [
    "lr = 2e-5 #[2e-5, 3e-5, 4e-5, 5e-5]:\n",
    "\n",
    "device = Common.device()\n",
    "# \n",
    "L = 0\n",
    "model = Model('distilbert-base-uncased', T, Y, device, L).to(device)\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('num of params: {}'.format(num_params))\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "    lr = lr, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "    eps = 1e-8, # args.adam_epsilon  - default is 1e-8.\n",
    "    weight_decay = 0.01\n",
    ")\n",
    "\n",
    "opt_level = 'O2'\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n",
    "\n",
    "criterion = Common.criterion()\n",
    "#criterion = FocalLoss(device)\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps = 1, # Default value in run_glue.py\n",
    "    num_training_steps = len(itrain) * E)\n",
    "\n",
    "#schedular = CosineAnnealingLR(optimizer, T_max=2)\n",
    "\n",
    "seed_val = 0\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "best_loss = 999\n",
    "best_model = None\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(E):\n",
    "    t = Timer()\n",
    "    total_loss = []\n",
    "    total_accy = []\n",
    "    for x, y in tqdm(itrain):\n",
    "\n",
    "        # step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # step 3. Run our forward pass.\n",
    "        scores = model(x)\n",
    "\n",
    "        # step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = criterion(scores, y.to(device).long())\n",
    "        total_loss.append(loss.item())\n",
    "        #total_accy.append(sum(torch.argmax(scores, axis=1) == y.to(device)).true_divide(len(y)).item())\n",
    "        total_accy.append(Common.accuracy(scores, y, device))\n",
    "\n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "            \n",
    "        #loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    train_loss, train_accy = np.mean(total_loss), np.mean(total_accy)\n",
    "    valid_loss, valid_accy = scoring(device, model, criterion, ivalid)\n",
    "\n",
    "    if valid_loss < best_loss:\n",
    "        Common.save_checkpoint({\n",
    "            'loss': valid_loss,\n",
    "            'accuracy': valid_accy,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, './models/model.tar')\n",
    "        best_model = model\n",
    "        best_epoch = epoch\n",
    "        best_loss = valid_loss\n",
    "\n",
    "    print(', '.join([\n",
    "        'epoch: {}'.format(epoch),\n",
    "        'train_loss: {:3.2}'.format(train_loss),\n",
    "        'valid_loss: {:3.2}'.format(valid_loss),\n",
    "        'train_accy: {:3.2%}'.format(train_accy),\n",
    "        'valid_accy: {:3.2%}'.format(valid_accy),\n",
    "        'time: {}'.format(t.get())\n",
    "    ]))\n",
    "\n",
    "# test_loss, test_accy = scoring(device, best_model, criterion, itest)\n",
    "# Log.info(', '.join([\n",
    "#         'best_epoch: {}'.format(best_epoch),\n",
    "#         'test_loss: {:3.2}'.format(test_loss),\n",
    "#         'test_accy: {:3.2}'.format(test_accy)\n",
    "#     ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model, do_lower_case=True)\n",
    "model = AutoModel.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "cp = torch.load('./models/model.tar', map_location=device)\n",
    "model = Model('distilbert-base-uncased', T, Y, device, L).to(device)\n",
    "optimizer = AdamW(model.parameters(),\n",
    "    lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "    eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    ")\n",
    "#criterion = FocalLoss(device)\n",
    "criterion = Common.criterion()\n",
    "#qmodel = torch.quantization.quantize_dynamic(model, {torch.nn.Linear}, dtype=torch.qint8)\n",
    "model.load_state_dict(cp['state_dict'])\n",
    "optimizer.load_state_dict(cp['optimizer'])\n",
    "\n",
    "#torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "total = []\n",
    "_start = datetime.datetime.now()\n",
    "for i, x in enumerate(valid_df['utterance'].values):\n",
    "    start = datetime.datetime.now()\n",
    "    with torch.no_grad():\n",
    "        scores = model([x])\n",
    "    delta = datetime.datetime.now() - start\n",
    "    total.append(delta.total_seconds() * 1000)\n",
    "    if i % 500 == 0 and i > 0:\n",
    "        print((datetime.datetime.now() - _start).total_seconds())\n",
    "        _start = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = valid_df['utterance'].str.split().map(len).values\n",
    "y = np.array(total)\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "ax = sns.regplot(x, y, marker='+', color='b')\n",
    "ax.set(xlabel='# of tokens', ylabel='elapsed time (millisecond)')\n",
    "\n",
    "import scipy\n",
    "slope, intercept, r2, p_value, std_err = scipy.stats.linregress(x=x, y=y)\n",
    "print(f'line-fit: y = {round(intercept, 2)} + {round(slope, 2)} x')\n",
    "print(f'r2: {round(r2 ** 2, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "#model = DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_ids_to_tokens(tokenizer.encode('my cat ate my card.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\n",
    "    'change of address but not effective till 9 / 22',\n",
    "    'my cat sucks really bad',\n",
    "    'my day is going well',\n",
    "    'Here is the sentence I want embeddings for.'\n",
    "]\n",
    "tokens = tokenizer.batch_encode_plus(\n",
    "    inputs, \n",
    "    add_special_tokens=True, \n",
    "    return_tensors='pt', \n",
    "    pad_to_max_length=True,\n",
    "    max_length=50,\n",
    "    return_attention_masks=False\n",
    ")\n",
    "\n",
    "print(tokens)\n",
    "\n",
    "#for token in tokens:\n",
    "#    print(tokenizer.convert_ids_to_tokens(token))\n",
    "# tokens = []\n",
    "# for x in inputs:\n",
    "#     tokens.append(torch.tensor(tokenizer.encode(x, add_special_tokens=True, max_length=T, pad_to_max_length=True)))\n",
    "    \n",
    "# tokens = torch.stack(tokens).to(device)\n",
    "# _, output = model(**tokens)\n",
    "#output = torch.flatten(output, start_dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
