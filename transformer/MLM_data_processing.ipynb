{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stopwords = set(stopwords.words('English'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def cleanse(text):\n",
    "    text = ''.join([ x for x in str(text).lower() if x in string.printable ])\n",
    "    text = re.sub(r'\\b\\d+\\b', '', text)\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = re.sub(r'[#`\\*\\\"“”\\n\\\\…\\+\\-\\/\\=\\(\\)‘•:\\[\\]\\|’\\!;$,?\\'%]', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [ abbrev[t] if t in abbrev else t for t in tokens ]\n",
    "    tokens = [ wnl.lemmatize(i,j[0].lower()) if j[0].lower() in ['a','n','v'] else wnl.lemmatize(i) for i, j in pos_tag(tokens) ]\n",
    "    #text = ' '.join(t for t in tokens if t not in stopwords)\n",
    "    text = ' '.join(tokens)\n",
    "    return text\n",
    "\n",
    "path = 'c:/Users/bill/Documents/projects/data/chatbot'\n",
    "data = pd.read_csv(os.path.join(path, 'sample'), sep='\\t', names=[\n",
    "    'rpt_mnth', 'cnv_id', 'msg_id', 'agent', 'msg_type', 'channel', \n",
    "    'creat_ts', 'text', 'intent', 'score', 'resp_cd'\n",
    "])\n",
    "data = data[data['agent'].isin(['coremobile', 'ccp'])]['text']\\\n",
    "    .apply(lambda x : cleanse(x)).str.split('.').explode()\\\n",
    "    .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masking(text):\n",
    "    text = re.sub(r'\\{+(\\s+)?\\{+[A-Za-z0-9\\s]+\\}+(\\s+)?\\}+', '[URL]', text)\n",
    "    tokens = str(text).split()\n",
    "    keys = [ t for t in tokens if t not in stopwords ]\n",
    "    out = []\n",
    "    if len(keys) >= 4:\n",
    "        size = min(max(math.ceil(len(keys) * 0.4), 1), 5)\n",
    "        masks = np.random.choice(keys, replace=False, size=size)\n",
    "        for mask in masks:\n",
    "            s = tokens.copy()\n",
    "            s[s.index(mask)] = '[MASK]'\n",
    "            s = ' '.join(s).strip() + '\\t' + mask\n",
    "            if '{ { link } }' not in s:\n",
    "                out.append(s)\n",
    "    return out\n",
    "data = data.apply(lambda x : masking(x)).to_frame()\n",
    "data = data['text'].apply(pd.Series).unstack().reset_index(drop=True).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('MLM.txt', 'w') as f:\n",
    "    f.write('text\\tmask\\n')\n",
    "    for d in data.values:\n",
    "        f.write(d + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "for r in data.str.split():\n",
    "    vocab.update(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32101"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
