{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "from torchtext.data import Field, TabularDataset, Iterator, batch\n",
    "from torchtext.data import Iterator, BucketIterator\n",
    "from torchtext.vocab import Vectors\n",
    "from src.models import get_model\n",
    "from torch.optim import Adam\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.autograd import Variable\n",
    "import spacy\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 2000\n",
    "K = 128\n",
    "H = 4\n",
    "N = 6\n",
    "dropout = 0.1\n",
    "MIN_FREQ = 2\n",
    "MAX_LEN = 100\n",
    "B = 32\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer(object):\n",
    "    \n",
    "    def __init__(self, lang):\n",
    "        self.nlp = spacy.load(lang)\n",
    "            \n",
    "    def tokenize(self, sentence):\n",
    "        sentence = re.sub(r\"[\\*\\\"“”\\n\\\\…\\+\\-\\/\\=\\(\\)‘•:\\[\\]\\|’\\!;]\", \" \", str(sentence))\n",
    "        sentence = re.sub(r\"[ ]+\", \" \", sentence)\n",
    "        sentence = re.sub(r\"\\!+\", \"!\", sentence)\n",
    "        sentence = re.sub(r\"\\,+\", \",\", sentence)\n",
    "        sentence = re.sub(r\"\\?+\", \"?\", sentence)\n",
    "        sentence = sentence.lower()\n",
    "        return [tok.text for tok in self.nlp.tokenizer(sentence) if tok.text != \" \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS_WORD = '<sos>'\n",
    "EOS_WORD = '<eos>'\n",
    "TRG = Field(\n",
    "    lower=True, \n",
    "    tokenize=Tokenizer('fr_core_news_sm').tokenize, \n",
    "    init_token=BOS_WORD, \n",
    "    eos_token=EOS_WORD,\n",
    "    batch_first=True\n",
    ")\n",
    "SRC = Field(\n",
    "    lower=True, \n",
    "    tokenize=Tokenizer('en_core_web_sm').tokenize,\n",
    "    batch_first=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/bill/Documents/projects/data/tutorial/transformer/'\n",
    "if not os.path.exists(os.path.join(path, 'temp.csv')):\n",
    "    source = open(os.path.join(path, 'english.txt'), encoding='utf8').read().strip().split('\\n')\n",
    "    target = open(os.path.join(path, 'french.txt'), encoding='utf8').read().strip().split('\\n')\n",
    "    df = pd.DataFrame({\n",
    "        'src' : source, \n",
    "        'trg': target \n",
    "    }, columns=[\"src\", \"trg\"])\n",
    "    df = df[(df['src'].str.count(' ') <= MAX_LEN) & (df['trg'].str.count(' ') <= MAX_LEN)]\n",
    "    df.to_csv(os.path.join(path, 'temp.csv'), index=False)\n",
    "data = TabularDataset(\n",
    "    os.path.join(path, 'temp.csv'), \n",
    "    format='csv', \n",
    "    fields=[\n",
    "        ('src', SRC), \n",
    "        ('trg', TRG)\n",
    "    ])\n",
    "train, valid, test = data.split(split_ratio=[0.8, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train.src, min_freq=MIN_FREQ)\n",
    "TRG.build_vocab(train.trg, min_freq=MIN_FREQ)\n",
    "src_pad = SRC.vocab.stoi['<pad>']\n",
    "trg_pad = TRG.vocab.stoi['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HarvardIterator(Iterator):\n",
    "    def create_batches(self):\n",
    "        if self.train:\n",
    "            def pool(d, random_shuffler):\n",
    "                for p in batch(d, self.batch_size * 100):\n",
    "                    p_batch = data.batch(\n",
    "                        sorted(p, key=self.sort_key),\n",
    "                        self.batch_size, self.batch_size_fn)\n",
    "                    for b in random_shuffler(list(p_batch)):\n",
    "                        yield b\n",
    "            self.batches = pool(self.data(), self.random_shuffler)\n",
    "        else:\n",
    "            self.batches = []\n",
    "            for b in batch(self.data(), \n",
    "                           self.batch_size,\n",
    "                           self.batch_size_fn):\n",
    "                self.batches.append(sorted(b, key=self.sort_key))\n",
    "\n",
    "#B = 32\n",
    "#train_iter = MyIterator(\n",
    "#    train, \n",
    "#     batch_size=B, \n",
    "#     device='cuda',\n",
    "#     repeat=False, \n",
    "#     sort_key=lambda x: (len(x.src), len(x.trg)),\n",
    "#     batch_size_fn=batch_size_fn, \n",
    "#     train=True, \n",
    "#     shuffle=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "itrain, ivalid = BucketIterator.splits(\n",
    "    (train, valid),\n",
    "    batch_sizes=(B, B),\n",
    "    device=device,\n",
    "    sort_key=lambda x: (len(x.src), len(x.trg)),\n",
    "    sort_within_batch=False,\n",
    "    repeat=False\n",
    ")\n",
    "itest = Iterator(\n",
    "    test,\n",
    "    batch_size=B,\n",
    "    device=device,\n",
    "    sort=False,\n",
    "    sort_within_batch=False,\n",
    "    repeat=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(\n",
    "    src_vocab=len(SRC.vocab), \n",
    "    trg_vocab=len(TRG.vocab), \n",
    "    K=K,\n",
    "    H=H,\n",
    "    N=N,\n",
    "    dropout=dropout\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nopeak_mask(size):\n",
    "    np_mask = np.triu(np.ones((1, size, size)), k=1).astype('uint8')\n",
    "    np_mask = Variable(torch.from_numpy(np_mask) == 0)\n",
    "    np_mask = np_mask.cuda()\n",
    "    return np_mask\n",
    "\n",
    "def create_masks(src, trg):\n",
    "    src_mask = (src != src_pad).unsqueeze(-2)\n",
    "    if trg is not None:\n",
    "        trg_mask = (trg != trg_pad).unsqueeze(-2)\n",
    "        size = trg.size(1)\n",
    "        np_mask = nopeak_mask(size)\n",
    "        trg_mask = trg_mask & np_mask\n",
    "    else:\n",
    "        trg_mask = None\n",
    "    return src_mask, trg_mask\n",
    "\n",
    "def scoring(device, model, criterion, iterator):\n",
    "    with torch.no_grad():\n",
    "        total_loss = []\n",
    "        for batch in iterator:\n",
    "            src = batch.src.to(device)\n",
    "            trg = batch.trg.to(device)\n",
    "            trg_input = trg[:, :-1]\n",
    "            src_mask, trg_mask = create_masks(src, trg_input)\n",
    "            preds = model(src, trg_input, src_mask, trg_mask)\n",
    "            loss = criterion(\n",
    "                preds.view(-1, preds.size(-1)), \n",
    "                trg[:, 1:].contiguous().view(-1))\n",
    "            total_loss.append(loss.item())\n",
    "    return np.mean(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac67cb5f81c4c0bac36ceba5b5cf056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3873.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 0, train_loss = 2.622, valid_loss = 2.370\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4adc3e96c4854d5eb3690fdf42ac32d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3873.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1, train_loss = 2.266, valid_loss = 2.105\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f3d3520f9249d4852c0ce2f193ce5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3873.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 2, train_loss = 2.041, valid_loss = 1.939\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f00601ef98f47eab2af3cea633d39b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3873.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 3, train_loss = 1.883, valid_loss = 1.826\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "619780f4107047a7b1bbc92c20b1f3cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3873.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 4, train_loss = 1.767, valid_loss = 1.747\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb378a91e0e94987b3e8ee85574397f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3873.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 5, train_loss = 1.675, valid_loss = 1.677\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97dcaa792bbd4d7da69b2a5ceab38db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3873.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 6, train_loss = 1.602, valid_loss = 1.626\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0c9c0c1f52461ca77cf83c07d404bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3873.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 7, train_loss = 1.542, valid_loss = 1.587\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a012dce0db4a9596b0498da55625d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3873.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 8, train_loss = 1.489, valid_loss = 1.563\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f232dfdf976e451595b6bb59e8acc466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3873.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 9, train_loss = 1.444, valid_loss = 1.520\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c9aaa9c4d2e45d7bbf47ce6d317b2c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3873.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 10, train_loss = 1.408, valid_loss = 1.502\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2f05e2e7fa4862a7417b695101008f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3873.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 11, train_loss = 1.378, valid_loss = 1.497\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece1b75057c345ae91f23f68b953460c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3873.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 12, train_loss = 1.367, valid_loss = 1.488\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd83f3a8f4044f0bdfc577dc9c373a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3873.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 13, train_loss = 1.355, valid_loss = 1.469\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "338b8f6534df425dba6a7d4e2d3d75db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3873.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"training model...\")\n",
    "model.to(device)\n",
    "#model.train()\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=trg_pad)\n",
    "best_loss = 10\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    \n",
    "    total_loss = []\n",
    "    for batch in tqdm(itrain): \n",
    "        \n",
    "        # index of the tokens B x T\n",
    "        src = batch.src.to(device)\n",
    "        trg = batch.trg.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        trg_input = trg[:, :-1]\n",
    "        src_mask, trg_mask = create_masks(src, trg_input)\n",
    "        preds = model(src, trg_input, src_mask, trg_mask)\n",
    "        \n",
    "        #set_trace()\n",
    "        \n",
    "        loss = criterion(\n",
    "            preds.view(-1, preds.size(-1)), \n",
    "            trg[:, 1:].contiguous().view(-1))\n",
    "\n",
    "        total_loss.append(loss.item())   \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_loss = np.mean(total_loss)\n",
    "    valid_loss = scoring(device, model, criterion, ivalid)\n",
    "\n",
    "    print(\"epoch %d, train_loss = %.3f, valid_loss = %.03f\" % (epoch, train_loss, valid_loss))\n",
    "    \n",
    "    if valid_loss < best_loss:\n",
    "        torch.save({\n",
    "                'loss': valid_loss,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "            }, 'C:/Users/bill/Documents/projects/tutorials/model.tar')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
